<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ES官方文档笔记</title>
      <link href="2022/02/15/backend/storage/es/"/>
      <url>2022/02/15/backend/storage/es/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/getting-started.html">ElasticSearch官方教程(非最新版)</a></li></ul><h2 id="集群原理"><a href="#集群原理" class="headerlink" title="集群原理"></a>集群原理</h2><h3 id="空集群"><a href="#空集群" class="headerlink" title="空集群"></a>空集群</h3><pre><code class="textmate">一个运行中的Elasticsearch实例称为一个节点，而集群是由一个或者多个拥有相同cluster.name配置的节点组成，它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。任何节点都可以成为主节点。我们的示例集群就只有一个节点，所以它同时也成为了主节点。作为用户，我们可以将请求发送到集群中的任何节点，包括主节点。每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。</code></pre><h3 id="集群健康"><a href="#集群健康" class="headerlink" title="集群健康"></a>集群健康</h3><pre><code class="textmate">Elasticsearch的集群监控信息中包含了许多的统计数据，其中最为重要的一项就是集群健康，它在status字段中展示为green、yellow或者red。GET/_cluster/health1.green    所有的主分片和副本分片都正常运行。2.yellow    所有的主分片都正常运行，但不是所有的副本分片都正常运行。3.red    有主分片没能正常运行。</code></pre><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><pre><code class="textmate">索引实际上是指向一个或者多个物理分片的逻辑命名空间。一个 分片 是一个底层的工作单元 ，它仅保存了全部数据中的一部分,一个分片是一个 Lucene 的实例，它本身就是一个完整的搜索引擎。索引在默认情况下会被分配5个主分片，我们的文档被存储和索引到分片内，但是应用程序是直接与索引而不是与分片进行交互。Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。 当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。一个分片可以是 主分片或者 副本 分片。 索引内任意一个文档都归属于一个主分片，所以主分片的数目决定着索引能够保存的最大数据量。</code></pre><ul><li>添加索引语法</li></ul><pre><code class="textmate">PUT /blogs&#123;   &quot;settings&quot; : &#123;      &quot;number_of_shards&quot; : 3,  //分片数量      &quot;number_of_replicas&quot; : 1 //副本数量   &#125;&#125;</code></pre><h3 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h3><pre><code class="textmate">当你在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的 cluster.name 配置，它就会自动发现集群并加入到其中。 但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表。</code></pre><h3 id="水平扩容"><a href="#水平扩容" class="headerlink" title="水平扩容"></a>水平扩容</h3><pre><code class="textmate">拥有三个节点的集群——为了分散负载而对分片进行重新分配分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。 有6个分片（3个主分片和3个副本分片）的索引可以最大扩容到6个节点，每个节点上存在一个分片，并且每个分片拥有所在节点的全部资源。主分片的数目在索引创建时就已经确定了下来。实际上，这个数目定义了这个索引能够 存储 的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作——搜索和返回数据——可以同时被主分片 或 副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群</code></pre><ul><li>调整副本数量</li></ul><pre><code class="textmate">PUT /blogs/_settings&#123;   &quot;number_of_replicas&quot; : 2&#125;</code></pre><h3 id="故障转移-1"><a href="#故障转移-1" class="headerlink" title="故障转移"></a>故障转移</h3><pre><code class="textmate">| Node1 | Node2 | Node3 ||1* 2 3 |1 2*  3|1 2 3* |*代表主分片如果关闭Node1,则会失去1主分片，索引不能正常工作，此时集群状态是red;其他节点会立即将Node2或Node3上的副本分片提升为主分片，此时集群状态是yellow,该动作是瞬时发生的；如果重启Node1,集群可以将缺失的副本分片再次进行分配，如果Node1依然拥有之前的分片，则会尝试重用，仅从主分片复制改动过的数据文件</code></pre><h2 id="数据输入输出"><a href="#数据输入输出" class="headerlink" title="数据输入输出"></a>数据输入输出</h2><blockquote><p>在 Elasticsearch 中， 每个字段的所有数据 都是 默认被索引的 。 即每个字段都有为了快速检索设置的专用倒排索引</p></blockquote><h3 id="什么是文档"><a href="#什么是文档" class="headerlink" title="什么是文档"></a>什么是文档</h3><pre><code class="textmate">在 Elasticsearch 中，术语 文档 有着特定的含义。它是指最顶层或者根对象, 这个根对象被序列化成 JSON 并存储到 Elasticsearch 中，指定了唯一 ID;字段的名字可以是任何合法的字符串，但 不可以 包含英文句号(.)。</code></pre><h3 id="文档元数据"><a href="#文档元数据" class="headerlink" title="文档元数据"></a>文档元数据</h3><pre><code class="textmate">三个必须的元数据元素：  _index: 文档在哪存放  _type: 文档表示的对象类别  _id: 文档唯一标识</code></pre><h3 id="索引文档"><a href="#索引文档" class="headerlink" title="索引文档"></a>索引文档</h3><pre><code class="textmate">// 创建文档时使用自定义IDPUT /website/blog/123&#123;  &quot;title&quot;: &quot;My first blog entry&quot;,  &quot;text&quot;:  &quot;Just trying this out...&quot;,  &quot;date&quot;:  &quot;2014/01/01&quot;&#125;//创建文档时使用ES自动生成的IDPOST /website/blog/&#123;  &quot;title&quot;: &quot;My second blog entry&quot;,  &quot;text&quot;:  &quot;Still trying this out...&quot;,  &quot;date&quot;:  &quot;2014/01/01&quot;&#125;/**tips: 自动生成的 ID 是 URL-safe、 基于 Base64 编码且长度为20个字符的 GUID 字符串。 这些 GUID 字符串由可修改的 FlakeID 模式生成，这种模式允许多个节点并行生成唯一 ID ，且互相之间的冲突概率几乎为零。**/</code></pre><h3 id="处理冲突"><a href="#处理冲突" class="headerlink" title="处理冲突"></a>处理冲突</h3><pre><code class="textmate">乐观并发控制每个文档都有一个 _version （版本）号，当文档被修改时版本号递增。 Elasticsearch 使用这个 _version 号来确保变更以正确顺序得到执行。如果旧版本的文档在新版本之后到达，它可以被简单的忽略。</code></pre><h2 id="分布式文档存储"><a href="#分布式文档存储" class="headerlink" title="分布式文档存储"></a>分布式文档存储</h2><h3 id="路由一个文档到一个分片中"><a href="#路由一个文档到一个分片中" class="headerlink" title="路由一个文档到一个分片中"></a>路由一个文档到一个分片中</h3><pre><code class="textmate">计算公式：shard = hash(routing) % number_of_primary_shards(主分片的数量)routing是可变值，默认是文档的_id,也可以设置成一个自定义的值。这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。</code></pre><h3 id="主副分片交互"><a href="#主副分片交互" class="headerlink" title="主副分片交互"></a>主副分片交互</h3><pre><code class="textmate">我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。将所有的请求发送到 Node 1 ，我们将其称为 协调节点(coordinating node) 。tips:当发送请求的时候， 为了扩展负载，更好的做法是轮询集群中所有的节点。</code></pre><h3 id="新建、索引和删除文档时步骤"><a href="#新建、索引和删除文档时步骤" class="headerlink" title="新建、索引和删除文档时步骤"></a>新建、索引和删除文档时步骤</h3><pre><code class="textmate">以下是在主副分片和任何副本分片上面 成功新建，索引和删除文档所需要的步骤顺序：1.客户端向 Node 1 发送新建、索引或者删除请求。2.节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在 Node 3 上。3.Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。</code></pre><h3 id="查询文档步骤"><a href="#查询文档步骤" class="headerlink" title="查询文档步骤"></a>查询文档步骤</h3><pre><code class="textmate">以下是从主分片或者副本分片检索文档的步骤顺序：1、客户端向 Node 1 发送获取请求。2、节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node2。3、Node2将文档返回给 Node 1 ，然后将文档返回给客户端。在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。考虑到分页过深以及一次请求太多结果的情况，结果集在返回之前先进行排序。 但请记住一个请求经常跨越多个分片，每个分片都产生自己的排序结果，这些结果需要进行集中排序以保证整体顺序是正确的。深度分页问题: 在分布式系统中，对结果排序的成本随分页的深度成指数上升。这就是 web 搜索引擎对任何查询都不要返回超过 1000 个结果的原因。</code></pre><h3 id="更新局部文档步骤"><a href="#更新局部文档步骤" class="headerlink" title="更新局部文档步骤"></a>更新局部文档步骤</h3><pre><code class="textmate">以下是部分更新一个文档的步骤：1.客户端向 Node 1 发送更新请求。2.它将请求转发到主分片所在的 Node 3 。3.Node 3 从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。 如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。4.如果 Node 3 成功地更新文档，它将新版本的文档并行转发到 Node 1 和 Node 2 上的副本分片，重新建立索引。 一旦所有副本分片都返回成功， Node 3 向协调节点也返回成功，协调节点向客户端返回成功。ps: 当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果Elasticsearch仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。</code></pre><h2 id="分片内部原理"><a href="#分片内部原理" class="headerlink" title="分片内部原理"></a>分片内部原理</h2><h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><pre><code class="textmate">倒排索引被写入磁盘后是 不可改变 的:它永远不会修改。 不变性有重要的价值：1.不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。2.一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。3.其它缓存(像filter缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。4.写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和 需要被缓存到内存的索引的使用量。当然，一个不变的索引也有不好的地方。主要事实是它是不可变的! 你不能修改它。如果你需要让一个新的文档 可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制。</code></pre><h3 id="索引与分片的比较"><a href="#索引与分片的比较" class="headerlink" title="索引与分片的比较"></a>索引与分片的比较</h3><pre><code class="textmate">一个 Lucene 索引 我们在 Elasticsearch 称作 分片 。 一个 Elasticsearch 索引 是分片的集合。 当 Elasticsearch 在索引中搜索的时候， 他发送查询到每一个属于索引的分片(Lucene 索引)，然后像 执行分布式检索 提到的那样，合并每个分片的结果到一个全局的结果集。</code></pre><h3 id="删除和更新"><a href="#删除和更新" class="headerlink" title="删除和更新"></a>删除和更新</h3><pre><code class="textmate">当一个文档被 “删除” 时，它实际上只是在 .del 文件中被 标记 删除。一个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。文档更新也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。 可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。</code></pre><h3 id="持久化变更"><a href="#持久化变更" class="headerlink" title="持久化变更"></a>持久化变更</h3><pre><code class="textmate">Elasticsearch 增加了一个 translog(事务日志)，在每一次对 Elasticsearch 进行操作时均进行了日志记录1.一个文档被索引之后，就会被添加到内存缓冲区，并且 追加到了 translog 2.刷新（refresh）, 缓存被清空但是事务日志不会3.事务日志持续积累文档4.每隔一段时间—例如 translog 变得越来越大，索引被刷新（flush）；一个新的 translog 被创建，并且一个全量提交被执行    4.1所有在内存缓冲区的文档都被写入一个新的段。  4.2缓冲区被清空。  4.3一个提交点被写入硬盘。  4.4文件系统缓存通过 fsync 被刷新（flush）。  4.5老的 translog 被删除。</code></pre><h3 id="Translog安全性"><a href="#Translog安全性" class="headerlink" title="Translog安全性"></a>Translog安全性</h3><pre><code class="textmate">在文件被 fsync 到磁盘前，被写入的文件在重启之后就会丢失。默认 translog 是每 5 秒被 fsync 刷新到硬盘， 或者在每次写请求完成之后执行(e.g. index, delete, update, bulk)。这个过程在主分片和复制分片都会发生。最终， 基本上，这意味着在整个请求被 fsync 到主分片和复制分片的translog之前，你的客户端不会得到一个 200 OK 响应。在每次请求后都执行一个 fsync 会带来一些性能损失，尽管实践表明这种损失相对较小（特别是bulk导入，它在一次请求中平摊了大量文档的开销）。但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync 还是比较有益的。比如，写入的数据被缓存到内存中，再每5秒执行一次 fsync 。这个行为可以通过设置 durability 参数为 async 来启用：PUT /my_index/_settings&#123;    &quot;index.translog.durability&quot;: &quot;async&quot;,    &quot;index.translog.sync_interval&quot;: &quot;5s&quot;&#125;这个选项可以针对索引单独设置，并且可以动态进行修改。如果你决定使用异步 translog 的话，你需要 保证 在发生crash时，丢失掉 sync_interval 时间段的数据也无所谓。</code></pre><h3 id="刷新"><a href="#刷新" class="headerlink" title="刷新"></a>刷新</h3><pre><code class="textmate">在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 refresh 。 默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是 近 实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。// 手动刷新数据 POST /_refresh  //刷新所有索引POST /blogs/_refresh  //只刷新blogs索引</code></pre><h3 id="段合并"><a href="#段合并" class="headerlink" title="段合并"></a>段合并</h3><pre><code class="textmate">目的：    由于自动刷新流程每秒会创建一个新的段 ，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。 每一个段都会消耗文件句柄、内存和cpu运行周期。更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。    Elasticsearch通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。流程：  1.当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。  2.合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。  3.合并结束，老的段被删除tips:合并大的段需要消耗大量的I/O和CPU资源，默认下会对合并流程进行资源限制optimeze API(强制合并)介绍: optimize API大可看做是 强制合并 API。它会将一个分片强制合并到 max_num_segments 参数指定大小的段数目。 这样做的意图是减少段的数量（通常减少到一个），来提升搜索性能。tips:     1.optimize API 不应该 被用在一个活跃的索引————一个正积极更新的索引。后台合并流程已经可以很好地完成工作。    2.使用 optimize API 触发段合并的操作不会受到任何资源上的限制。这可能会消耗掉你节点上全部的I/O资源</code></pre><h2 id="常用查找语法"><a href="#常用查找语法" class="headerlink" title="常用查找语法"></a>常用查找语法</h2><h3 id="精确查找-包含，不是等于"><a href="#精确查找-包含，不是等于" class="headerlink" title="精确查找(包含，不是等于)"></a>精确查找(包含，不是等于)</h3><pre><code class="textmate">//term查数字GET /my_store/products/_search&#123;    &quot;query&quot; : &#123;        &quot;constant_score&quot; : &#123;             &quot;filter&quot; : &#123;                &quot;term&quot; : &#123;                     &quot;price&quot; : 20                &#125;            &#125;        &#125;    &#125;&#125;//term查文本原词可能会被分词,构建索引时，需要指定不分析值&quot;index&quot; : &quot;not_analyzed&quot; //terms匹配多个内容    //运行非评分查询(精确查询)时的步骤1.查找匹配文档2.创建bitset(一个包含 0 和 1 的数组），它描述了哪个文档会包含该 term 3.迭代bitsets4.增量计数</code></pre><h3 id="组合过滤器"><a href="#组合过滤器" class="headerlink" title="组合过滤器"></a>组合过滤器</h3><ul><li>布尔过滤器</li></ul><pre><code class="textmate">&#123;   &quot;bool&quot; : &#123;      &quot;must&quot; :     [],  //相当于and      &quot;should&quot; :   [],  //相当于or      &quot;must_not&quot; : [],  //相当于not   &#125;&#125;</code></pre><h3 id="范围"><a href="#范围" class="headerlink" title="范围"></a>范围</h3><pre><code class="textmate">&quot;range&quot; : &#123;    &quot;price&quot; : &#123;        &quot;gte&quot; : 20,        &quot;lte&quot; : 40    &#125;&#125;/**  gt: &gt; 大于（greater than）  lt: &lt; 小于（less than）  gte: &gt;= 大于或等于（greater than or equal to）  lte: &lt;= 小于或等于（less than or equal to）**/// 特殊用法//1.时间计算： 查找时间戳在过去一小时内的所有文档&quot;range&quot; : &#123;    &quot;timestamp&quot; : &#123;        &quot;gt&quot; : &quot;now-1h&quot;    &#125;&#125;&quot;range&quot; : &#123;    &quot;timestamp&quot; : &#123;        &quot;gt&quot; : &quot;2014-01-01 00:00:00&quot;,        &quot;lt&quot; : &quot;2014-01-01 00:00:00||+1M&quot;  //早于2014年1月1日加1月（2014年2月1日零时）    &#125;&#125;//2.字符串范围(效率较低)&quot;range&quot; : &#123;    &quot;title&quot; : &#123;        &quot;gte&quot; : &quot;a&quot;,        &quot;lt&quot; :  &quot;b&quot;    &#125;&#125;</code></pre><h3 id="Null值查询"><a href="#Null值查询" class="headerlink" title="Null值查询"></a>Null值查询</h3><pre><code class="textmate">// 存在查询 existGET /my_index/posts/_search&#123;    &quot;query&quot; : &#123;        &quot;constant_score&quot; : &#123;            &quot;filter&quot; : &#123;                &quot;exists&quot; : &#123; &quot;field&quot; : &quot;tags&quot; &#125;            &#125;        &#125;    &#125;&#125;//不存在查询GET /my_index/posts/_search&#123;    &quot;query&quot; : &#123;        &quot;constant_score&quot; : &#123;            &quot;filter&quot;: &#123;                &quot;missing&quot; : &#123; &quot;field&quot; : &quot;tags&quot; &#125;            &#125;        &#125;    &#125;&#125;//对象的存在与不存在 //如果 first 和 last 都是空，那么 name 这个命名空间才会被认为不存在。&#123;  //对象数据   &quot;name&quot; : &#123;      &quot;first&quot; : &quot;John&quot;,      &quot;last&quot; :  &quot;Smith&quot;   &#125;&#125;&#123; //查询语句    &quot;exists&quot; : &#123; &quot;field&quot; : &quot;name&quot; &#125;&#125;&#123; //实际执行的语句    &quot;bool&quot;: &#123;        &quot;should&quot;: [            &#123; &quot;exists&quot;: &#123; &quot;field&quot;: &quot;name.first&quot; &#125;&#125;,            &#123; &quot;exists&quot;: &#123; &quot;field&quot;: &quot;name.last&quot; &#125;&#125;        ]    &#125;&#125;</code></pre><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><pre><code class="textmate">自动缓存Elasticsearch 会基于使用频次自动缓存查询。如果一个非评分查询在最近的 256 次查询中被使用过（次数取决于查询类型），那么这个查询就会作为缓存的候选。但是，并不是所有的片段都能保证缓存 bitset 。只有那些文档数量超过 10,000 （或超过总文档数量的 3% )才会缓存 bitset 。因为小的片段可以很快的进行搜索和合并，这里缓存的意义不大。一旦缓存了，非评分计算的 bitset 会一直驻留在缓存中直到它被剔除。剔除规则是基于 LRU 的：一旦缓存满了，最近最少使用的过滤器会被剔除。</code></pre><h2 id="相关度"><a href="#相关度" class="headerlink" title="相关度"></a>相关度</h2><h3 id="相关度评分逻辑"><a href="#相关度评分逻辑" class="headerlink" title="相关度评分逻辑"></a>相关度评分逻辑</h3><pre><code class="textmate">Lucene（或 Elasticsearch）使用 布尔模型（Boolean model） 查找匹配文档，并用一个名为 实用评分函数（practical scoring function） 的公式来计算相关度。这个公式借鉴了 词频/逆向文档频率（term frequency/inverse document frequency） 和 向量空间模型（vector space model），同时也加入了一些现代的新特性，如协调因子（coordination factor），字段长度归一化（field length normalization），以及词或查询语句权重提升。</code></pre><h4 id="布尔模型"><a href="#布尔模型" class="headerlink" title="布尔模型"></a>布尔模型</h4><pre><code class="textmate">布尔模型（Boolean Model）只是在查询中使用 AND、OR 和 NOT（与、或和非）这样的条件来查找匹配的文档，以下查询：full AND text AND search AND (elasticsearch OR lucene)会将所有包括词 full 、 text 和 search ，以及 elasticsearch 或 lucene 的文档作为结果集。</code></pre><h4 id="词频-逆向文档频率-TF-IDF"><a href="#词频-逆向文档频率-TF-IDF" class="headerlink" title="词频/逆向文档频率(TF/IDF)"></a>词频/逆向文档频率(TF/IDF)</h4><pre><code class="textmate">当匹配到一组文档后，需要根据相关度排序这些文档，不是所有的文档都包含所有词，有些词比其他的词更重要。一个文档的相关度评分部分取决于每个查询词在文档中的 权重 。词频词在文档中出现的频度越高，权重越高 。逆向文档频率词在集合所有文档里出现的频次越高，权重越低 </code></pre><h4 id="字段长度归一"><a href="#字段长度归一" class="headerlink" title="字段长度归一"></a>字段长度归一</h4><pre><code class="textmate">字段的长度越短，字段的权重越高。字段长度归一值(norm)</code></pre><h4 id="组合使用"><a href="#组合使用" class="headerlink" title="组合使用"></a>组合使用</h4><pre><code class="textmate">词频（term frequency）、逆向文档频率（inverse document frequency）和字段长度归一值（field-length norm）——是在索引时计算并存储的。最后将它们结合在一起计算单个词在特定文档中的权重 。</code></pre><h3 id="脚本评分"><a href="#脚本评分" class="headerlink" title="脚本评分"></a>脚本评分</h3><pre><code class="textmate">如果所有 function_score 内置的函数都无法满足应用场景，可以使用 script_score 函数自行实现逻辑Elasticsearch 里使用 Groovy 作为默认的脚本语言例子:入参:     price和margin变量可以分别从文档中提取    threshold、discount、target是作为参数params传入的GET /_search&#123;  &quot;function_score&quot;: &#123;    &quot;functions&quot;: [      &#123; ...location clause... &#125;,       &#123; ...price clause... &#125;,       &#123;        &quot;script_score&quot;: &#123;          &quot;params&quot;: &#123;             &quot;threshold&quot;: 80,            &quot;discount&quot;: 0.1,            &quot;target&quot;: 10          &#125;,          &quot;script&quot;: &quot;price  = doc[&#39;price&#39;].value; margin = doc[&#39;margin&#39;].value;          if (price &lt; threshold) &#123; return price * margin / target &#125;;          return price * (1 - discount) * margin / target;&quot;         &#125;      &#125;    ]  &#125;&#125;tips:   1.将这些变量作为参数 params 传递，我们可以查询时动态改变脚本无须重新编译。  2.JSON 不能接受内嵌的换行符，脚本中的换行符可以用 \n 或 ; 符号替代</code></pre><h2 id="人类语言处理"><a href="#人类语言处理" class="headerlink" title="人类语言处理"></a>人类语言处理</h2><pre><code class="textmate">分词器  standard(标准分词器)、english(英文分词器)、icu(亚洲语言分词器)错误拼写匹配-语音匹配    搜索发音相似的词，即使他们的拼写不同。 Soundex算法</code></pre><h2 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h2><h3 id="主要概念"><a href="#主要概念" class="headerlink" title="主要概念"></a>主要概念</h3><pre><code class="textmate">桶（Buckets）    满足特定条件的文档的集合指标（Metrics）    对桶内的文档进行统计计算每个聚合都是一个或者多个桶和零个或者多个指标的组合桶在概念上类似于 SQL 的分组（GROUP BY），而指标则类似于 COUNT() 、 SUM() 、 MAX() 等统计方法。例：SELECT COUNT(color)  FROM table GROUP BY color;1.COUNT(color) 相当于指标。2.GROUP BY color 相当于桶。</code></pre><h3 id="桶"><a href="#桶" class="headerlink" title="桶"></a>桶</h3><pre><code class="textmate">桶 简单来说就是满足特定条件的文档的集合1.当聚合开始被执行，每个文档里面的值通过计算来决定符合哪个桶的条件。如果匹配到，文档将放入相应的桶并接着进行聚合操作。2.桶也可以被嵌套在其他桶里面，提供层次化的或者有条件的划分方案。3.Elasticsearch 有很多种类型的桶，能让你通过很多种方式来划分文档（时间、最受欢迎的词、年龄区间、地理位置等等）。其实根本上都是通过同样的原理进行操作：基于条件来划分文档。</code></pre><h3 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h3><pre><code class="textmate">桶能让我们划分文档到有意义的集合，但是最终我们需要的是对这些桶内的文档进行一些指标的计算。分桶是一种达到目的的手段：它提供了一种给文档分组的方法来让我们可以计算感兴趣的指标。大多数 指标 是简单的数学运算（例如最小值、平均值、最大值，还有汇总），这些是通过文档的值来计算。在实践中，指标能让你计算像平均薪资、最高出售价格、95%的查询延迟这样的数据。聚合     由桶和指标组成的。 聚合可能只有一个桶，可能只有一个指标，或者可能两个都有。也有可能有一些桶嵌套在其他桶里面。</code></pre><h3 id="条形图"><a href="#条形图" class="headerlink" title="条形图"></a>条形图</h3><pre><code class="textmate">聚合还有一个令人激动的特性就是能够十分容易地将它们转换成图表和图形。例:GET /cars/transactions/_search&#123;   &quot;size&quot; : 0,   &quot;aggs&quot;:&#123;      &quot;price&quot;:&#123;         &quot;histogram&quot;:&#123;            &quot;field&quot;: &quot;price&quot;,            &quot;interval&quot;: 20000         &#125;,         &quot;aggs&quot;:&#123;            &quot;revenue&quot;: &#123;               &quot;sum&quot;: &#123;                  &quot;field&quot; : &quot;price&quot;               &#125;             &#125;         &#125;      &#125;   &#125;&#125;//响应结果-直方图&#123;...   &quot;aggregations&quot;: &#123;      &quot;price&quot;: &#123;         &quot;buckets&quot;: [            &#123;               &quot;key&quot;: 0,               &quot;doc_count&quot;: 3,               &quot;revenue&quot;: &#123;                  &quot;value&quot;: 37000               &#125;            &#125;,            &#123;               &quot;key&quot;: 20000,               &quot;doc_count&quot;: 4,               &quot;revenue&quot;: &#123;                  &quot;value&quot;: 95000               &#125;            &#125;         ]      &#125;   &#125;&#125;</code></pre><h3 id="按时间统计"><a href="#按时间统计" class="headerlink" title="按时间统计"></a>按时间统计</h3><pre><code class="textmate">//查询脚本GET /cars/transactions/_search&#123;   &quot;size&quot; : 0,   &quot;aggs&quot;: &#123;      &quot;sales&quot;: &#123;         &quot;date_histogram&quot;: &#123;            &quot;field&quot;: &quot;sold&quot;,            &quot;interval&quot;: &quot;month&quot;,             &quot;format&quot;: &quot;yyyy-MM-dd&quot;,               &quot;min_doc_count&quot; : 0,    //强制返回空 buckets。            &quot;extended_bounds&quot; : &#123;   //强制返回整年。                &quot;min&quot; : &quot;2014-01-01&quot;,                &quot;max&quot; : &quot;2014-12-31&quot;            &#125;         &#125;      &#125;   &#125;&#125;//返回结果&#123;   ...   &quot;aggregations&quot;: &#123;      &quot;sales&quot;: &#123;         &quot;buckets&quot;: [            &#123;               &quot;key_as_string&quot;: &quot;2014-01-01&quot;,               &quot;key&quot;: 1388534400000,               &quot;doc_count&quot;: 1            &#125;,            &#123;               &quot;key_as_string&quot;: &quot;2014-02-01&quot;,               &quot;key&quot;: 1391212800000,               &quot;doc_count&quot;: 1            &#125;         ]...&#125;</code></pre><h3 id="Doc-Values"><a href="#Doc-Values" class="headerlink" title="Doc Values"></a>Doc Values</h3><pre><code class="textmate">1.聚合使用一个叫 doc values 的数据结构。Doc values 可以使聚合更快、更高效并且内存友好2.Doc values 的存在是因为倒排索引只对某些操作是高效的。 倒排索引的优势 在于查找包含某个项的文档，而对于从另外一个方向的相反操作并不高效，即：确定哪些项是否存在单个文档里，聚合需要这种次级的访问模式。3.Doc Values 是在索引时与 倒排索引 同时生成。也就是说 Doc Values 和 倒排索引 一样，基于 Segement 生成并且是不可变的。同时 Doc Values 和 倒排索引 一样序列化到磁盘，这样对性能和扩展性有很大帮助。Doc Values 通过序列化把数据结构持久化到磁盘，我们可以充分利用操作系统的内存，而不是 JVM 的 Heap 。 当 working set 远小于系统的可用内存，系统会自动将 Doc Values 驻留在内存中，使得其读写十分快速；不过，当其远大于可用内存时，系统会根据需要从磁盘读取 Doc Values，然后选择性放到分页缓存中。原理:    Doc values 通过转置两者间的关系来解决这个问题。倒排索引将词项映射到包含它们的文档，doc values 将文档映射到它们包含的词项用途:Doc values 不仅可以用于聚合。 任何需要查找某个文档包含的值的操作都必须使用它。 除了聚合，还包括排序，访问字段值的脚本，父子关系处理</code></pre><h2 id="地理位置"><a href="#地理位置" class="headerlink" title="地理位置"></a>地理位置</h2><pre><code class="textmate">Elasticsearch 提供了 两种表示地理位置的方式：1.用纬度－经度表示的坐标点使用 geo_point 字段类型2.用GeoJSON 格式定义的复杂地理形状，使用 geo_shape 字段类型。Geo-points 允许你找到距离另一个坐标点一定范围内的坐标点、计算出两点之间的距离来排序或进行相关性打分、或者聚合到显示在地图上的一个网格。另一方面，Geo-shapes 纯粹是用来过滤的。它们可以用来判断两个地理形状是否有重合或者某个地理形状是否完全包含了其他地理形状。Geohashes 是一种将经纬度坐标（ lat/lon ）编码成字符串的方式。这么做的初衷只是为了让地理位置在 url 上呈现的形式更加友好，但现在 geohashes 已经变成一种在数据库中有效索引地理坐标点和地理形状的方式。Geohashes 把整个世界分为 32 个单元的格子 —— 4 行 8 列 —— 每一个格子都用一个字母或者数字标识。</code></pre><h2 id="数据建模"><a href="#数据建模" class="headerlink" title="数据建模"></a>数据建模</h2><pre><code class="textmate">Elasticsearch建模    关联关系处理 、 嵌套对象 和 父-子关系文档 另外ES支持多种扩容方式</code></pre><h2 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h2><pre><code class="textmate">支持动态更新的参数https://www.elastic.co/guide/en/elasticsearch/reference/5.6/cluster-update-settings.html集群备份、快照恢复</code></pre>]]></content>
      
      
      <categories>
          
          <category> 存储 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> es </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大话数据结构-摘要</title>
      <link href="2022/01/13/backend/java/algorithm/book1/"/>
      <url>2022/01/13/backend/java/algorithm/book1/</url>
      
        <content type="html"><![CDATA[<h2 id="大话数据结构-摘要"><a href="#大话数据结构-摘要" class="headerlink" title="大话数据结构-摘要"></a>大话数据结构-摘要</h2><blockquote><p>阅读《大话数据结构》一书，总结下来一些东西；总结的比较粗，部分思想暂时理解不了，先放一放，后面通过学习其他的东西后，再回过头来消化这些知识点</p></blockquote><h3 id="1、数据结构"><a href="#1、数据结构" class="headerlink" title="1、数据结构"></a>1、数据结构</h3><blockquote><p>数据结构是相互之间存在一种或多种特定关系的数据元素的集合</p></blockquote><h4 id="数据的逻辑结构"><a href="#数据的逻辑结构" class="headerlink" title="数据的逻辑结构"></a>数据的逻辑结构</h4><p>1.集合结构<br>属于同一集合，元素平等<br>2.线性结构<br>元素一对一<br>3.树状结构<br>元素一对多的层次关系<br>4.图状结构<br>元素多对多</p><h4 id="数据的物理结构"><a href="#数据的物理结构" class="headerlink" title="数据的物理结构"></a>数据的物理结构</h4><p>1.顺序存储<br>元素存放在地址连续的存储单元，数据逻辑关系与物理关系一致<br>2.链式结构<br>把数据存在任务任意的 存储单元中，地址连不连续都可以；通过指针找到相关联的数据位置</p><h3 id="2、时间算法复杂度"><a href="#2、时间算法复杂度" class="headerlink" title="2、时间算法复杂度"></a>2、时间算法复杂度</h3><h4 id="推导方法"><a href="#推导方法" class="headerlink" title="推导方法"></a>推导方法</h4><p>1.用常数1取代时间中的所有加法常数<br>2.修改的次函数中，只保留最高阶<br>3.如果最高阶存在且不是1，则去除与这个项相乘的常数。<br>得到的结果就是大O阶</p><ul><li>常数阶 O(1)</li></ul><pre><code class="textmate">int sum = 0,n=100; //执行一次sum = sum+n; //执行一次System.out.printf(sum); //执行一次O(1)</code></pre><ul><li>线性阶 O(n)</li><li>对数阶 Ologn</li><li>平方阶     O(n²)</li></ul><h3 id="3、线性表"><a href="#3、线性表" class="headerlink" title="3、线性表"></a>3、线性表</h3><ul><li>顺序存储结构</li></ul><pre><code class="textmate">存储位置连续，插入慢，查找快(下标查找)</code></pre><ul><li>链式存储结构<ul><li>单链表</li><li>静态链表</li><li>循环链表</li><li>双向循环链表</li></ul></li></ul><pre><code class="textmate">查找慢，插入删除块；空间换时间</code></pre><h3 id="4、栈与队列"><a href="#4、栈与队列" class="headerlink" title="4、栈与队列"></a>4、栈与队列</h3><ul><li>栈</li></ul><pre><code class="textmate">栈是限定仅在队尾进行插入和删除操作的线性表作用：递归应用：四则运算表达式求值(后缀表达式)</code></pre><ul><li>队列</li></ul><pre><code class="textmate">队列是只允许在一端进行插入操作，另一端进行删除操作的线性表</code></pre><h3 id="5、串"><a href="#5、串" class="headerlink" title="5、串"></a>5、串</h3><blockquote><p>串是由0个或多个字符组成的有限序列，又叫字符串</p></blockquote><ul><li>KMP匹配算法</li></ul><h3 id="6、树"><a href="#6、树" class="headerlink" title="6、树"></a>6、树</h3><ul><li><p>深度</p><pre><code class="textmate">树中节点的最大层次，称为树的深度或高度</code></pre></li><li><p>表示方法</p></li></ul><pre><code class="textmate">双亲表示法、孩子表示法、孩子兄弟表示法</code></pre><ul><li>二叉树</li></ul><pre><code class="textmate">1.每个节点最多有两颗子树，二叉树中不存在度大于2的节点2.左右字数是有顺序的，不能颠倒3.只有一颗子树，也要区分是左子树还是右子树五种基本形态    1.空二叉树    2.只有一个根节点    3.根节点只有左子树    4.根节点只有右子树    5.根节点既有左子树又有右子树</code></pre><ul><li>特殊二叉树</li></ul><pre><code class="textmate">1.斜树2.满二叉树(左右节点数量完全相等)3.完全二叉树(在某一层上，左右节点数量相等)</code></pre><ul><li>二叉树遍历方法</li></ul><pre><code class="textmate">1.前序       从根节点开始，先左边后右依次遍历2.中序    从最左边节点开始，先遍历根节点，后遍历右边节点3.后序    从最左边节点开始，先遍历右边节点，最后遍历根节点4.层序遍历    从根节点开始，逐层从左到右遍历</code></pre><img src="https://gitee.com/im-fan/fan-pic/raw/master/images/tree-first.png" alt="tree-first" style="zoom:30%;" /><img src="https://gitee.com/im-fan/fan-pic/raw/master/images/tree-middle.png" alt="tree-middle" style="zoom:33%;" /><img src="https://gitee.com/im-fan/fan-pic/raw/master/images/tree-last.png" alt="image-20220113103906997" style="zoom:31%;" /><img src="https://gitee.com/im-fan/fan-pic/raw/master/images/tree-level.png" alt="image-20220113103925951" style="zoom:33%;" /><ul><li><p>树的应用</p><pre><code class="textmate">赫夫曼树    带权路径长度WPL最小的二叉树称为赫夫曼树赫夫曼编码-压缩</code></pre></li></ul><h3 id="7、图-Graph"><a href="#7、图-Graph" class="headerlink" title="7、图-Graph"></a>7、图-Graph</h3><blockquote><p>图是由顶点的有穷非空集合的顶点之间边的集合组成，通常表示为： G(V,E), 其中G是一个图，V是图G中顶点的结婚，E是图G中边的集合</p></blockquote><h4 id="图中的一些定义"><a href="#图中的一些定义" class="headerlink" title="图中的一些定义"></a>图中的一些定义</h4><ul><li><p>图中数据元素称为顶点(Vertex)</p></li><li><p>图结构中，不允许没有顶点</p></li><li><p>图中任意两个顶点之间都有可能有关系，顶点之间的逻辑关系用边来表示，边集可以是空的</p></li><li><p>边的定义</p><pre><code class="textmate">无向边有向边</code></pre></li></ul><h3 id="8、查找"><a href="#8、查找" class="headerlink" title="8、查找"></a>8、查找</h3><h4 id="顺序表查找"><a href="#顺序表查找" class="headerlink" title="顺序表查找"></a>顺序表查找</h4><h4 id="有序表查找"><a href="#有序表查找" class="headerlink" title="有序表查找"></a>有序表查找</h4><ul><li>折半查找</li><li>插值查找</li><li>斐波那契查找</li></ul><h4 id="线性索引查找"><a href="#线性索引查找" class="headerlink" title="线性索引查找"></a>线性索引查找</h4><ul><li><p>稠密索引</p><pre><code class="textmate">稠密索引是指在线性索引中，将数据集中的每个记录对应一个索引项；例：记事本</code></pre></li><li><p>分块索引</p><pre><code class="textmate">块内无序，块间有序； 参考图书馆、档案馆存放书籍方式</code></pre></li><li><p>倒排索引</p><pre><code class="textmate">索引项通用结构：次关键码记录号表</code></pre></li></ul><h4 id="二叉排序树"><a href="#二叉排序树" class="headerlink" title="二叉排序树"></a>二叉排序树</h4><h4 id="平衡二叉树-AVL树"><a href="#平衡二叉树-AVL树" class="headerlink" title="平衡二叉树(AVL树)"></a>平衡二叉树(AVL树)</h4><pre><code class="textmate">构建思想: 每当插入一个节点时，先检查是否因插入而破坏了树的平衡性，若是，则找出最小不平衡子树。在保持二叉排序树特性的前提下，调整最小不平衡子树各节点之间的链接关系，进行相应旋转，使之成为新的平衡子树</code></pre><h4 id="多路查找树-B树"><a href="#多路查找树-B树" class="headerlink" title="多路查找树(B树)"></a>多路查找树(B树)</h4><h4 id="哈希表查找"><a href="#哈希表查找" class="headerlink" title="哈希表查找"></a>哈希表查找</h4><pre><code class="textmate">散列技术最适合的求解问题是查找与给定值相等的记录；但是无法查找最大值、最小值等结果散列函数的构造方法：    1.直接定址法    2.数字分析法    3.平方取中法    4.折叠法    5.除留余数法    6.随机数法处理散列冲突的方法：    1.开放定址法        解决冲突的开放定址法称为线性探测法        本来不是同义词却需要争夺同一个地址的情况，称为堆积        为了不让关键字都堆积在一个区域。采用二次探测法/随机探测法 重新计算地址    2.再散列函数法    3.链地址法    4.公共溢出区法</code></pre><h3 id="9、排序"><a href="#9、排序" class="headerlink" title="9、排序"></a>9、排序</h3><h4 id="排序分类"><a href="#排序分类" class="headerlink" title="排序分类"></a>排序分类</h4><pre><code class="textmate">根据在排序过程中待排序的记录是否全部被放置在内存中，排序分为:内排序和外排序内排序: 内排序是在排序的整个过程中，待排序的所有记录全部都被放置在内存中。外排序: 由于排序的记录个数太多，不能同时放置在内存，整个排序过程总需要在内外存之间多次交换数据才能进行内排序性能影响点：    1.时间性能    2.辅助空间    3.算法的复杂性内排序分为: 插入排序、交换排序、选择排序和归并排序</code></pre><h4 id="排序类型"><a href="#排序类型" class="headerlink" title="排序类型"></a>排序类型</h4><ul><li><a href="https://www.runoob.com/data-structures/heap-storage.html">菜鸟教程-数据结构</a></li></ul><pre><code class="textmate">冒泡排序、简单选择排序、直接插入排序、希尔排序、堆排序、归并排序、快速排序</code></pre><ul><li>快速排序！！！<ul><li>随机快排</li><li>双路快排</li><li>三路快排</li></ul></li></ul><h4 id="排序方法效率比较"><a href="#排序方法效率比较" class="headerlink" title="排序方法效率比较"></a>排序方法效率比较</h4><img src="https://gitee.com/im-fan/fan-pic/raw/master/images/sort-rank.png" alt="sort-rank" style="zoom:50%;" /><h3 id="结尾语"><a href="#结尾语" class="headerlink" title="结尾语"></a>结尾语</h3><ul><li>没有什么是不可能的，不要被条条框框限制住自己的思维</li><li>如果你有梦想的话，就要去捍卫它。当别人做不到，他们就想要告诉你，你也不能。如果你想要些什么。就努力去争取。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构与算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阅读</title>
      <link href="2022/01/13/thinking/year-end/"/>
      <url>2022/01/13/thinking/year-end/</url>
      
        <content type="html"><![CDATA[<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="2022"><a href="#2022" class="headerlink" title="2022"></a>2022</h3><h4 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h4><p>[ ] 找到一份稳定收入的副业<br>[ ] 坚持写文章<br>[ ] 出去旅游一次<br>[ ] 持续阅读<br>[ ] 买车</p><h3 id="2021"><a href="#2021" class="headerlink" title="2021"></a>2021</h3><h4 id="目标-1"><a href="#目标-1" class="headerlink" title="目标"></a>目标</h4><p>[√] 考PMP<br>[x] 找到一份稳定收入的副业<br>[x] 开始写文章<br>[x] 出去旅游一次<br>[√] 养成读书的习惯(技术、职业规划、思考、理财)<br>[√] 换一份工作</p><h4 id="完成情况"><a href="#完成情况" class="headerlink" title="完成情况"></a>完成情况</h4><pre><code class="textmate">    1.关于考证: 考PMP证一方面是为了看看自己是否有自制力，另一方面也是为了持续提升自己；通过学习掌握相关方法论，并    能提高自己在日常工作中的效率，提升整体项目组的主动性，促进项目成功；试试证明学习与实践中间还有比较大的差距，    还需不断学习、思考，将方法应用到具体项目中。    2.关于副业: 找一份副业的念头一直有，更近一步是让副业收入能支撑自己日常开销和房贷。疫情持续太久，未来方向不明，    行业危机四伏，为了给自己一份保障；虽然接了一个月的私活少赚了点，但是过程真的是心累；复盘过自身的资源，基本没啥资源。。。。     现在看貌似只有在知名网站上持续更新文章，看看有没有恰饭机会这样；过程中也学习了一些技能(PPT、简单视频剪辑)，    总体还是收获不小，虽然目标没达到，过程也是很好的    3.关于写文章: 更偏向记录,写文章是为了整理并记录自己学过的东西，好记性不如烂笔头，况且我的记忆力不是那么多好；除了经常用的东    西，其他知识点看完过一段时间就记忆就模糊了。为了不遗忘学过的东西，在学习过程中记录、摘要、总结一些东西沉淀下来，空闲了翻翻看看，强化记忆。    日积月累，感觉自己也要成为一个大牛了呢(终极目标)    4.工作到现在，真正算的上旅游的次数一只手就能数得过来；有时间就想去其他地方看看，看看沿途的风景、看看    当地的景色，给人生中留下一点不一样的记忆；原本打算一年至少出去一次吧，结果疫情反反复复，再加上各种事情，一拖再拖，结果一年过去了。。。     明年一定要完成这个目标！！！    5.关于读书: 约长大约觉得读书的重要性，相当于高手们把他们的大招和毕生绝学都告诉你了，你却视而不见，还    抱怨说这一路打怪升级咋这么难(个人观点)；我不限制自己读书的方向，觉得有兴趣就读，兴趣不大的慢慢读，没兴趣但是有用硬着头皮读；    读书为了提升技能、提高思考高度和深度、为了让能更加看清人生、生活、资本的本质    6.关于换工作: 如果干的开心、工资还不错的话，一般没有人想频繁的换工作吧？我很想在一个公司能长时间待下去，但总是因为各种原因不得不换工作；    虽然这份工作也不是那么的忙，还能每天和媳妇一起上下班(开心);无奈公司业务没啥起色，为了生计不想坐以待毙。从直属领导离职后就开始准备，    陆陆续续3-4个月面试了估计有十几家吧，公司有大有小，最心意的是某物，结果二面后没信了；后来同事介绍了个公司，综合看还不错就入职了，现在总体感受还不错    总之大目标就是健康、快乐的活着，顺便挣点钱养家</code></pre>]]></content>
      
      
      <categories>
          
          <category> 思考 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阅读</title>
      <link href="2022/01/10/thinking/tv/"/>
      <url>2022/01/10/thinking/tv/</url>
      
        <content type="html"><![CDATA[<h2 id="一些东西的摘要"><a href="#一些东西的摘要" class="headerlink" title="一些东西的摘要"></a>一些东西的摘要</h2><h2 id="资本的故事-第一季"><a href="#资本的故事-第一季" class="headerlink" title="资本的故事 第一季"></a>资本的故事 第一季</h2><h3 id="1-股份的力量"><a href="#1-股份的力量" class="headerlink" title="1.股份的力量"></a>1.股份的力量</h3><pre><code class="textmate">股份制可以融到更多的钱，扩大生产规模；同时也分摊了风险</code></pre><h3 id="2-泡沫的诱惑"><a href="#2-泡沫的诱惑" class="headerlink" title="2.泡沫的诱惑"></a>2.泡沫的诱惑</h3><pre><code class="textmate">郁金香引入后，由于作为身份和地位的象征，价格飙升，导致大量资金涌入郁金香市场；最终由于一个没有买家的传言，导致价格崩盘；郁金香泡沫后，郁金香价格趋势图频繁出现，常见于金融危机、A股危机中</code></pre><h3 id="3-南海骗局"><a href="#3-南海骗局" class="headerlink" title="3.南海骗局"></a>3.南海骗局</h3><pre><code class="textmate">曾经的商业巨头由于战争原因，后续无法盈利；用股票换国债，加上用股票贿赂主要决策人的方式通过了提案；后续真相暴露，推动了资本市场开始往华尔街转移</code></pre><h3 id="4-汉密尔顿的旋转门-华尔街之父"><a href="#4-汉密尔顿的旋转门-华尔街之父" class="headerlink" title="4.汉密尔顿的旋转门(华尔街之父)"></a>4.汉密尔顿的旋转门(华尔街之父)</h3><pre><code class="textmate">解释: 美国发行新货币、新债务、联邦信用替代州政府信用，达到统一货币、统一财政的目的作用: 构建了美国的信用货币和国债体系，是现代美国金融体系的两大支柱建立国家信用体系，并将国家信用直接转换为社会财富，促进经济增长引用： 信 国之宝也 --《左传》</code></pre><h3 id="5-梧桐树下的承诺"><a href="#5-梧桐树下的承诺" class="headerlink" title="5.梧桐树下的承诺"></a>5.梧桐树下的承诺</h3><pre><code class="textmate">背景: 初期股票市场信息不透明，私下交易，利用利害信息可以影响股价有人利用提前的值得利好消息，利用大量杠杆成为银行股票的持有者，结果贷款渠道被掌权者切断，导致第一次股市崩盘股票交易员在梧桐树下初步签订了关于股票交易的一些协议(行业的自律和交易的规则)，成为纽约股票交易所的起点引用: 不以规矩，不能成方圆 --孟子</code></pre><h3 id="6-给风险定价"><a href="#6-给风险定价" class="headerlink" title="6.给风险定价"></a>6.给风险定价</h3><pre><code class="textmate">期货，初期是从谷物期货交易开始，规避谷物价格不稳定带来的风险(戈登哈伯德)；市场监督机制出现，保证金交易制度出现    保证金交易和标准化合约，是芝加哥期货交易的两大发明，也是全球期货交易的基石</code></pre><h3 id="7-注水的股票"><a href="#7-注水的股票" class="headerlink" title="7.注水的股票"></a>7.注水的股票</h3><pre><code class="textmate">滥发股票导致交易市场混乱，催生了新的股票交易规则，遏制滥发股票</code></pre><h3 id="8-巨人的诞生"><a href="#8-巨人的诞生" class="headerlink" title="8.巨人的诞生"></a>8.巨人的诞生</h3><pre><code class="textmate">美国钢铁公司诞生，首家市值超过10亿美元的公司；通过整合美国钢铁制造业，提升美国刚铁制造业地位，垄断了美国钢铁行业；随后促进和行业整合浪潮，诞生了很多大公司引用: 相出新办法的人，在他的办法没有成功以前，人家总是说他异想天开 --马克吐温</code></pre><h3 id="9-镀金的美元"><a href="#9-镀金的美元" class="headerlink" title="9.镀金的美元"></a>9.镀金的美元</h3><pre><code class="textmate">构建一个全球性的货币金融体系，重要人物: 凯恩斯 布雷顿森林协议签订：各国货币与美元挂钩，年度汇率波动不超过10%;美元与黄金挂钩(35/盎司)  双挂钩后续由于美国随意增发货币，导致各国挤兑黄金，美国为了防止黄金被挤兑，颁布尼克松冲击(美元与黄金脱钩)，随后各国兑美元固定汇率改为浮动汇率；中东石油危机爆发，导致双挂钩失效</code></pre><h3 id="10-风险的价值"><a href="#10-风险的价值" class="headerlink" title="10.风险的价值"></a>10.风险的价值</h3><pre><code class="textmate">第一家风险投资公司诞生(多利奥特-风险投资之父)；纳斯达克成立，为风险投资提供了一条从进入到退出的产业链</code></pre><h3 id="11-日本泡沫"><a href="#11-日本泡沫" class="headerlink" title="11.日本泡沫"></a>11.日本泡沫</h3><pre><code class="textmate">快速升值的日元，带来楼市和股市的飞涨，资本逃离实体经济广场协议: 联合干预外汇市场，让美元对主要货币有序贬值；促进了日元的升值；日元升值导致投资人大量收购海外资产，对内投资楼市股市，泡沫逐渐产生 两个日本说法: 一个是低迷的本土资产，另一个是日本国民的海外资产不断向本土汇回收入</code></pre><h3 id="12-八佰伴倒闭"><a href="#12-八佰伴倒闭" class="headerlink" title="12.八佰伴倒闭"></a>12.八佰伴倒闭</h3><pre><code class="textmate">由于日元升值，大量购入海外固定资产开连锁超市；后期由于经济原因股价崩盘，需要偿还大量债务，最终导致破产；八佰伴腾飞到倒闭，伴随着日本经期泡沫的腾飞与破灭</code></pre><h3 id="13-门口的野蛮人"><a href="#13-门口的野蛮人" class="headerlink" title="13.门口的野蛮人"></a>13.门口的野蛮人</h3><pre><code class="textmate">黑色星期一导致纳斯维克公司股价暴跌，KKR打算联合另一公司收购纳斯维克，结果反被踢出局，诞生当时最大规模收购案；垃圾债券：已少量自有资金，外加拟收购目标的资产为抵押，大大降低了收购方的资金压力各路资本对公司控制权的争夺，却在争夺自身利益的同时，提升了公司的价值，此时的公司，已是一个可交易的商品 </code></pre><h3 id="14-英镑狙击战"><a href="#14-英镑狙击战" class="headerlink" title="14.英镑狙击战"></a>14.英镑狙击战</h3><pre><code class="textmate">索罗斯  对冲基金英镑兑马克(德国货币)采用固定汇率，索罗斯判断英镑价值被高估，做空英镑，导致英镑采用浮动利率</code></pre>]]></content>
      
      
      <categories>
          
          <category> 摘要 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 思维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>集成SwaggerUI</title>
      <link href="2021/11/25/backend/other/swagger/"/>
      <url>2021/11/25/backend/other/swagger/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://doc.xiaominfo.com/knife4j/documentation/">knife4j官网</a></li></ul><h3 id="集成步骤"><a href="#集成步骤" class="headerlink" title="集成步骤"></a>集成步骤</h3><ul><li><p>引入jar包</p><pre><code class="xml">&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;  &lt;version&gt;2.0.9&lt;/version&gt;&lt;/dependency&gt;</code></pre></li><li><p>添加配置类</p><pre><code class="java">/** * 注意knife版本号，如果是2.0.x* * **/@Configuration//@EnableSwagger2WebMvc //2.x版本用这个//@EnableOpenApi  //3.x版本用这个public class MySwagger &#123;  @Bean  public Docket createRestApi(Environment env) &#123;      //开发测试环境开启      Profiles profile = Profiles.of(&quot;local&quot;, &quot;dev&quot;, &quot;test&quot;);      boolean flag = env.acceptsProfiles(profile);      //2.x版本用 DocumentationType.SWAGGER_2      //3.x版本用 DocumentationType.OAS_30      return new Docket(DocumentationType.SWAGGER_2)              //分组名称              .groupName(&quot;2.X版本&quot;)              .apiInfo(apiInfo())              .enable(flag)              .pathMapping(&quot;/&quot;)              .select()              //这里指定Controller扫描包路径              .apis(RequestHandlerSelectors.basePackage(&quot;com.my.demo.web.controller&quot;))              .paths(PathSelectors.any())              .build();  &#125;  private ApiInfo apiInfo() &#123;      return new ApiInfoBuilder()              .title(&quot;服务名&quot;)              .version(&quot;2.0.0&quot;)              .description(&quot;描述&quot;)              .build();  &#125;&#125;</code></pre></li><li><p>常用注解</p></li></ul><pre><code class="textmate">1.Controller类注解    @Api(tags = &quot;Controller名&quot;)    @RestController    @RequestMapping(&quot;/请求路径&quot;)2.Controller中方法注解    @ApiOperation(value = &quot;方法名&quot;,notes = &quot;方法描述&quot;)    @GetMapping(&quot;/请求路径&quot;)    @PostMapping(&quot;/请求路径&quot;)3.Controller中方法入参注解    @RequestParam(value = &quot;入参&quot;,name = &quot;入参名称&quot;)    @RequestBody4.出参入参注解    @ApiModel(&quot;对象名称&quot;)    @ApiModelProperty(name = &quot;属性名&quot;)</code></pre><h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><ul><li>版本不兼容<pre><code class="textmate">&lt;!--swagger-ui 兼容性好的版本--&gt;&lt;dependency&gt;  &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;  &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;  &lt;version&gt;2.0.9&lt;/version&gt;  &lt;!-- 去掉不兼容的版本 --&gt;  &lt;exclusions&gt;      &lt;exclusion&gt;          &lt;artifactId&gt;spring-plugin-core&lt;/artifactId&gt;          &lt;groupId&gt;org.springframework.plugin&lt;/groupId&gt;      &lt;/exclusion&gt;  &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt;  &lt;groupId&gt;org.springframework.plugin&lt;/groupId&gt;  &lt;artifactId&gt;spring-plugin-core&lt;/artifactId&gt;  &lt;version&gt;2.0.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 接口文档 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 接口文档 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发相关</title>
      <link href="2021/11/22/backend/java/thread/concurrent/"/>
      <url>2021/11/22/backend/java/thread/concurrent/</url>
      
        <content type="html"><![CDATA[<h1 id="高并发相关"><a href="#高并发相关" class="headerlink" title="高并发相关"></a>高并发相关</h1><blockquote><p>高并发相关书籍总结文档</p></blockquote><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h4 id="进程的结构"><a href="#进程的结构" class="headerlink" title="进程的结构"></a>进程的结构</h4><blockquote><p>由程序段、数据端和进程控制块组成</p></blockquote><pre><code class="textmate">线程的大致结构线程描述信息、程序计数器和栈内存组成区别1.进程是进程代码段的一次顺序执行流程，一个进程有一个或多个线程组成2.线程是CPU调度最小单位；进项是操作系统分配资源的最小单位。3.线程从进程的内部演进而来。4.进程之间相互独立；进程中的各个线程不完全独立，共享进程的方法区内存、堆内存、系统资源等5.切换速度不同： 线程上下文切换比进程上下文切换速度快。</code></pre><h4 id="Java线程和OS线程关系"><a href="#Java线程和OS线程关系" class="headerlink" title="Java线程和OS线程关系"></a>Java线程和OS线程关系</h4><pre><code class="textmate">一对一模型，缺点是创建一个用户线程也要创建一个内核线程，开销大</code></pre><h4 id="Java线程底层实现"><a href="#Java线程底层实现" class="headerlink" title="Java线程底层实现"></a>Java线程底层实现</h4><pre><code class="textmate">Windows上采用Win32 API实现UNIX和Linux采用Pthread( POSIX标准的扩展，提供用户级或内核级库)</code></pre><h4 id="JDK创建Linux线程源码"><a href="#JDK创建Linux线程源码" class="headerlink" title="JDK创建Linux线程源码"></a>JDK创建Linux线程源码</h4><pre><code class="textmate">src/hotspot/os/linux/os_linux.cpp</code></pre><h4 id="创建线程的方式"><a href="#创建线程的方式" class="headerlink" title="创建线程的方式"></a>创建线程的方式</h4><pre><code class="textmate">Thread/Runnable/FutureTask/线程池(ThreadPoolExecutor)SynchronousQueued(同步队列)必须有take线程在阻塞等待，offer操作才能成功；否则会为新任务开一条新线程去执行关闭线程池方法shutdown/shutdownNow/awaitTermination</code></pre><h4 id="确定线程池的线程数"><a href="#确定线程池的线程数" class="headerlink" title="确定线程池的线程数"></a>确定线程池的线程数</h4><pre><code class="textmate">分类：IO密集型   最佳线程数 = CPU核心线程的2倍CPU密集型  最佳线程数 = CPU核心线程数量混合型     最佳线程数 = ((线程等待时间+线程 CPU 时间)/线程 CPU 时间 )* CPU 核数 = 最佳线程数目 =(线程等待时间与线程 CPU 时间之比 + 1)* CPU 核数</code></pre><h4 id="Java对象的三个部分"><a href="#Java对象的三个部分" class="headerlink" title="Java对象的三个部分"></a>Java对象的三个部分</h4><pre><code class="textmate">1.对象头对象头包括三个字段，Mark Word(标记字)，用于存储自身运行时的数据 例如 GC 标志位、哈希码、锁状态等信息。Class Pointer(类对象指针)，用于存放方法区 Class 对象的地址，虚拟机通 过这个指针来确定这个对象是哪个类的实例。Array Length(数组长度)。如果对象是一个 Java 数组，那么此字段必须有， 用于记录数组长度的数据;如果对象不是一个 Java 数组，那么此字段不存在，所以这是一个可选 字段。2.对象体对象体包含了对象的实例变量(成员变量)。用于成员属性值，包括父类的成员属性值。这 部分内存按 4 字节对齐。3.对齐字节对齐字节也叫做填充对齐，其作用是用来保证 Java 对象在所占内存字节数为 8 的倍数(8N bytes)。HotSpot VM 的内存管理要求对象起始地址必须是 8 字节的整数倍。对象头本身是 8 的 倍数，当对象的实例变量数据不是 8 的倍数，便需要填充数据来保证 8 字节的对齐。</code></pre><h4 id="对象结构中的核心字段作用"><a href="#对象结构中的核心字段作用" class="headerlink" title="对象结构中的核心字段作用"></a>对象结构中的核心字段作用</h4><pre><code class="textmate">(1)Mark Word(标记字)字段主要用来表示对象的线程锁状态，另外还可以用来配合 GC、 存放该对象的 hashCode。(2)Class Pointer(类对象指针)字段是一个指向方法区中 Class 信息的指针，意味着该对象 可随时知道自己是哪个 Class 的实例。(3)Array Length(数组长度)字段也占用 32 位(在 32 位 JVM 中)的字节，这是可选的， 只有当本对象是一个数组对象时才会有这个部分。(4)对象体用于保存对象属性值，是对象的主体部分，占用的内存空间大小取决于对象的属 性数量和类型。(5)对齐字节并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。当对象实 例数据部分没有对齐(8 字节的整数倍)时，就需要通过对齐填充来补全。</code></pre><h4 id="对象结构中的字段长度"><a href="#对象结构中的字段长度" class="headerlink" title="对象结构中的字段长度"></a>对象结构中的字段长度</h4><pre><code class="textmate">Mark Word、Class Pointer、Array Length 等字段的长度，都与 JVM 的位数有关。Mark Word 的长度为 JVM 的一个 Word(字)大小，也就是说 32 位 JVM 的 Mark Word 为 32 位，64 位 JVM 为 64 位。Class Pointer(类对象指针)字段的长度也为 JVM 的一个 Word(字)大小，即 32 位的 JVM为32位，64位的JVM为64位。所以，在 32 位 JVM 虚拟机中，Mark Word 和 Class Pointer 这两部分都是 32 位的;在 64 位 JVM 虚拟机中，Mark Word 和 Class Pointer 这两部分都是 64 位的。对于对象指针而言，如果 JVM 中对象数量过多，使用 64 位的指针将浪费大量内存，通过简 单统计，64 位的 JVM 将会比 32 位的 JVM 多耗费 50%的内存。为了节约内存可以使用选项 +UseCompressedOops 开启指针压缩。选项 UseCompressedOops 中的 Oop 部分为 Ordinary object pointer 普通对象指针的缩写。如果开启 UseCompressedOops 选项，以下类型的指针将从 64 位压缩至 32 位:1.Class 对象的属性指针(即静态变量)2.Object 对象的属性指针(即成员变量)3.普通对象数组的元素指针当然，也不是所有的指针都会压缩，一些特殊类型的指针不会压缩，比如指向 PermGen(永 久代)的 Class 对象指针(JDK8 中指向元空间的 Class 对象指针)、本地变量、堆栈元素、入参、返 回值和 NULL 指针等。</code></pre><h4 id="JOL"><a href="#JOL" class="headerlink" title="JOL"></a>JOL</h4><pre><code class="textmate">JOL 全称为 Java Object Layout，是分析 JVM 中对象的结构布局的工具，该工具大量使用了 Unsafe、JVMTI 来解码内部布局情况，其分析结果相对比较精准的。要使用 JOL 工具，先引入 Maven 的依赖坐标:&lt;!--Java Object Layout --&gt; &lt;dependency&gt;    &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt;     &lt;artifactId&gt;jol-core&lt;/artifactId&gt;     &lt;version&gt;0.11&lt;/version&gt;&lt;/dependency&gt;</code></pre><h4 id="锁分类"><a href="#锁分类" class="headerlink" title="锁分类"></a>锁分类</h4><blockquote><p>偏向锁、轻量级锁、重量级锁</p></blockquote><h4 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h4><pre><code class="textmate">偏向锁的核心原理是:    如果不存在线程竞争的一个线程获得了锁，那么锁就进入偏向状态， 此时 Mark Word 的结构变为偏向锁结构，锁对象的锁标志位(lock)被改为 01，偏向标志位 (biased_lock)被改为 1，然后线程的 ID 记录在锁对象的 Mark Word 中(使用 CAS 操作完成)以后该线程获取锁的时，判断一下线程 ID 和标志位，就可以直接进入同步块，连 CAS 操作都不 需要，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。偏向锁的主要作用:    消除无竞争情况下的同步原语，进一步提升程序性能，所在于没有锁竞 争的场合，偏向锁有很好的优化效果。但是，一旦有第二条线程需要竞争锁，那么偏向模式立即 结束，进入轻量级锁的状态。偏向锁的缺点:    如果锁对象时常被多条线程竞争，那偏向锁就是多余的，并且其撤销的过程 会带来一些性能开销。</code></pre><h4 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h4><pre><code class="textmate">轻量锁存在的目的是尽可能不用动用操作系统层面的互斥锁，因为那个性能会比较差，轻量级锁是一种自旋锁；轻量级锁主要有两种:    (1)普通自旋锁，        所谓普通自旋锁，就是指当有线程来竞争锁时，抢锁线程会在原地循环等待，而不是被阻塞，直到那个占有锁的线程释放锁之后，这个抢锁线程就可以马上获得锁的。默认情况下，自旋的次数为 10 次，用户可以通过-XX:PreBlockSpin 选项来进行更改。    (2)自适应自旋锁。        所谓自适应自旋锁，就是等待线程空循环的自旋次数并非是固定的，而是会动态着根据实际 情况来改变自旋等待的次数，自旋次数由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定JDK1.6 的轻量级锁使用的是普通自旋锁，且需要使用 -XX:+UseSpinning 选 项手工开启。JDK1.7 后，轻量级锁使用自适应自旋锁，JVM 启动时自动开启，且自 旋时间由 JVM 自动控制。</code></pre><h4 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h4><pre><code class="textmate">JVM 中每个对象都会有一个监视器，监视器和对象一起创建、销毁Monitor 是一种同步工具，也可以说是一种同步机制，主要特点是:(1)同步。    Monitor 所保护的临界区代码，是互斥的执行。一个 Monitor 是一个运行许可，任一个线程进入临界区代码都需要获得这个许可，离开时把许可归还。(2)协作。    Monitor 提供 Signal 机制:允许正持有许可的线程暂时放弃许可进入阻塞等待状 态，等待其他线程发送 Signal去唤醒;其他拥有许可的线程可以发送 Signal，唤醒正在阻塞等待 的线程，让它可以重新获得许可并启动执行。</code></pre><h4 id="三种内置锁的对比"><a href="#三种内置锁的对比" class="headerlink" title="三种内置锁的对比"></a>三种内置锁的对比</h4><table><thead><tr><th>锁</th><th>优点</th><th>缺点</th><th>适用场景</th></tr></thead><tbody><tr><td>偏向锁</td><td>加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距</td><td>如果线程间存在锁竞争，会带来额外的锁撤销的消耗</td><td>适用于只有一个线程访问 临界区场景</td></tr><tr><td>轻量级锁</td><td>竞争的线程不会阻塞，提高了程序的响应速度</td><td>抢不到锁的线程会CAS自旋等待，消耗CPU</td><td>锁占用时间短，吞吐量低</td></tr><tr><td>重量级锁</td><td>线程竞争不使用自旋，不会消耗CPU</td><td>线程阻塞，响应时间缓慢</td><td>锁占用时间较长，吞吐量高</td></tr></tbody></table><h4 id="线程通信"><a href="#线程通信" class="headerlink" title="线程通信"></a>线程通信</h4><pre><code class="textmate">定义:当多个线程共同操作共享的资源时，线程间通过某种方式互相告 知自己的状态，以避免无效的资源争夺。分类:等待-通知、共享内存、管道流。1.等待-通知    &quot;等待-通知&quot; 是Java中使用最为普遍的线程间通信方式，其最为经典的案例就是 “生产者-消费者”模式。2.共享内存    通过实现Runnable或内部类的形式，共享同一个变量3.管道通信就是使用java.io.PipedInputStream 和 java.io.PipedOutputStream进行通信wait 方法的原理:    首先 JVM 会释放当前线程的对象锁 Monitor 的 Owner 资格;其次 JVM 会 当前线程移入 Monitor 的 WaitSet 队列，而这些操作都和对象锁 Monitor 是相关的。    所以，wait 方法必须在 synchronized 同步块的内部使用。在当前线程执行 wait 方法前，必须 通过 synchronized 方法成为对象锁的 Monitor 的 Owner。notify 方法的原理:    JVM 从对象锁的 Monitor 的 WaitSet 队列，移动一条线程到其 EntryList 队列，这些操作都与对象锁的 Monitor 有关。    所以，notify 方法也必须在 synchronized 同步块的内部使用。在执行 notify 方法前，当前线 程也必须通过 synchronized 方法成为对象锁的 Monitor 的 Owner。</code></pre><h3 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h3><h4 id="ABA问题解决方案"><a href="#ABA问题解决方案" class="headerlink" title="ABA问题解决方案"></a>ABA问题解决方案</h4><pre><code class="textmate">AtomicStampedReference  compareAndSetAtomicMarkableReference       AtomicMarkableReference适用只要知道对象是否有被修改过，而不适用于对象被反复修改的 场景。</code></pre><h4 id="提高高并发场景下CAS操作性能"><a href="#提高高并发场景下CAS操作性能" class="headerlink" title="提高高并发场景下CAS操作性能"></a>提高高并发场景下CAS操作性能</h4><pre><code class="textmate">LongAdder 以空间换时间的方式提升高并发场景下 CAS 操作性能    LongAdder 的实现思路，与 ConcurrentHashMap 中分段锁基本原理非常相似，本质上，都是不同的线程在不同的单元上进行操作，这样减少了线程竞争，提高了并发效率</code></pre><h3 id="可见性和缓存一致性"><a href="#可见性和缓存一致性" class="headerlink" title="可见性和缓存一致性"></a>可见性和缓存一致性</h3><pre><code class="textmate">1. 总线锁    效率低，开销大2. 缓存锁     MESI 协议，保证缓存一致性     缓存一致性:缓存一致性机制就整体来说，是当某块CPU对缓存中的数据进行操作了之后， 就通知其他 CPU 放弃储存在它们内部的缓存，或者从主内存中重新读取    CPU 对 Cache 副 本如何与主存内容保持一致有几种写入方式可供选择，主要的写入方式有以下两种    1)Write-through(直写模式)  更新低一级缓存和存储器，数据写入速度慢    2)Write-back(回写模式)  只写入缓存，发现数据有变动，才将数据更新到存储器</code></pre><h4 id="MESI协议解释"><a href="#MESI协议解释" class="headerlink" title="MESI协议解释"></a>MESI协议解释</h4><pre><code class="textmate">M: 被修改(Modified)E: 独享的(Exclusive)S: 共享的(Shared)I: 无效的(Invalid)</code></pre><h4 id="指令重排"><a href="#指令重排" class="headerlink" title="指令重排"></a>指令重排</h4><pre><code class="textmate">As-if-Serial规则： 不管如何重排序，都必须保证代码在单线程下的运行正确。扩展:    JIT 是 Just In Time 的缩写, 也就是“即时编译器”。JVM 读入“.class” 文件的字 节码后，默认情况下是解释执行的。但是对于运行频率很高(如&gt;5000 次)的字节码， JVM 采用了 JIT 技术，将直接编译为机器指令，以提高性能。</code></pre><h4 id="硬件层面的内存屏障"><a href="#硬件层面的内存屏障" class="headerlink" title="硬件层面的内存屏障"></a>硬件层面的内存屏障</h4><pre><code class="texxtmate">1. 硬件层的内存屏障定义    内存屏障(Memory Barrier)又称内存栅栏(Memory Fences)，是让一个 CPU 高速缓存的内 存状态对其他 CPU 内核可见的一项技术，也是一项保障跨 CPU 内核有序执行指令的技术。    硬件层常用的内存屏障分为三种:读屏障(Load Barrier)、写屏障(Store Barrier)、全屏障 (Full Barrier)。2.作用    1).阻止屏障两侧的指令重排序    2).强制让高速缓存的数据失效</code></pre><h4 id="JMM-Java内存模型"><a href="#JMM-Java内存模型" class="headerlink" title="JMM(Java内存模型)"></a>JMM(Java内存模型)</h4><blockquote><p>JMM 并不像 JVM 内存结构一样是真实存在的运行实体，更多体现为一种规范和规则</p></blockquote><pre><code class="textmate">1.核心的价值在于解决可见性和有序性。2.JMM的另一大价值，在于能屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证最终的一致。Java 内存模型的规定:    (1)所有变量存储在主内存中。     (2)每个线程都有自己的工作内存，且对变量的操作都是在工作内存中进行。     (3)不同线程之间无法直接访问彼此工作内存中的变量，要想访问只能通过主内存来传递。volatile内存屏障操作    LoadLoad、LoadStore、StoreStore、StoreLoadHappens-Before(先行发生)规则</code></pre><h2 id="显式锁"><a href="#显式锁" class="headerlink" title="显式锁"></a>显式锁</h2><h3 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h3><pre><code class="textmate">Lock锁对比Java内置锁1.可中断获取锁2.可非阻塞获取锁3.可限时抢锁</code></pre><h3 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h3><pre><code class="textmate">1)“可重入”含义:表示该锁能够支持一个线程对资源的重复加锁，也就是说，一个线程 可以多次进入同一个锁所同步的临界区代码块。比如，同一线程在外层函数获得锁后，在内层函 数能再次获取该锁，甚至多次抢占到同一把锁。2)“独占”含义:在同一时刻只能有一个线程获取到锁，而其他获取锁的线程只能等待， 只有拥有锁的线程释放了锁后，其他的线程才能够获取锁。</code></pre><h3 id="Condition"><a href="#Condition" class="headerlink" title="Condition"></a>Condition</h3><blockquote><p> Lock代替了synchronized方法和语句的使用，而Condition代替了对象监视器方法的使用</p></blockquote><pre><code class="textmate">Condition实例本质上绑定到一个锁。要获取特定Lock实例的Condition实例，请使用其newCondition()方法。基于显示锁进行“等待-通知”方式的线程间通信接口Condition 的“等待-通知”方法和 Object 的“等待-通知”方法的语义等效关系为:    - Condition 类的 awiat 方法和 Object 类的 wait 方法等效。    - Condition 类的 signal 方法和 Object 类的 notify 方法等效。    - Condition 类的 signalAll 方法和 Object 类的 notifyAll 方法等效。Condition 对象的 signal(通知)方法和同一个对象的 await(等待)方法是一一配对使用的， 也就是说，一个 Condition 对象的 signal(或 signalAll)方法，不能去唤醒其他 Condition 对象上的 await 线程。</code></pre><h3 id="LockSupport"><a href="#LockSupport" class="headerlink" title="LockSupport"></a>LockSupport</h3><blockquote><p>LockSupport 是 JUC 提供的一线程阻塞与唤醒的工具类，该工具类可以让线程在任意位置阻 塞和唤醒，其所有的方法都是静态方法。</p></blockquote><ul><li><p>LockSupport.park()和 Thread.sleep()的区别</p><pre><code class="textmate">从功能上说，LockSupport.park()与 Thread.sleep()方法类似，都是让线程阻塞，二者的区别如下:(1)Thread.sleep()没法从外部唤醒，只能自己醒过来;而被LockSupport.park()方法阻塞的线程可以通过调用LockSupport.unpark()方法去唤醒。(2)Thread.sleep()方法声明了 InterruptedException 中断异常，这是一个受检异常，调用者需要捕获这个异常或者再抛出;而使用 LockSupport.park()方法时，不需要捕获中断异常。(3)LockSupport.park()方法、Thread.sleep()方法所阻塞的线程，当被阻塞线程的 Thread.interrup(t方法被调用时，被阻塞线程都会响应线程的中断信号，唤醒线程的执行。不同的是， 二者对中断信号的响应的方式不同。LockSupport.park( )方法不会抛出InterruptedException异常， 仅仅设置了线程的中断标志;而Thread.sleep()方法还会抛出InterruptedException 异常。(4)与 Thread.sleep()相比，使用 LockSupport.park()能更精准、更加灵活的阻塞、唤醒指定 线程。(5)Thread.sleep()本身就是一个 Native 方法;LockSupport.park()并不是一个 Native 方法，只是调用了一个Unsafe 类的Native方法(名字也叫 park)去实现。(6)LockSupport.park()方法还允许设置一个 Blocker 对象，主要用来给监视工具或诊断工具 确定线程受阻塞的原因。</code></pre></li><li><p>LockSupport.park( )与 Object.wait()的区别</p><pre><code class="textmate">LockSupport.park()与 Object.wait()方法也类似，都是让线程阻塞，二者的区别如下:(1)Object.wait()方法需要在synchronized块中执行;而LockSupport.park()可以在任意地方执行。(2)当被阻塞线程被中断时，Object.wait()方法抛出了中断异常，调用者需要捕获或者再抛出;当被阻塞线程被中断时，LockSupport.park()不会抛出异常，使用时不需要处理中断异常。(3)线程如果在Object.wait()执行之前去执行Object.notify()，会抛出 IllegalMonitorStateException异常，是不被允许的;而线程如果在LockSupport.park()执行之前去执行LockSupport.unPark()，不会抛出任何异常，是被允许的。</code></pre></li></ul><h3 id="显式锁分类"><a href="#显式锁分类" class="headerlink" title="显式锁分类"></a>显式锁分类</h3><pre><code class="textmate">1. 可重入锁与不可重入锁    可重入: 递归锁，同一个线程可重复获取当前对象的锁    不可重入: 同一时间，只有一个线程能持有对象的锁2. 悲观锁和乐观锁    悲观锁: 每次操作都会加锁    乐观锁: 基于AQS实现的锁都是乐观锁，操作不会加锁，采取在写时先读出当前版本号，然后加锁操作(失败则重复该操作)    悲观锁适用于写多读少的场景，遇到高并发写时性能高；乐观锁用于读多写少的情况3. 公平锁和非公平锁    公平锁就是保障了各个线程获取锁都是按照顺序来的，先到的线程先获取锁，抢锁成功的次序体现为 FIFO(先进先出)顺序4. 可中断锁和不可中断锁    在抢锁过程中能通过某些方法去终止抢占过程，那就是可中断锁，否则就是不可 中断锁。5. 共享锁和独占锁    “独占锁”指的是每次只能有一个线程能持有的锁。    “共享锁”允许多个线程同时获取锁，容许线程并发进入临界区。其他    CAS自旋锁可能会导致&quot;总线风暴&quot;，CLH 自旋锁(基于队列(具体为单向链表)排队的一种自旋锁),避免了总线风暴    AQS是CLH的一个变种</code></pre><h3 id="高并发设计模式"><a href="#高并发设计模式" class="headerlink" title="高并发设计模式"></a>高并发设计模式</h3><pre><code class="textmate">1.安全的单例模式2.Master-Worker模式3.ForkJoin模式4.生产者消费者模式5.Future模式</code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 高并发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>测试相关</title>
      <link href="2021/11/15/test/test/"/>
      <url>2021/11/15/test/test/</url>
      
        <content type="html"><![CDATA[<h3 id="后端测试工具"><a href="#后端测试工具" class="headerlink" title="后端测试工具"></a>后端测试工具</h3><ul><li>PostMan</li><li><a href="https://blog.csdn.net/weixin_43767015/article/details/104758415">JMH-性能优化测试(转)</a></li><li>Jmeter(接口测试)</li></ul><h3 id="移动端测试"><a href="#移动端测试" class="headerlink" title="移动端测试"></a>移动端测试</h3><ul><li>Charles(抓包)</li><li><a href="https://perfdog.qq.com/">Perfdog(软件性能)</a></li><li><a href="https://testerhome.com/topics/19832">Android专项测试工具</a></li><li>Monkey</li></ul>]]></content>
      
      
      <categories>
          
          <category> 测试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Arthas-问题排查工具</title>
      <link href="2021/10/13/devops/arthas/"/>
      <url>2021/10/13/devops/arthas/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><pre><code class="textmate">线上问题排查工具，无侵入；支持查看服务jvm信息、方法出入参数信息、接口耗时等</code></pre><h2 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h2><ul><li><a href="https://arthas.aliyun.com/doc/quick-start.html">官网</a></li><li><a href="https://github.com/alibaba/arthas/issues?q=label:user-case">用户案例</a></li><li><a href="https://github.com/alibaba/arthas/issues?utf8=%E2%9C%93&q=label:question-answered+">常见问题回答</a><h2 id="安装启动"><a href="#安装启动" class="headerlink" title="安装启动"></a>安装启动</h2>```textmate</li></ul><p>1.arthas-boot方式安装<br>curl -O <a href="https://arthas.aliyun.com/arthas-boot.jar">https://arthas.aliyun.com/arthas-boot.jar</a><br>java -jar arthas-boot.jar -h</p><p>-h: 打印帮助信息</p><pre><code>## 常用命令|命令名称|描述|示例||---|---|---||thread|查看当前线程信息，查看线程的堆栈|thread -n 3 指定最忙的前N个线程并打印堆栈&lt;br/&gt;thread -b 查找阻塞的线程||jvm|显示jvm信息|||watch|方法执行数据观测|watch com.xxx.xxService 方法名 -x 3 (参数遍历深度3，默认1)||trace|方法内部调用路径，并输出方法路径上的每个节点上耗时|trace com.xxx.xxService 方法名||stack|输出当前方法被调用的调用路径|stack com.xxx.xxService 方法名|## 完整命令介绍&gt; [完整命令详细文档](https://arthas.aliyun.com/doc/commands.html)|命令名称|描述|示例||---|---|---||help|显示arthas帮助| ||auth|验证当前会话| ||keymap|显示指定连接的所有可用键图。| ||sc|搜索JVM加载的所有类| ||sm|搜索JVM加载的类的方法| ||classloader|显示类加载器信息| ||jad|反编译类| ||getstatic|显示类的静态字段| ||monitor|监控方法执行统计数据，例如总/成功/失败计数，平均rt，失败率等。 |  ||stack|显示指定类和方法的堆栈跟踪| ||thread|显示线程信息，线程堆栈| ||trace|跟踪指定方法调用的执行时间。| ||watch|显示指定方法调用的输入/输出参数、返回对象和抛出异常 | ||tt|时间隧道| ||jvm|显示目标JVM信息| ||perfcounter|显示性能计数器信息。| ||ognl|执行ognl表达式。| ||mc|内存编译器，在内存中将java文件编译成字节码和类文件。| ||redefine|重新定义类。@see仪表# redefineClasses (ClassDefinition…) | ||retransform|使变回原形类。@see仪表# retransformClasses(类…) | ||dashboard|目标jvm的线程，内存，gc, vm, tomcat信息的概述。 | ||dump|从JVM中转储类字节数组| ||heapdump|堆转储| ||options|查看和改变各种阿尔萨斯选项| ||cls|清理屏幕信息| ||reset|重置所有增强类| ||version|显示arthas版本| ||session|显示当前会话信息| ||sysprop|显示和更改系统属性。| ||sysenv|显示系统env。| ||vmoption|显示和更新虚拟机诊断选项。| ||logger|打印记录器信息，并更新记录器级别| ||history|显示命令历史| ||cat|连接和打印文件| ||base64|使用Base64表示进行编码和解码| ||echo|将参数写入标准输出| ||pwd|返回工作目录名| ||mbean|显示mbean信息| ||grep|用于管道的Grep命令。| ||tee|tee命令用于管道。| ||profiler|异步分析器。https://github.com/jvm-profiling-tools/async-profiler| ||vmtool|jvm的工具| ||stop|停止/关闭Arthas服务器并退出控制台。| |</code></pre>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> arthas </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IO</title>
      <link href="2021/08/11/backend/java/netty/io/"/>
      <url>2021/08/11/backend/java/netty/io/</url>
      
        <content type="html"><![CDATA[<h3 id="IO模型"><a href="#IO模型" class="headerlink" title="IO模型"></a>IO模型</h3><table><thead><tr><th>类型</th><th>解释</th></tr></thead><tbody><tr><td>阻塞IO</td><td>返回数据就绪状态后，用户线程才能做其他动作</td></tr><tr><td>非阻塞IO</td><td>用户线程不断询问数据是否就绪</td></tr><tr><td>多路复用IO</td><td>即NIO(NewIO)  有一个线程不断去轮询多个 socket 的状态，只有当 socket 真正有读写事件时，才真正调用实际的 IO 读写操作，这个操作在内核中，比用户线程效率高<br/>缺点：一旦事件响应体很大，那么就会导致后续的事件迟迟得不到处理，并且会影响新的事件轮询。</td></tr><tr><td>信号驱动IO</td><td>当用户线程发起一个 IO 请求操作，会给对应的 socket 注册一个信号函数，然后用户线程会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到之后，在信号函数中调用 IO 读写操作来进行实际的 IO 请求操作</td></tr><tr><td>异步IO</td><td>最理想的IO模型  <br/>1.用户线程发起read操作，内核立即返回响应。<br/>2.内核接收到请求后，准备数据-&gt;copy至用户线程-&gt;给用户线程发信号<br/>比较：   信号驱动IO是需要client端调用函数操作IO，异步IO是内核异步处理，client端无需处理</td></tr></tbody></table><ul><li>多路复用IO</li></ul><pre><code class="textmate">IO多路复用模型的IO涉及两种系统调用，一种是IO操作的系统调用，另一种是select/epoll就绪查询系统调用。IO多路复用模型建立在操作系统的基础 设施之上，即操作系统的内核必须能够提供多路分离的系统调用select/epoll。优点:一个选择器查询线程，可以同时处理成千上万的网络连接， 所以，用户程序不必创建大量的线程，也不必维护这些线程，从而大大减小了系统的开 销。这是一个线程维护一个连接的阻塞IO模式相比，使用多路IO复用模型的最大优势。缺点:本质上，select/epoll系统调用是阻塞式的，属于同步IO。需要在读写事件就绪后，由系统调用本身负责进行读写，也就是说这个读写过程是阻塞 的</code></pre><h3 id="IO包"><a href="#IO包" class="headerlink" title="IO包"></a>IO包</h3><table><thead><tr><th>包名</th><th>类型/包</th><th>类名</th></tr></thead><tbody><tr><td>java.io</td><td>字节流</td><td>InputStream</td></tr><tr><td></td><td></td><td>OutputStream</td></tr><tr><td></td><td>字符流</td><td>Reader</td></tr><tr><td></td><td></td><td>Writer</td></tr><tr><td>java.nio</td><td>channels包</td><td></td></tr><tr><td>java.nio</td><td>charset包</td><td></td></tr><tr><td>java.nio</td><td>Buffer包</td><td></td></tr><tr><td>java.nio</td><td>ByteOrder</td><td></td></tr><tr><td>java.nio</td><td>MappedByteBuffer</td><td></td></tr></tbody></table><h3 id="文件句柄-文件描述符"><a href="#文件句柄-文件描述符" class="headerlink" title="文件句柄(文件描述符)"></a>文件句柄(文件描述符)</h3><ul><li><p>解释</p><pre><code class="textmate">文件句柄，也叫文件描述符。在Linux系统中，文件可分为:普通文件、目录文件、链 接文件和设备文件。文件描述符(File Descriptor)是内核为了高效管理已被打开的文件所 创建的索引，它是一个非负整数(通常是小整数)，用于指代被打开的文件。所有的IO系 统调用，包括socket的读写调用，都是通过文件描述符完成的。</code></pre></li><li><p>Linux的系统默认值为1024，需要解除文件句柄数的限制</p></li><li><p>调整步骤</p></li></ul><pre><code class="textmate">1.查看一个进程最大文件句柄数量  ulimit -n2.调整最大句柄数(当期会话有效)  ulimit -n 10000003.永久调整最大句柄数(root权限)    vim /etc/rc.local    添加  ulimit -SHn 1000000    解释: 选项-S表示软性极限值，-H表示硬性极限值。硬 性极限是实际的限制，就是最大可以是100万，不能再多了。软性极限值则是系统发出警告 (Warning)的极限值，超过这个极限值，内核会发出警告。4.终极解除Linux系统的最大文件打开数量的限制    vim /etc/security/limits.conf    添加         soft nofile 1000000        hard nofile 1000000    解释: soft nofile表示软性极限，hard nofile表示硬性极限。</code></pre><h3 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h3><h4 id="Java-NIO类库包含以下三个核心组件"><a href="#Java-NIO类库包含以下三个核心组件" class="headerlink" title="Java NIO类库包含以下三个核心组件"></a>Java NIO类库包含以下三个核心组件</h4><ul><li>Channel(通道)</li><li>Buffer(缓冲区)</li><li>Selector(选择器)</li></ul><h4 id="NIO与OIO-Old-IO-对比"><a href="#NIO与OIO-Old-IO-对比" class="headerlink" title="NIO与OIO(Old IO)对比"></a>NIO与OIO(Old IO)对比</h4><pre><code class="textmate">1)OIO是面向流(Stream Oriented)的，NIO是面向缓冲区(Buffer Oriented)的。 面向流:    在一般的OIO操作中，面向字节流或字符流的IO操作，总是以流式的方式顺序地从一个流(Stream)中读取一个或多个字节，因此，我们不能随意地改变读取指针的位置。面向缓冲区:    在NIO操作中则不同，NIO中引入了Channel(通道)和Buffer(缓冲区)的概念。面向缓冲 区的读取和写入，只需要从通道中读取数据到缓冲区中，或将数据从缓冲区中写入到通道 中。    NIO不像OIO那样是顺序操作，可以随意地读取Buffer中任意位置的数据。(2)OIO的操作是阻塞的，而NIO的操作是非阻塞的。    OIO操作都是阻塞的，例如，我们调用一个 read方法读取一个文件的内容，那么调用read的线程会被阻塞住，直到read操作完成。    而在NIO的非阻塞模式中，当我们调用read方法时，如果此时有数据，则read读取数据并返回;如果此时没有数据，则read也会直接返回，而不会阻塞当前线程。    NIO的非阻塞: NIO使用了通道和 通道的多路复用技术。(3)OIO没有选择器(Selector)概念，而NIO有选择器的概念。NIO的实现是基于底层的选择器的系统调用，所以NIO的需要底层操作系统提供支持。</code></pre><h4 id="通道-Channel"><a href="#通道-Channel" class="headerlink" title="通道(Channel)"></a>通道(Channel)</h4><pre><code class="textmate">OIO: InputStream、OutputStreamNIO: 向通道中写入数据，也可以从通道中读取数据</code></pre><h4 id="缓冲区-Buffer"><a href="#缓冲区-Buffer" class="headerlink" title="缓冲区(Buffer)"></a>缓冲区(Buffer)</h4><pre><code class="textmate">所谓通道的读取，就是将数据从通道读取到缓冲区中;所谓通道的写入，就是将 数据从缓冲区中写入到通道中。</code></pre><h3 id="选择器-Selector"><a href="#选择器-Selector" class="headerlink" title="选择器(Selector)"></a>选择器(Selector)</h3><pre><code class="textmate">Selector 选择器可以理解为一个IO事件的监听与查询 器。通过选择器，一个线程可以查询多个通道的IO事件的就绪状态</code></pre><h2 id="Buffer类"><a href="#Buffer类" class="headerlink" title="Buffer类"></a>Buffer类</h2><table><thead><tr><th align="center">属性</th><th>说明</th></tr></thead><tbody><tr><td align="center">capacity</td><td>容量，即可以容纳的最大数据量;在缓冲区创建时设置并且不能改变</td></tr><tr><td align="center">limit</td><td>上限，缓冲区中当前的数据量</td></tr><tr><td align="center">position</td><td>位置，缓冲区中下一个要被读或写的元素的索引</td></tr><tr><td align="center">mark</td><td>调用 mark()方法来设置 mark=position，再调用 reset()可以让 position 恢复到 mark 标记的位置，即 position=mark</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> io </category>
          
      </categories>
      
      
        <tags>
            
            <tag> io </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>集成Jimu报表</title>
      <link href="2021/08/04/backend/other/jimu-report/"/>
      <url>2021/08/04/backend/other/jimu-report/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="http://www.jimureport.com/">官网</a></li><li><a href="http://report.jeecg.com/2078875">官方文档</a></li></ul><h3 id="集成步骤"><a href="#集成步骤" class="headerlink" title="集成步骤"></a>集成步骤</h3><blockquote><p>见官网文档</p></blockquote><h3 id="集成时遇到的问题"><a href="#集成时遇到的问题" class="headerlink" title="集成时遇到的问题"></a>集成时遇到的问题</h3><ul><li>集成后启动报错，Unable to load cache item<blockquote><p><a href="https://docs.spring.io/spring-boot/docs/1.5.16.RELEASE/reference/html/using-boot-devtools.html">导致问题产生的原因</a></p></blockquote><pre><code class="textmate">解决方法: 去掉devtools即可</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 三方集成 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 三方集成 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringFramework源码学习</title>
      <link href="2021/07/26/backend/spring/framework/springframework-2/"/>
      <url>2021/07/26/backend/spring/framework/springframework-2/</url>
      
        <content type="html"><![CDATA[<h3 id="StartDemo"><a href="#StartDemo" class="headerlink" title="StartDemo"></a>StartDemo</h3><pre><code class="java">public class StartDemo &#123;   public static void main(String[] args) &#123;      ApplicationContext context =            new AnnotationConfigApplicationContext(&quot;com.my.config&quot;);      TestConfig testConfig = context.getBean(TestConfig.class);      System.out.println(&quot;==========&gt;main&quot;);      System.out.println(testConfig.getValue());   &#125;&#125;</code></pre><h3 id="关键类"><a href="#关键类" class="headerlink" title="关键类"></a>关键类</h3><ul><li>AnnotationConfigApplicationContext<pre><code class="textmate">根据包扫描对象</code></pre></li><li>RootBeanDefinition<pre><code class="textmate">记录扫描到的类的具体信息(描述类)</code></pre></li><li>BeanFactoryPostProcessor<pre><code class="textmate">接口，可自定义参与类初始化过程逻辑  工厂钩子，允许自定义修改应用程序上下文的 bean 定义，调整上下文底层 bean 工厂的 bean 属性值。  BeanFactoryPostProcessor是在spring容器加载了bean的定义文件之后，在bean实例化之前执行的。接口方法的入参是ConfigurrableListableBeanFactory，使用该参数，可以获取到相关bean的定义信息</code></pre></li><li>BeanPostProcessor<pre><code class="textmate">后置处理器父类，有很多子类；不同子类提供了不同的实现方法，参与到bean初始化过程中  例：AutowiredAnnotationBeanPostProcessor  可以在spring容器实例化bean之后，在执行bean的初始化方法前后，添加一些自己的处理逻辑。  BeanPostProcessor的执行顺序是在BeanFactoryPostProcessor之后。  内置实现:   org.springframework.context.annotation.CommonAnnotationBeanPostProcessor：支持@Resource注解的注入  org.springframework.beans.factory.annotation.RequiredAnnotationBeanPostProcessor：支持@Required注解的注入  org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor：支持@Autowired注解的注入</code></pre></li></ul><pre><code>### 简易流程```textmate生命周期 加载 -&gt; 实例化 -&gt; 初始化 -&gt; 使用 -&gt; 销毁scan -&gt; beanPorcessor(描述bean信息) -&gt; 放到 configMap 中 -&gt; refresh -&gt; 通过bean工厂实例化类 -&gt; 放到单例池中</code></pre><h3 id="AnnotationConfigApplicationContext详解"><a href="#AnnotationConfigApplicationContext详解" class="headerlink" title="AnnotationConfigApplicationContext详解"></a>AnnotationConfigApplicationContext详解</h3><ul><li>类图<br><img src="https://gitee.com/im-fan/fan-pic/raw/master/images/springframework-bean-uml.png" alt="类图"></li><li>流程图<br><img src="https://gitee.com/im-fan/fan-pic/raw/master/images/spring-start-process.png" alt="执行流程"></li></ul><h3 id="解决循环依赖"><a href="#解决循环依赖" class="headerlink" title="解决循环依赖"></a>解决循环依赖</h3><ul><li><a href="https://www.cnblogs.com/crazymakercircle/p/14465630.html">疯狂创客圈(转)</a></li><li>主要流程图<br><img src="https://gitee.com/im-fan/fan-pic/raw/master/images/spring-cycle-refrence.png" alt="spring解决循环依赖流程(转)"></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringFramework </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL相关-知识点</title>
      <link href="2021/07/20/backend/storage/mysql/"/>
      <url>2021/07/20/backend/storage/mysql/</url>
      
        <content type="html"><![CDATA[<h3 id="相关文档"><a href="#相关文档" class="headerlink" title="相关文档"></a>相关文档</h3><ul><li><a href="https://blog.jcole.us/innodb">Jeremy Cole的博客</a></li><li><a href="https://dev.mysql.com/doc/dev/mysql-server">MySQL8.0的源码文档</a></li><li><a href="https://publications.sba-research.org/publications/WSDF2012_InnoDB.pdf">mariadb-innodb原理文档(带图)</a></li><li><a href="http://mysqlserverteam.com/">MySQL Team Blog</a></li><li><a href="http://www.unofficialmysqlguide.com/optimizer-trace.html">非官方MySQL8.0优化器指南</a></li></ul><h2 id="部分总结"><a href="#部分总结" class="headerlink" title="部分总结"></a>部分总结</h2><h3 id="Innodb引擎的4大特性"><a href="#Innodb引擎的4大特性" class="headerlink" title="Innodb引擎的4大特性"></a>Innodb引擎的4大特性</h3><blockquote><p><a href="https://www.cnblogs.com/zhs0/p/10528520.html">参考文档</a></p></blockquote><ul><li>插入缓冲</li><li>二次写</li><li>自适应哈希</li><li>预读</li></ul><h4 id="插入缓冲"><a href="#插入缓冲" class="headerlink" title="插入缓冲"></a>插入缓冲</h4><pre><code class="textmate">用于提升插入性能，分为Insert Buffer、Change Bufferchange buffering是insert buffer的加强，insert buffer只针对insert有效，change buffering对insert、delete、update(delete+insert)、purge都有效使用插入缓冲的条件：* 非聚集索引* 非唯一索引</code></pre><h4 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h4><ul><li><p>事务的特性ACID</p><pre><code class="textmate">原子性(atomicity)：一个事务被事务不可分割的最小工作单元，要么全部提交，要么全部失败回滚。一致性(consistency)：数据库总是从一致性状态到另一个一致性状态，它只包含成功事务提交的结果隔离型(isolation)：事务所做的修改在最终提交一起，对其他事务是不可见的持久性(durability)：一旦事务提交，则其所做的修改就会永久保存到数据库中。</code></pre></li><li><p>事务隔离级别 </p></li></ul><table><thead><tr><th></th><th>脏读</th><th>不可重复读</th><th>幻读</th><th>解决原理</th></tr></thead><tbody><tr><td>读未提交</td><td>x</td><td>x</td><td>x</td><td></td></tr><tr><td>读已提交</td><td>√</td><td>x</td><td>x</td><td></td></tr><tr><td>可重复读</td><td>√</td><td>√</td><td>x</td><td>gap锁 (mysql默认级别)</td></tr><tr><td>串行化</td><td>√</td><td>√</td><td>√</td><td>读锁</td></tr></tbody></table><h4 id="重要文件"><a href="#重要文件" class="headerlink" title="重要文件"></a>重要文件</h4><ul><li>undolog</li><li>redolog</li><li>binlog</li></ul><h4 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h4><ul><li>MyISAM</li><li>Heap</li><li>Merge</li><li>INNODB</li><li>ISAM</li></ul><h2 id="《MySQL是怎样运行的：从根上理解MySQL》-读书笔记"><a href="#《MySQL是怎样运行的：从根上理解MySQL》-读书笔记" class="headerlink" title="《MySQL是怎样运行的：从根上理解MySQL》 读书笔记"></a>《MySQL是怎样运行的：从根上理解MySQL》 读书笔记</h2><blockquote><p>第一次读，摘录了其中部分知识点 2021-09-13读完</p></blockquote><h3 id="InnoDB数据格式"><a href="#InnoDB数据格式" class="headerlink" title="InnoDB数据格式"></a>InnoDB数据格式</h3><ul><li><p>内存与磁盘交互方式</p><pre><code class="textmate">InnoDB 采取的方式是:将数据划分为若干个页，以页作为磁盘和内存之间交互的基本单位，InnoDB中页的大小 一般为 16 KB。也就是在一般情况下，一次最少从磁盘中读取16KB的内容到内存中，一次最少把内存中的16KB 内容刷新到磁盘中。</code></pre></li><li><p>行格式<br><br/><a href="https://gitee.com/im-fan/fan-pic/raw/master/images/mysql-compact%E8%A1%8C%E6%A0%BC%E5%BC%8F.png">Compact行</a></p><pre><code class="textmate">Compact 、 Redundant 、Dynamic 和 Compressed变长字段(varchar(n)、text等)占用内存：1. 真正的数据内容 2. 占用的字节数对于 CHAR(M) 类型的列来说，当列采用的是定长字符集时，该列占用的字节数不会被加到变长字 段长度列表，而如果采用变长字符集时，该列占用的字节数也会被加到变长字段长度列表。</code></pre></li><li><p>数据太多造成的溢出</p><pre><code class="textmate">行溢出：一个页一般是 16KB ，当记录中的数据太多，当前页放不下的时候，会把多余的数据存储到其他页中；MySQL 是以 页为单位管理存储空间，一个页一般16kb,16384字节，一个varchar最多存储65532个字节对于占用存储空间非常大的列，在 记录的真实数据 处只会存储该列的一部 分数据，把剩余的数据分散存储在几个其他的页中，然后记录的真实数据处用20个字节存储指向这些页的地址 (当然这20个字节中还包括这些分散在其他页面中的数据的占用的字节数)，从而可以找到剩余数据所在的页，</code></pre></li><li><p>行溢出的临界点</p><pre><code class="textmate">MySQL 中规定一个页中至少存放两行记录对于只有一个列的表，发生行溢出现象时需要满足这个式子: 136 + 2×(27 + n) &gt; 16384 ， n &gt; 8098重点:  不用关注这个临界点是什么，只要知道如果我们向一个行中存储了很大的数据时，可能发生 行溢出 的现象不论我们怎么对页中的记录做增删改操作，InnoDB始终会维护一条记录的单链表，链表中的各个 节点是按照主键值由小到大的顺序连接起来的</code></pre></li><li><p>总结<br><br/><a href="https://gitee.com/im-fan/fan-pic/raw/master/images/InnoDB_data_page.png">InnoDB数据页结构</a></p></li></ul><pre><code class="textmate">1. InnoDB为了不同的目的而设计了不同类型的页，我们把用于存放记录的页叫做 数据页 。2. 一个数据页可以被大致划分为7个部分，分别是   File Header ，表示页的一些通用信息，占固定的38字节。   Page Header ，表示数据页专有的一些信息，占固定的56个字节。   Infimum + Supremum ，两个虚拟的伪记录，分别表示页中的最小和最大记录，占固定的 26 个字节。   User Records :真实存储我们插入的记录的部分，大小不固定。   Free Space :页中尚未使用的部分，大小不确定。   Page Directory: 页中的某些记录相对位置，也就是各个槽在页面中的地址偏移量，大小不固定，插入的记录越多，这个部分占用的空间越多。   File Trailer :用于检验页是否完整的部分，占用固定的8个字节。3. 每个记录的头信息中都有一个 next_record 属性，从而使页中的所有记录串联成一个 单链表 。4. InnoDB 会为把页中的记录划分为若干个组，每个组的最后一个记录的地址偏移量作为一个 槽 ，存放在   Page Directory 中，所以在一个页中根据主键查找记录是非常快的，分为两步:   4.1 通过二分法确定该记录所在的槽。   4.2 通过记录的next_record属性遍历该槽所在的组中的各个记录。5. 每个数据页的 File Header 部分都有上一个和下一个页的编号，所以所有的数据页会组成一个 双链表 。6. 为保证从内存中同步到磁盘的页的完整性，在页的首部和尾部都会存储页中数据的校验和和页面最后修改时   对应的 LSN 值，如果首部和尾部的校验和和 LSN 值校验不成功的话，就说明同步过程出现了问题。</code></pre><ul><li>Innodb通用页结构<br><br/><a href="https://gitee.com/im-fan/fan-pic/raw/master/images/InnoDB%E6%95%B0%E6%8D%AE%E9%A1%B5%E7%BB%93%E6%9E%84%E7%A4%BA%E6%84%8F%E5%9B%BE.png">Innodb通用页结构</a><br><br/><a href="https://gitee.com/im-fan/fan-pic/raw/master/images/Innodb%E9%80%9A%E7%94%A8%E9%A1%B5%E7%BB%93%E6%9E%84-%E8%A7%A3%E9%87%8A.png">Innodb通用页结构-解释</a></li></ul><pre><code class="textmate">表空间结构(系统表空间/独立表空间)连续64个页面 = 一个区(默认1MB)每256个区被划分为一个组每个组的最开始的几个页面类型是固定的1.FSP_HDR 类型:这个类型的页面是用来登记整个表空间的一些整体属性以及本组所有的 区 ，也就是  extent 0 ~ extent 255 这256个区的属性，稍后详细唠叨。需要注意的一点是，整个表空间只有一 个 FSP_HDR 类型的页面。2.IBUF_BITMAP 类型:这个类型的页面是存储本组所有的区的所有页面关于 INSERT BUFFER 的信息。3.INODE 类型:这个类型的页面存储了许多称为 INODE 的数据结构，其余各组最开始的2个页面的类型是固定的1.DES 类型:全称是 extent descriptor ，用来登记本组256个区的属性，也就是说对于在 extent 256 区中的该类型页面存储的就是 extent 256 ~ extent 511 这些区的属性，对于在 extent 512 区中的该 类型页面存储的就是 extent 512 ~ extent 767 这些区的属性。上边介绍的 FSP_HDR 类型的页面其实 和 XDES 类型的页面的作用类似，只不过 FSP_HDR 类型的页面还会额外存储一些表空间的属性。2.IBUF_BITMAP</code></pre><ul><li><a href="https://gitee.com/im-fan/fan-pic/raw/master/images/mysql-innondb%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.png">InnonDB文件结构总结</a></li></ul><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><pre><code class="textmate">SHOW INDEX FROM 表名 - 索引统计数据    对于InnoDB存储引擎来说，使用SHOW INDEX语句展示出来的某个索引列的Cardinality属性是一个估计 值，并不是精确的注意：    在MySQL 5.7.3以及之前的版本中，eq_range_index_dive_limit的默认值为10，之 后的版本默认值为200。    所以如果大家采用的是5.7.3以及之前的版本的话，很容易采用索引统计数据而 不是index dive的方式来计算查询成本。当你的查询中使用到了IN查询，但是却实际没有用到索引，就 应该考虑一下是不是由于 eq_range_index_dive_limit 值太小导致的。连接查询的成本计算公式:    连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出数 x 单次访问被驱动表的成本</code></pre><h4 id="InnoDB统计数据的方式"><a href="#InnoDB统计数据的方式" class="headerlink" title="InnoDB统计数据的方式"></a>InnoDB统计数据的方式</h4><pre><code class="textmate">InnoDB 以表为单位来收集统计数据，这些统计数据可以是基于磁盘的永久性统计数据，也可以是基于内存 的非永久性统计数据。    innodb_stats_persistent 控制着使用永久性统计数据还是非永久性统计数据;     innodb_stats_persistent_sample_pages 控制着永久性统计数据的采样页面数量;     innodb_stats_transient_sample_pages 控制着非永久性统计数据的采样页面数量;     innodb_stats_auto_recalc 控制着是否自动重新计算统计数据。我们可以针对某个具体的表，在创建和修改表时通过指定 STATS_PERSISTENT 、 STATS_AUTO_RECALC 、 STATS_SAMPLE_PAGES 的值来控制相关统计数据属性。    innodb_stats_method 决定着在统计某个索引列不重复值的数量时如何对待 NULL 值。通过配置将决定权交给用户    1.nulls_equal :认为所有 NULL 值都是相等的。这个值也是 innodb_stats_method 的默认值。如果某个索引列中 NULL 值特别多的话，这种统计方式会让优化器认为某个列中平均一个值重复次数特别 多，所以倾向于不使用索引进行访问。    2.nulls_unequal :认为所有 NULL 值都是不相等的。如果某个索引列中 NULL 值特别多的话，这种统计方式会让优化器认为某个列中平均一个值重复次数特别 少，所以倾向于使用索引进行访问。    3.nulls_ignored :直接把 NULL 值忽略掉。</code></pre><h4 id="SQL重写方式"><a href="#SQL重写方式" class="headerlink" title="SQL重写方式"></a>SQL重写方式</h4><h5 id="条件化简"><a href="#条件化简" class="headerlink" title="条件化简"></a>条件化简</h5><pre><code class="textmate">1.移除不必要的括号2.常量传递    a = 5 AND b &gt; a 改写为 a = 5 AND b &gt; 53.等值传递    a = b and b = c and c = 5 改写为 a = 5 and b = 5 and c = 54.移除没用的条件    (a &lt; 1 and b = b) OR (a = 6 OR 5 != 5) 改写为 (a &lt; 1 and TRUE) OR (a = 6 OR FALSE)  ==&gt;  a &lt; 1 OR a = 65.表达式计算    a =5 + 1 改写为 a=66.having和where子句合并7.常量表检测</code></pre><h5 id="外连接消除"><a href="#外连接消除" class="headerlink" title="外连接消除"></a>外连接消除</h5><ul><li>外连接和内连接区别<pre><code class="textmate">外连接和内连接的本质区别就是:  对于外连接的驱动表的记录来说，如果无法在被驱动表中找到 匹配ON子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用 NULL值填充;  而内连接的驱动表的记录如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记 录会被舍弃空值拒绝:  在被驱动表的WHERE子句符合空值拒绝的条件后，外连接和内连接可以相互转 换。这种转换带来的好处就是查询优化器可以通过评估表的不同连接顺序的成本，选出成本最低的那种连接顺序 来执行查询。</code></pre></li></ul><h5 id="子查询优化"><a href="#子查询优化" class="headerlink" title="子查询优化"></a>子查询优化</h5><pre><code class="textmate">1.按返回的结果集区分子查询    标量子查询    行子查询    列子查询    表子查询2.按与外层查询关系来区分子查询    不相关子查询    相关子查询3.子查询在布尔表达式中的使用4.子查询语法注意事项    4.1 子查询必须用小括号扩起来    4.2 在 SELECT 子句中的子查询必须是标量子查询    4.3 在想要得到标量子查询或者行子查询，但又不能保证子查询的结果集只有一条记录时，应该使用LIMIT 1语句来限制记录数量。    4.4 对于[NOT]IN/ANY/SOME/ALL 子查询来说，子查询中不允许有 LIMIT 语句。    4.5 不允许在一条语句中增删改某个表的记录时同时还对该表进行子查询。    如果 IN 子查询符合转换为 semi-join 的条件，查询优化器会优先把该子查询为 semi-join ，然后再考虑下边5种执行半连接的策略中哪个成本最低:    Table pullout    DuplicateWeedout     LooseScan     Materialization     FirstMatch    选择成本最低的那种执行策略来执行子查询。    如果 IN 子查询不符合转换为 semi-join 的条件，那么查询优化器会从下边两种策略中找出一种成本更低的 方式执行子查询:    先将子查询物化之后再执行查询 执行 IN to EXISTS 转换。5.[NOT] EXISTS子查询的执行    如果 [NOT] EXISTS 子查询是不相关子查询，可以先执行子查询，得出该 [NOT] EXISTS 子查询的结果是 TRUE 还    是 FALSE ，并重写原先的查询语句6.对于派生表的优化    6.1 最容易想到的就是把派生表物化    6.2将派生表和外层的表合并，也就是将查询重写为没有派生表的形式</code></pre><h3 id="Explain"><a href="#Explain" class="headerlink" title="Explain"></a>Explain</h3><h5 id="查看优化器生成执行计划的整个过程"><a href="#查看优化器生成执行计划的整个过程" class="headerlink" title="查看优化器生成执行计划的整个过程"></a>查看优化器生成执行计划的整个过程</h5><pre><code class="textmate">SHOW VARIABLES LIKE &#39;optimizer_trace&#39;; 1. 打开optimizer trace功能 (默认情况下它是关闭的):    SET optimizer_trace=&quot;enabled=on&quot;; 2. 这里输入你自己的查询语句 SELECT ...; 3. 从OPTIMIZER_TRACE表中查看上一个查询的优化过程     SELECT * FROM information_schema.OPTIMIZER_TRACE; 4. 可能你还要观察其他语句执行的优化过程，重复上边的第2、3步 ... 5. 当你停止查看语句的优化过程时，把optimizer trace功能关闭 SET optimizer_trace=&quot;enabled=off&quot;;</code></pre><h3 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h3><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><pre><code class="textmate">1. 磁盘太慢，用内存作为缓存很有必要。2. Buffer Pool 本质上是 InnoDB 向操作系统申请的一段连续的内存空间，可以通过   innodb_buffer_pool_size 来调整它的大小。3. Buffer Pool 向操作系统申请的连续内存由控制块和缓存页组成，每个控制块和缓存页都是一一对应的，在   填充足够多的控制块和缓存页的组合后， Buffer Pool 剩余的空间可能产生不够填充一组控制块和缓存页，   这部分空间不能被使用，也被称为 碎片 。4. InnoDB 使用了许多 链表 来管理 Buffer Pool 。5. free链表 中每一个节点都代表一个空闲的缓存页，在将磁盘中的页加载到 Buffer Pool 时，会从 free链 表 中寻找空闲的缓存页。6. 为了快速定位某个页是否被加载到 Buffer Pool ，使用 表空间号 + 页号 作为 key ，缓存页作为 value ， 建立哈希表。7. 在 Buffer Pool 中被修改的页称为 脏页 ，脏页并不是立即刷新，而是被加入到 flush链表 中，待之后的某 个时刻同步到磁盘上。8. LRU链表 分为 young 和 old 两个区域，可以通过 innodb_old_blocks_pct 来调节 old 区域所占的比例。   首次从磁盘上加载到 Buffer Pool 的页会被放到 old 区域的头部，在 innodb_old_blocks_time 间隔时间内访 问该页不会把它移动到 young 区域头部。在 Buffer Pool 没有可用的空闲缓存页时，会首先淘汰掉 old 区 域的一些页。9. 我们可以通过指定 innodb_buffer_pool_instances 来控制 Buffer Pool 实例的个数，每个 Buffer Pool 实 例中都有各自独立的链表，互不干扰。10. 自 MySQL 5.7.5 版本之后，可以在服务器运行过程中调整 Buffer Pool 大小。每个 Buffer Pool 实例由若 干个 chunk 组成，每个 chunk 的大小可以在服务器启动时通过启动参数调整。11. 可以用下边的命令查看 Buffer Pool 的状态信息: SHOW ENGINE INNODB STATUS\G</code></pre><h3 id="事务-1"><a href="#事务-1" class="headerlink" title="事务"></a>事务</h3><h4 id="ReadView"><a href="#ReadView" class="headerlink" title="ReadView"></a>ReadView</h4><ul><li><a href="https://gitee.com/im-fan/fan-pic/raw/master/images/mysql-innodb-%E7%89%88%E6%9C%AC%E9%93%BE.png">版本链</a></li></ul><pre><code class="textmate">READ COMMITTED 和 REPEATABLE READ 隔离级别的事务来说，核心问题就是:需要判断一下版本链中的哪个版本是当前事务可见的;</code></pre><ul><li>ReadView包含信息</li></ul><pre><code class="textmate">1.m_ids :表示在生成 ReadView 时当前系统中活跃的读写事务的 事务id 列表。2.min_trx_id :表示在生成 ReadView 时当前系统中活跃的读写事务中最小的 事务id ，也就是 m_ids 中的最 小值。3.max_trx_id :表示生成 ReadView 时系统中应该分配给下一个事务的 id 值。  小贴士:  注意max_trx_id并不是m_ids中的最大值，事务id是递增分配的。比方说现在有id为1，2，3这三 个事务，之后id为3的事务提交了。那么一个新的读事务在生成ReadView时，m_ids就包括1和2，mi n_trx_id的值就是1，max_trx_id的值就是4。4.creator_trx_id :表示生成该 ReadView 的事务的 事务id 。</code></pre><ul><li>区别</li></ul><pre><code class="textmate">READ COMMITTED 和 REPEATABLE READ 隔离级别的的一个非常大的区别就是它们生成ReadView的 时机不同READ COMMITTED —— 同一事务每次读取数据前都生成一个ReadViewREPEATABLE READ —— 同一事务在第一次读取数据时生成一个ReadView</code></pre><ul><li>ReadView判断步骤</li></ul><pre><code class="textmate">1.如果被访问版本的 trx_id 属性值与 ReadView 中的 creator_trx_id 值相同，意味着当前事务在访问它自己 修改过的记录，所以该版本可以被当前事务访问。2.如果被访问版本的 trx_id 属性值小于 ReadView 中的 min_trx_id 值，表明生成该版本的事务在当前事务生 成 ReadView 前已经提交，所以该版本可以被当前事务访问。3.如果被访问版本的 trx_id 属性值大于 ReadView 中的 max_trx_id 值，表明生成该版本的事务在当前事务生 成 ReadView 后才开启，所以该版本不可以被当前事务访问。4.如果被访问版本的 trx_id 属性值在 ReadView 的 min_trx_id 和 max_trx_id 之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该  版本不可以被访问;如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。MVCC (Multi-Version Concurrency Control ，多版本并发控制)指的就 是在使用 READ COMMITTD 、 REPEATABLE READ 这两种隔离级别的事务在执行普通的 SEELCT 操作时访问记录的版 本链的过程，这样子可以使不同事务的 读-写 、 写-读 操作并发执行，从而提升系统性能。</code></pre><ul><li><p>purge</p><pre><code class="textmate">insert undo 在事务提交之后就可以被释放掉了，而 update undo 由于还需要支持 MVCC ，不能立即 删除掉。为了支持 MVCC ，对于 delete mark 操作来说，仅仅是在记录上打一个删除标记，并没有真正将它删除掉。随着系统的运行，在确定系统中包含最早产生的那个 ReadView 的事务不会再访问某些 update undo日志 以及被 打了删除标记的记录后，有一个后台运行的 purge线程 会把它们真正的删除掉</code></pre><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><h4 id="锁分类"><a href="#锁分类" class="headerlink" title="锁分类"></a>锁分类</h4><pre><code class="textmate">行级锁、表锁(S锁-共享锁、X锁-独占锁、IS-意向共享、IX-意向独占)总结:  IS、IX锁是表级锁，它们的提出仅仅为了在之后加表级别的S锁和X锁时可以快速判断表中的记录是否 被上锁，  以避免用遍历的方式来查看表中有没有上锁的记录，也就是说其实IS锁和IX锁是兼容的，IX锁和IX锁是 兼容的</code></pre></li><li><p>兼容性</p></li></ul><table><thead><tr><th>是否兼容</th><th>X</th><th>IX</th><th>S</th><th>IS</th></tr></thead><tbody><tr><td>X</td><td>否</td><td>否</td><td>否</td><td>否</td></tr><tr><td>IX</td><td>否</td><td>是</td><td>否</td><td>是</td></tr><tr><td>S</td><td>否</td><td>否</td><td>是</td><td>是</td></tr><tr><td>IS</td><td>否</td><td>是</td><td>是</td><td>是</td></tr></tbody></table><ul><li>锁结构(简易)<pre><code class="textmate">trx信息 :代表这个锁结构是哪个事务生成的。is_waiting :代表当前事务是否在等待。</code></pre></li><li>操作锁步骤<pre><code class="textmate">在事务 T1 提交之后，就会把该事务生成的 锁结构 释放掉，然后看看还有没有别的事务在等待获取锁， 发现了事务 T2 还在等待获取锁，所以把事务 T2 对应的锁结构的 is_waiting 属性设置为 false ，然后 把该事务对应的线程唤醒，让它继续执行，此时事务 T2 就算获取到锁了</code></pre></li></ul><h4 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h4><pre><code class="textmate">在 READ UNCOMMITTED 隔离级别下， 脏读 、 不可重复读 、 幻读 都可能发生。在 READ COMMITTED 隔离级别下， 不可重复读 、 幻读 可能发生， 脏读 不可以发生。在 REPEATABLE READ 隔离级别下， 幻读 可能发生， 脏读 和 不可重复读 不可以发生。在 SERIALIZABLE 隔离级别下，上述问题都不可以发生。脏读：读到另一个事务未提交的数据不可重复读: 同一个事务两次读取，第二次读取到了另外一个事务提交的数据幻读: 同一个事务两次读取范围数据，第二次读取到新的记录</code></pre>]]></content>
      
      
      <categories>
          
          <category> 存储 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringFramework源码编译</title>
      <link href="2021/06/26/backend/spring/framework/springframework-1/"/>
      <url>2021/06/26/backend/spring/framework/springframework-1/</url>
      
        <content type="html"><![CDATA[<h2 id="SpringFramework5-2-x编译步骤-Mac下"><a href="#SpringFramework5-2-x编译步骤-Mac下" class="headerlink" title="SpringFramework5.2.x编译步骤(Mac下)"></a>SpringFramework5.2.x编译步骤(Mac下)</h2><h3 id="使用工具"><a href="#使用工具" class="headerlink" title="使用工具"></a>使用工具</h3><ul><li>jdk1.8</li><li>Spring-Framework5.2.x 源码</li><li>Gradle 5.6.4</li><li>Idea2021</li></ul><h3 id="Gradle安装配置-编译工具"><a href="#Gradle安装配置-编译工具" class="headerlink" title="Gradle安装配置(编译工具)"></a>Gradle安装配置(编译工具)</h3><ul><li><a href="https://gradle.org/">Gradle官网</a></li><li><a href="https://gradle.org/releases/">下载页面</a></li></ul><h4 id="方式一、压缩包-推荐"><a href="#方式一、压缩包-推荐" class="headerlink" title="方式一、压缩包(推荐)"></a>方式一、压缩包(推荐)</h4><blockquote><p>建议下载源码中标识的gradle版本(源码gradle/wrapper/gradle-wrapper.properties中)</p></blockquote><pre><code class="textmate">1.下载压缩包，解压至~/software/文件夹下2.设置环境变量   echo $SHELL 先查看当前shell   /bin/bash 则修改 ~/.bash_profile 文件   /bin/zsh 则修改 ~/.zshrc 文件   添加以下配置:        export GRADLE_HOME=/Users/mac/software/gradle        export PATH=$PATH:$GRADLE_HOME/bin    source ~/.zshrc 或 source ~/.bash_profile 刷新3.验证安装  gradle -v</code></pre><ul><li>添加Gradle配置<pre><code class="groovy">allprojects&#123; repositories &#123;     def REPOSITORY_URL = &#39;http://maven.aliyun.com/nexus/content/groups/public/&#39;     all &#123; ArtifactRepository repo -&gt;         if(repo instanceof MavenArtifactRepository)&#123;             def url = repo.url.toString()             if (url.startsWith(&#39;https://repo1.maven.org/maven2&#39;) || url.startsWith(&#39;https://jcenter.bintray.com/&#39;)) &#123;                 project.logger.lifecycle &quot;Repository $&#123;repo.url&#125; replaced by $REPOSITORY_URL.&quot;                 remove repo             &#125;         &#125;     &#125;     maven &#123;         url REPOSITORY_URL     &#125; &#125;&#125;</code></pre></li></ul><h4 id="方式二、brew安装"><a href="#方式二、brew安装" class="headerlink" title="方式二、brew安装"></a>方式二、brew安装</h4><blockquote><p>可能不是你想要的版本，注意！！！</p></blockquote><pre><code class="shell">brew install gradle</code></pre><h4 id="方式三、旧版本升级命令-没试过"><a href="#方式三、旧版本升级命令-没试过" class="headerlink" title="方式三、旧版本升级命令(没试过)"></a>方式三、旧版本升级命令(没试过)</h4><pre><code class="shell">./gradlew wrapper --gradle-version=7.1 --distribution-type=bin</code></pre><h3 id="Idea安装配置Gradle"><a href="#Idea安装配置Gradle" class="headerlink" title="Idea安装配置Gradle"></a>Idea安装配置Gradle</h3><pre><code class="textmate">1.搜索并安装插件     菜单: Preferences -&gt; Plugins    插件名(2个): Gradle / Gradle Extension2.配置    菜单: Preferences -&gt; Build -&gt; Build Tools -&gt; Gradle    配置项: 设置Gradle user home(仓库目录)</code></pre><h3 id="Idea编译项目"><a href="#Idea编译项目" class="headerlink" title="Idea编译项目"></a>Idea编译项目</h3><pre><code class="textmate">1.导入   File -&gt; Open -&gt; 打开 Spring-Framework5.2x源码中 build.gradle2.等待编译完成   正常情况下一次编译通过，不熟悉gradle的话建议先不要改 settings.gradle 和 build.gradle 内容，否则会编译失败；3.其他   出现其他异常先参考源码中 import-into-XXX.md 文档</code></pre><h3 id="新建项目测试"><a href="#新建项目测试" class="headerlink" title="新建项目测试"></a>新建项目测试</h3><ul><li>1.新建模块my-demo，类型选Gradle</li><li>2.将新建的模块加到项目中(idea自动新增)<pre><code class="textmate">settings.gradle 中新增 include &#39;my-demo&#39;</code></pre></li><li>3.引入模块<pre><code class="groovy">// my-demo/build.gradle中引入模块dependencies 下新增 compile(project(&quot;:spring-context&quot;))</code></pre></li><li>4.新建配置类及测试代码<pre><code class="java">//配置类//如果注解引入失败，则在@Componentpublic class TestConfig &#123;&#125;</code></pre></li></ul><p>//测试类，打印成功则说明编译成功<br>public class StartDemo {<br>    public static void main(String[] args) {<br>        AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(“com.my.config”);<br>        System.out.println(context.getBean(TestConfig.class));<br>    }<br>}</p><pre><code></code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringFramework </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringClougGateway</title>
      <link href="2021/06/15/backend/spring/springcloud-gateway/"/>
      <url>2021/06/15/backend/spring/springcloud-gateway/</url>
      
        <content type="html"><![CDATA[<h3 id="文章收集"><a href="#文章收集" class="headerlink" title="文章收集"></a>文章收集</h3><ul><li><a href="https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.1.0.RC3/multi/multi_spring-cloud-gateway.html">SpringCloudGateway-2.1.0.RC3</a></li><li><a href="https://spring.io/projects/spring-cloud-gateway">SpringCloudGateway官网</a></li><li><a href="https://www.haoyizebo.com/posts/876ed1e8/">SpringCloudGateway(读取、修改RequestBody)(转)</a></li></ul><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><pre><code class="yaml">spring:  application:    name: cloud-gateway  cloud:    httpclient:      connect-timeout: 20000      pool:        max-idle-time: 20000    #开启从注册中心动态创建路由的功能，利用微服务名进行路由#    discovery:#      locator:#        lower-case-service-id: true#        enabled: true    # 相关文档 https://www.cnblogs.com/crazymakercircle/p/11704077.html    # uri相同时，只有最后一个会生效    #一个请求满足多个路由的断言条件时，请求只会被首个成功匹配的路由转发；    #predicates断言，可根据datetime、Cookie、Header、Host、Method、Path、Queryparam、RemoteAddr匹配    #filter: 支持PrefixPath、RewritePath、SetPath、RedirectTo、RemoveRequestHeader、    #RemoveResponseHeader、SetStatus、StripPrefix、RequestSize、Default-filters    gateway:      routes:      #根据url拦截      - id: service1_v1        uri: https://www.so.com/?quanso.com.cn        predicates:          - Path=/360#      - id: service1_v2#        uri: http://localhost:8080/api/v2#        predicates:#          - Path=/v2      #拦截v1请求，并带上/api，转发到8080端口上#      - id: service1_v3#        uri: http://localhost:8080#        predicates:#          - Path=/v1#        filters:#          - PrefixPath=/api      #predicates断言，可根据datetime/Cookie/Header/Host/Method/Path/Queryparam/RemoteAddr匹配      - id: queryParam-baidu-route        uri: https://www.baidu.com        predicates:          - Query=baidu      - id: queryParam-bing-route        uri: https://bing.com/        predicates:          - Query=bing, tr. #参数中包含bing,且值为tr开头的三位参数 才能匹配到#      - id: queryParam-release2-route#        uri: http://localhost:8080/api/v2#        predicates:#          - Path=/api#          - Weight=service2, 90#      - id: queryParam-head-route#        uri: http://localhost:8080#        predicates:#          - Header=Jump, 1001 #请求头中包含信息才校验通过#        filters:#          - PrefixPath=/api#      - id: queryParam-host-route#        uri: http://localhost:8080#        predicates:#          - Host=*.apix #请求头中包含信息才校验通过#        filters:#          - PrefixPath=/api      #测试StripPrefix#      - id: full-route#        uri: http://localhost:8080#        predicates:#          - Query=full#        filters:#          - PrefixPath=/full#          - StripPrefix=0      # 熔断降级#      - id: queryParam-fallback-route#        uri: http://localhost:8080#        predicates:#          - Path=/test#        filters:#          - name: Hystrix#            args:#              name: default#              fallbackUri: forward:/fallback#      - id: fallback-route#        uri: http://localhost:8080/fallback#        predicates:#          - Path=/fallback        # 金丝雀发布      - id: release1-route        uri: http://localhost:8080        predicates:          - Path=/v1          - Weight=service1, 50        filters:          - PrefixPath=/api      - id: release2-route        uri: http://localhost:8081        predicates:          - Path=/v1          - Weight=service1, 50        filters:          - PrefixPath=/api#hystrix.command.fallbackA.execution.isolation.thread.timeoutInMilliseconds: 5000# hystrix 信号量隔离，1.5秒后自动超时hystrix:  command:    default:      execution:        isolation:          strategy: SEMAPHORE          thread:            timeoutInMilliseconds: 1500</code></pre><h3 id="获取及改写RequestBody示例"><a href="#获取及改写RequestBody示例" class="headerlink" title="获取及改写RequestBody示例"></a>获取及改写RequestBody示例</h3><pre><code class="java">class DemoFilter implements GlobalFilter, Ordered&#123;    @Resource    private ServerCodecConfigurer configurer;    @Override    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123;        ServerRequest serverRequest = ServerRequest.create(exchange, configurer.getReaders());        // read &amp; modify body        Mono&lt;String&gt; modifiedBody = serverRequest.bodyToMono(String.class)                .flatMap(body -&gt; &#123;                    //例子：验签                    boolean checkFlag = paramSignCheck(jsonParam);                    if(!checkFlag)&#123;                        return Mono.error(new Exception(&quot;验签失败&quot;));                    &#125;                    return Mono.just(body);                &#125;);        BodyInserter bodyInserter = BodyInserters.fromPublisher(modifiedBody,String.class);        HttpHeaders headers = new HttpHeaders();        headers.putAll(exchange.getRequest().getHeaders());        //重要 不处理会导致请求失败        headers.remove(HttpHeaders.CONTENT_LENGTH);        CachedBodyOutputMessage outputMessage = new CachedBodyOutputMessage(exchange, headers);        return bodyInserter.insert(outputMessage, new BodyInserterContext())                .then(Mono.defer(() -&gt; &#123;                    ServerHttpRequestDecorator decorator = new ServerHttpRequestDecorator(                            exchange.getRequest()) &#123;                        @Override                        public HttpHeaders getHeaders() &#123;                            long contentLength = headers.getContentLength();                            HttpHeaders httpHeaders = new HttpHeaders();                            httpHeaders.putAll(super.getHeaders());                            if (contentLength &gt; 0) &#123;                                httpHeaders.setContentLength(contentLength);                            &#125;                            return httpHeaders;                        &#125;                        @Override                        public Flux&lt;DataBuffer&gt; getBody() &#123;                            return outputMessage.getBody();                        &#125;                    &#125;;                    ServerHttpResponse decoratedResponse = decorate(exchange, trace);                    return chain.filter(exchange.mutate().request(decorator).response(decoratedResponse).build());                &#125;));    &#125;&#125;</code></pre><h3 id="新增headers"><a href="#新增headers" class="headerlink" title="新增headers"></a>新增headers</h3><pre><code class="java">@Configurationpublic class AuthGatewayFilter implements GlobalFilter, Ordered &#123;    @Override    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123;        Consumer&lt;HttpHeaders&gt; httpHeaders = httpHeader -&gt; &#123;            // 存在相同的key,直接添加会报错            if(StringUtils.isBlank(httpHeader.getFirst(&quot;xxx&quot;)))&#123;                httpHeader.add(&quot;xxx&quot;, &quot;xxx&quot;);            &#125;        &#125;;        ServerHttpRequest serverHttpRequest = exchange.getRequest().mutate().headers(httpHeaders).build();        exchange = exchange.mutate().request(serverHttpRequest).build();        return chain.filter(exchange);    &#125;    @Override    public int getOrder() &#123;        return Ordered.HIGHEST_PRECEDENCE - 1;    &#125;&#125;</code></pre><h3 id="请求非json格式转jsondemo"><a href="#请求非json格式转jsondemo" class="headerlink" title="请求非json格式转jsondemo"></a>请求非json格式转jsondemo</h3><pre><code class="java">class Demo&#123;    /** application/x-www-form-urlencoded 转json **/    private Map&lt;String, Object&gt; decodeBody(String body) &#123;        return Arrays.stream(body.split(&quot;&amp;&quot;))                .map(s -&gt; s.split(&quot;=&quot;))                .collect(Collectors.toMap(arr -&gt; arr[0], arr -&gt; arr[1]));    &#125;    /** fomrData(非文件)转 json 数据 **/    private String parseFormData2Json(String requestParam)&#123;        if(StringUtils.isBlank(requestParam)                 &amp;&amp; !requestParam.contains(&quot;filename&quot;))&#123;            return requestParam;        &#125;        try&#123;            requestParam = requestParam.replace(&quot;-&quot;,&quot;&quot;).split(&quot;-&quot;)[0];            String code = requestParam.split(&quot;\n&quot;)[0];            requestParam = requestParam.replaceAll(code,&quot;&quot;)                    .replaceAll(&quot;ContentDisposition: formdata;&quot;,&quot;&quot;)                    .replaceAll(&quot;\n&quot;,&quot;&quot;)                    .replaceAll(&quot;name=&quot;,&quot;,&quot;)                    .replaceAll(&quot;\&quot;\r\r&quot;,&quot;\&quot;:\&quot;&quot;)                    .replaceFirst(&quot;,&quot;,&quot;&quot;)                    .replaceAll(&quot;\r&quot;,&quot;\&quot;&quot;)            ;            requestParam = &quot;&#123;&quot; + requestParam + &quot;\&quot;&#125;&quot;;        &#125; catch (Exception e)&#123;            e.printStackTrace();        &#125;        return requestParam;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gateway </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>调用链监控-skywalking</title>
      <link href="2021/05/19/devops/skywalking/"/>
      <url>2021/05/19/devops/skywalking/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="http://skywalking.apache.org/">官网</a></li><li><a href="http://skywalking.apache.org/downloads/">下载地址</a></li><li><a href="https://www.jianshu.com/p/8b9aad4210c5">部署及使用文档(转)</a></li></ul><h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><ul><li>重启<pre><code class="textmate">原脚本中没有杀掉旧进程，使用jps找到对应服务，然后kill掉再执行bin/startup.sh</code></pre></li><li>支持SpringCloudGateway<pre><code class="textmate">默认情况agent是不支持对spring-cloud-gateway的监控的，需要插件的支持。我们要将optional-plugins下的插件apm-spring-cloud-gateway-2.x-plugin-6.5.0.jar拷贝到plugins下</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> skywalking </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>istio</title>
      <link href="2021/05/18/devops/istio/"/>
      <url>2021/05/18/devops/istio/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://istio.io/latest/zh/docs/examples/bookinfo/">官网</a></li><li><a href="https://www.jianshu.com/p/1f3f62ce3ea9">istio性能测试</a></li></ul><h3 id="流量管理"><a href="#流量管理" class="headerlink" title="流量管理"></a>流量管理</h3><ul><li><p>配置基本请求路由</p><pre><code class="yaml">spec:hosts:  - reviewshttp:  - route:      - destination:          host: reviews          subset: v1</code></pre></li><li><p>按照请求头中用户信息过滤</p><pre><code class="yaml">spec:hosts:  - reviewshttp:  - match:      - headers:          end-user:            exact: jason    route:      - destination:          host: reviews          subset: v2  - match:      - headers:          end-user:            exact: aaa    route:      - destination:          host: reviews          subset: v2  - route:      - destination:          host: reviews          subset: v3</code></pre></li><li><p>故障注入-延迟(jason登录，访问6s后页面才加载出来)</p><pre><code class="yaml">spec:hosts:  - ratingshttp:  - fault:      delay:        fixedDelay: 7s # 7s延迟        percentage:          value: 100    match:      - headers:          end-user:            exact: jason    route:      - destination:          host: ratings          subset: v1  - route:      - destination:          host: ratings          subset: v1</code></pre></li><li><p>故障注入-异常(jason登录，50几率访问返回500)</p><pre><code class="yaml">spec:hosts:- ratingshttp:- match:  - headers:      end-user:        exact: jason  fault:    abort:      percentage:        value: 50      httpStatus: 500 #注入500错误  route:  - destination:      host: ratings      subset: v1- route:  - destination:      host: ratings      subset: v1</code></pre></li><li><p>流量转移</p><pre><code class="yaml">spec:hosts:  - reviewshttp:- route:  - destination:      host: reviews      subset: v1    weight: 50  - destination:      host: reviews      subset: v3    weight: 50</code></pre></li><li><p>设置请求超时(2s延迟)</p><pre><code class="yaml">spec:hosts:- ratingshttp:- fault:    delay:      percent: 100      fixedDelay: 2s  route:  - destination:      host: ratings      subset: v1</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> istio </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vue</title>
      <link href="2021/04/28/frontend/vue/"/>
      <url>2021/04/28/frontend/vue/</url>
      
        <content type="html"><![CDATA[<h3 id="vue-es6接入Echarts"><a href="#vue-es6接入Echarts" class="headerlink" title="vue+es6接入Echarts"></a>vue+es6接入Echarts</h3><h4 id="1-安装"><a href="#1-安装" class="headerlink" title="1.安装"></a>1.安装</h4><pre><code class="shell"># echarsnpm install echarts --save</code></pre><h4 id="2-实现图表下钻及还原demo"><a href="#2-实现图表下钻及还原demo" class="headerlink" title="2.实现图表下钻及还原demo"></a>2.实现图表下钻及还原demo</h4><pre><code class="textmate">&lt;template&gt;    &lt;div style=&quot;display: inline-block&quot; v-show=&quot;optionShow&quot; &gt;        &lt;div id=&quot;option&quot; :style=&quot;&#123;width: &#39;800px&#39;, height: &#39;600px&#39;&#125;&quot;&gt;&lt;/div&gt;    &lt;/div&gt;    &lt;div style=&quot;display: inline-block&quot; v-show=&quot;optionSecondShow&quot; &gt;        &lt;div id=&quot;secondOption&quot; :style=&quot;&#123;width: &#39;800px&#39;, height: &#39;600px&#39;&#125;&quot;&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/template&gt;&lt;script&gt;    import * as echarts from &#39;echarts&#39;;    export default &#123;        name: &#39;dashboard&#39;,        data() &#123;            return &#123;                optionShow: true,                // echarts报表                option: &#123;&#125;,                optionSecond: &#123;&#125;,            &#125;        &#125;,        created()&#123;        &#125;,        mounted()&#123;            //调用method中方法！！！            let that = this;            //渲染报表一            let myChart = echarts.init(document.getElementById(&#39;option&#39;))            that.initEcharts();            myChart.setOption(that.option);            //报表二            let myChartSecond = echarts.init(document.getElementById(&#39;secondOption&#39;))            //图表一下钻            myChart.on(&#39;click&#39;, function (params) &#123;                console.log(params.name,params.value,params.seriesName);                //重置值                that.secondShowFun()                myChartSecond.setOption(that.optionSecond)            &#125;);            //点击图表二还原数据            myChartSecond.getZr().on(&#39;click&#39;, function (event) &#123;                if (!event.target) &#123;                    that.initEcharts();                    myChart.setOption(that.option)                &#125;            &#125;);            //点击图表二下钻            myChartSecond.on(&#39;click&#39;, function (params) &#123;                console.log(params.name,params.value,params.seriesName);                //展示列表                that.showTabFun()            &#125;);        &#125;,        methods: &#123;            initEcharts()&#123;                this.optionShow = true;                this.optionSecondShow = false;                this.tableShow = false;                this.option = &#123;                    tooltip: &#123;                        trigger: &#39;axis&#39;,                        axisPointer: &#123;            // Use axis to trigger tooltip                            type: &#39;shadow&#39;        // &#39;shadow&#39; as default; can also be &#39;line&#39; or &#39;shadow&#39;                        &#125;                    &#125;,                    legend: &#123;                        data: [&#39;项目一&#39;, &#39;项目二&#39;, &#39;项目三&#39;]                    &#125;,                    grid: &#123;                        left: &#39;3%&#39;,                        right: &#39;4%&#39;,                        bottom: &#39;3%&#39;,                        containLabel: true                    &#125;,                    xAxis: &#123;                        type: &#39;value&#39;                    &#125;,                    yAxis: &#123;                        type: &#39;category&#39;,                        data: [&#39;user-center&#39;, &#39;user-auth&#39;, &#39;uaa-gateway&#39;, &#39;crm&#39;, &#39;ims&#39;, &#39;fms&#39;, &#39;cloud-gateway&#39;]                    &#125;,                    series: [                        &#123;                            name: &#39;项目一&#39;,                            type: &#39;bar&#39;,                            stack: &#39;total&#39;,                            label: &#123;                                show: true,                                valueAnimation: true                            &#125;,                            emphasis: &#123;                                focus: &#39;series&#39;                            &#125;,                            data: [320, 302, 301, 334, 390, 330, 320]                        &#125;,                        &#123;                            name: &#39;项目二&#39;,                            type: &#39;bar&#39;,                            stack: &#39;total&#39;,                            label: &#123;                                show: true,                                valueAnimation: true                            &#125;,                            emphasis: &#123;                                focus: &#39;series&#39;                            &#125;,                            data: [120, 132, 101, 134, 90, 230, 210]                        &#125;,                        &#123;                            name: &#39;项目三&#39;,                            type: &#39;bar&#39;,                            stack: &#39;total&#39;,                            label: &#123;                                show: true,                                valueAnimation: true                            &#125;,                            emphasis: &#123;                                focus: &#39;series&#39;                            &#125;,                            data: [220, 182, 191, 234, 290, 330, 310]                        &#125;                    ],                &#125;;            &#125;,            secondShowFun()&#123;                this.optionShow = false;                this.optionSecondShow = true;                this.optionSecond = &#123;                    tooltip: &#123;                        trigger: &#39;axis&#39;,                        axisPointer: &#123;            // Use axis to trigger tooltip                            type: &#39;shadow&#39;        // &#39;shadow&#39; as default; can also be &#39;line&#39; or &#39;shadow&#39;                        &#125;                    &#125;,                    legend: &#123;                        data: [&#39;分类一&#39;,&#39;分类二&#39;,&#39;分类三&#39;]                    &#125;,                    grid: &#123;                        left: &#39;3%&#39;,                        right: &#39;4%&#39;,                        bottom: &#39;3%&#39;,                        containLabel: true                    &#125;,                    xAxis: &#123;                        type: &#39;value&#39;                    &#125;,                    yAxis: &#123;                        type: &#39;category&#39;,                        data: [&#39;子项一&#39;, &#39;子项二&#39;, &#39;子项三&#39;]                    &#125;,                    series : [                        &#123;                            name: &#39;子项一&#39;,                            type: &#39;bar&#39;,                            stack: &#39;total&#39;,                            label: &#123;                                show: true                            &#125;,                            emphasis: &#123;                                focus: &#39;series&#39;                            &#125;,                            data: [10,2,3]                        &#125;,                        &#123;                            name: &#39;子项二&#39;,                            type: &#39;bar&#39;,                            stack: &#39;total&#39;,                            label: &#123;                                show: true                            &#125;,                            emphasis: &#123;                                focus: &#39;series&#39;                            &#125;,                            data: [1,3,4]                        &#125;,                        &#123;                            name: &#39;子项三&#39;,                            type: &#39;bar&#39;,                            stack: &#39;total&#39;,                            label: &#123;                                show: true                            &#125;,                            emphasis: &#123;                                focus: &#39;series&#39;                            &#125;,                            data: [2,5,6]                        &#125;,                    ],                &#125;;            &#125;,        &#125;    &#125;&lt;/script&gt;&lt;style lang=&quot;scss&quot; scoped&gt;    .dashboard-editor-container &#123;        padding: 32px;        background-color: rgb(240, 242, 245);        position: relative;    .chart-wrapper &#123;        background: #fff;        padding: 16px 16px 0;        margin-bottom: 32px;    &#125;    &#125;    @media (max-width:1024px) &#123;        .chart-wrapper &#123;            padding: 8px;        &#125;    &#125;&lt;/style&gt;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维相关</title>
      <link href="2021/04/16/devops/docker/"/>
      <url>2021/04/16/devops/docker/</url>
      
        <content type="html"><![CDATA[<h3 id="K8S相关"><a href="#K8S相关" class="headerlink" title="K8S相关"></a>K8S相关</h3><ul><li><a href="https://k8s.imroc.io/troubleshooting/">k8s实践(转)</a></li><li><a href="https://www.processon.com/view/link/5e4662ade4b0d86ec4018e50#map">k8s问题定位手册(转)</a></li></ul><h3 id="Docker相关"><a href="#Docker相关" class="headerlink" title="Docker相关"></a>Docker相关</h3><ul><li><a href="https://dockerwebdev.com/tutorials/clean-up-docker/">清理Docker</a></li><li><a href="https://www.kubernetes.org.cn/kubernetes-pod">Kubernetes中文社区</a></li><li><a href="https://istio.io/latest/zh/docs/setup/getting-started/">Istio(ServiceMesh)</a></li><li><a href="https://kiali.io/documentation/latest/runtimes-monitoring/#_quarkus">Kiali</a></li></ul><h4 id="本地启动K8S"><a href="#本地启动K8S" class="headerlink" title="本地启动K8S"></a>本地启动K8S</h4><pre><code class="textmate">1.先下载安装docker desktop(建议3.2.2以上)    https://www.docker.com/products/docker-desktop2.安装好后启动docker desktop3.设置    3.1 Perferences ==&gt; Kubernetes ==&gt; 开启Enable Kubernetes，Show system containers    3.2 如果开启不了尝试手动下载k8s相关进行并重启docker desktop    3.3 下载与docker desktop中Kubernetes一致的版本        https://github.com/maguowei/k8s-docker-desktop-for-mac</code></pre><h4 id="docker设置"><a href="#docker设置" class="headerlink" title="docker设置"></a>docker设置</h4><pre><code class="textmate">1.设置开机自启    sudo systemctl enable xx2.配置docker容器自动重启    docker update xx --restart=always</code></pre><h4 id="清理Docker"><a href="#清理Docker" class="headerlink" title="清理Docker"></a>清理Docker</h4><pre><code class="textmate">https://dockerwebdev.com/tutorials/clean-up-docker</code></pre><h4 id="配置阿里云镜像加速"><a href="#配置阿里云镜像加速" class="headerlink" title="配置阿里云镜像加速"></a>配置阿里云镜像加速</h4><pre><code class="textmate">阿里云控制台-&gt;容器服务-&gt;镜像加速器-&gt;选择不同系统的命令并执行</code></pre><h4 id="Docker踩坑"><a href="#Docker踩坑" class="headerlink" title="Docker踩坑"></a>Docker踩坑</h4><pre><code class="textmate">1.目录挂载问题    如果要映射具体文件，需要先手工创建好，否则默认是作为文件夹创建的</code></pre><h3 id="虚拟机-VirtualBox"><a href="#虚拟机-VirtualBox" class="headerlink" title="虚拟机-VirtualBox"></a>虚拟机-VirtualBox</h3><h4 id="VirtualBox虚拟机镜像安装工具"><a href="#VirtualBox虚拟机镜像安装工具" class="headerlink" title="VirtualBox虚拟机镜像安装工具"></a>VirtualBox虚拟机镜像安装工具</h4><pre><code class="textmate">   vargrant 软件(有对应的镜像仓库)   vargrant init center/7  ---&gt; 会生成类似dockerfile的文件,支持修改配置   vargrant up --&gt; 启动，相当于点虚拟机开机   vargrant ssh  ---&gt; ssh链接虚拟机   vargrant reload ---&gt; 重启虚拟机</code></pre>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nacos</title>
      <link href="2021/04/13/backend/service/nacos/"/>
      <url>2021/04/13/backend/service/nacos/</url>
      
        <content type="html"><![CDATA[<h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><ul><li><a href="https://nacos.io/zh-cn/docs/what-is-nacos.html">官方文档</a></li><li><a href="https://mp.weixin.qq.com/s/S8HI7DG5v9C2IfjXtkVjuQ">小白也能懂的 Nacos 服务模型介绍(转)</a> </li><li><a href="https://blog.csdn.net/wangwei19871103/article/details/105775039/">动态刷新原理(转)</a></li><li><a href="https://www.baidu.com/s?ie=UTF-8&wd=Raft%E7%AE%97%E6%B3%95">相关-Raft算法(转)</a></li></ul><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><h3 id="主要作用"><a href="#主要作用" class="headerlink" title="主要作用"></a>主要作用</h3><pre><code class="textmate">1.致力于发现、配置和管理微服务    提供了一组简单易用的特性集，帮助使用者快速实现动态服务发现、服务配置、服务元数据及流量管理。2.更敏捷和容易地构建、交付和管理微服务平台    构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施服务（Service）是 Nacos 世界的一等公民。Nacos 支持几乎所有主流类型的“服务”的发现、配置和管理</code></pre><h3 id="关键特性"><a href="#关键特性" class="headerlink" title="关键特性"></a>关键特性</h3><ul><li>服务发现和服务健康监测</li><li>动态配置服务</li><li>动态 DNS 服务</li><li>服务及其元数据管理</li></ul><h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><pre><code class="textmate">1.与eureka相比    nacos基于raft协议，集群一致性高；    eureka2.0闭源了    理论上支持的实例数大于eureka2.与SpringCloud Config相比    无需基于git仓库存储配置；    有可视化操作界面    nacos基于长连接，配置变动后立即通知Proivder</code></pre><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul><li>raft协议<pre><code class="textmate">Raft 协议强依赖 Leader 节点来确保集群数据一致性。步骤:client 发送过来的数据均先到达 Leader 节点，Leader 接收到数据后，先将数据标记为 uncommitted 状态，随后 Leader 开始向所有 Follower 复制数据并等待响应，集群中超过半数的 Follower 成功接收数据并响应后，Leader 将数据的状态标记为 committed，随后向 client 发送数据已接收确认，在向 client 发送出已数据接收后，再向所有 Follower 节点发送通知表明该数据状态为committed。</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 服务治理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 注册中心 </tag>
            
            <tag> nacos </tag>
            
            <tag> 动态配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nginx</title>
      <link href="2021/04/05/devops/nginx/"/>
      <url>2021/04/05/devops/nginx/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="http://nginx.org/">官网</a></li><li><a href="https://www.runoob.com/linux/nginx-install-setup.html">菜鸟教程-Nginx 安装配置</a></li><li><a href="https://cloud.tencent.com/document/product/400/35244">Nginx服务器SSL证书安装部署-腾讯云</a></li></ul><h3 id="nginx命令"><a href="#nginx命令" class="headerlink" title="nginx命令"></a>nginx命令</h3><pre><code class="textmate">1.检测配置是否正常nginx -t 2.热部署配置nginx -s reload</code></pre><h3 id="ssl-nginx配置"><a href="#ssl-nginx配置" class="headerlink" title="ssl-nginx配置"></a>ssl-nginx配置</h3><pre><code class="textmate">具体参考云厂商ssl证书安装步骤1.下载ssl相关文件,服务器开启443端口权限2.解压后将文件夹Nginx中文件放到nginx安装目录下(或其他地方)3.添加nginx配置文件4.重启生效</code></pre><h3 id="同一域名不同服务配置"><a href="#同一域名不同服务配置" class="headerlink" title="同一域名不同服务配置"></a>同一域名不同服务配置</h3><pre><code class="textmate">server &#123;    listen       8888;    server_name  localhost;    location /service1/ &#123;         proxy_pass http://localhost:7001/;    &#125;    location /service2/ &#123;         proxy_pass http://localhost:7002/;    &#125;&#125;</code></pre><h3 id="关于请求头经过nginx会被转为小写的原因"><a href="#关于请求头经过nginx会被转为小写的原因" class="headerlink" title="关于请求头经过nginx会被转为小写的原因"></a>关于请求头经过nginx会被转为小写的原因</h3><ul><li><a href="https://blog.csdn.net/qq_32771571/article/details/95903909">关于请求头经过nginx会被转为小写的原因-转</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot</title>
      <link href="2021/03/22/backend/spring/spring-boot/"/>
      <url>2021/03/22/backend/spring/spring-boot/</url>
      
        <content type="html"><![CDATA[<h3 id="文章收集"><a href="#文章收集" class="headerlink" title="文章收集"></a>文章收集</h3><ul><li><a href="https://www.jianshu.com/p/603d125f21b3">SpringBoot启动过程(转)</a></li><li><a href="https://www.processon.com/view/link/59812124e4b0de2518b32b6e">流程图(转)</a></li><li><a href="https://blog.csdn.net/youanyyou/article/details/103562907">@RefreshScope原理</a></li><li><a href="https://www.cnblogs.com/sword-successful/p/11383723.html">SpringBoot内置Tomcat启动源码分析</a></li><li><a href="https://blog.csdn.net/qq_28289405/article/details/81302498">@SpringBootApplication(转)</a></li></ul><h3 id="集成PageHelper"><a href="#集成PageHelper" class="headerlink" title="集成PageHelper"></a>集成PageHelper</h3><ul><li><p>配置</p><pre><code class="pom">&lt;!--基础框架包--&gt;&lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;  &lt;version&gt;2.3.4.RELEASE&lt;/version&gt;  &lt;type&gt;pom&lt;/type&gt;  &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;  &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;  &lt;version&gt;Hoxton.SR8&lt;/version&gt;  &lt;type&gt;pom&lt;/type&gt;  &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt;&lt;!--page helper依赖--&gt;&lt;!-- https://mvnrepository.com/artifact/com.github.pagehelper/pagehelper-spring-boot-starter --&gt;&lt;dependency&gt;  &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;  &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt;  &lt;version&gt;1.3.0&lt;/version&gt;&lt;/dependency&gt;</code></pre></li><li><p>使用</p><pre><code class="java">class XXService&#123;  public Result list(QueryParam param)&#123;      PageMethod.startPage(param.getPageNumber(),param.getPageSize());      List result = mapper.list(param);      PageInfo pageInfo = new PageInfo(result);      return PageDTO.result(pageInfo.getTotal(),result);  &#125;&#125;</code></pre></li><li><p>注意事项</p></li></ul><pre><code class="textmate">1.注意pom版本号2.使用pagehelper-spring-boot-starter pom后，不需要在yml中配置pagehelper相关参数，否则分页会有问题(亲测)  例如: 永远只在第一页</code></pre><h3 id="自动装配原理"><a href="#自动装配原理" class="headerlink" title="自动装配原理"></a>自动装配原理</h3><pre><code class="textmate">@EnableAutoConfiguration条件注解 @ConditionalOnBean等@EnableAutoConfiguration注解(找META-INF/spring.factories配置文件中的所有自动配置类)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> springboot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对象转换工具-Orika</title>
      <link href="2021/03/20/backend/java/utils/convert/orika/"/>
      <url>2021/03/20/backend/java/utils/convert/orika/</url>
      
        <content type="html"><![CDATA[<h2 id="Orika"><a href="#Orika" class="headerlink" title="Orika"></a>Orika</h2><ul><li><a href="http://orika-mapper.github.io/orika-docs/">官方文档</a></li></ul><h3 id="提供的能力"><a href="#提供的能力" class="headerlink" title="提供的能力"></a>提供的能力</h3><pre><code class="textmate">Orika为开发者提供了如下功能：1.映射复杂的、深层次结构性对象。2.通过将嵌套属性映射到顶级属性，“拉平”或“展开”对象。3.自动创建映射，并且在部分或所有映射上自定义。4.创建转换器，以完全控制对象图中的任何特定对象集合的映射——按类型，甚至是通过特定的属性名。5.处理代理或增强对象（如Hibernate或各种模拟框架）6.用一个配置应用双向映射。7.为一个目标抽象类或接口映射到具体的实现类。8.映射POJO属性到Lists, Arrays, and Maps。</code></pre><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><h4 id="pom引用"><a href="#pom引用" class="headerlink" title="pom引用"></a>pom引用</h4><pre><code class="textmate">&lt;!-- 方式一(推荐) --&gt;&lt;dependency&gt;    &lt;groupId&gt;net.rakugakibox.spring.boot&lt;/groupId&gt;    &lt;artifactId&gt;orika-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;1.9.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 方式二，需要在项目中加入配置类 --&gt;&lt;dependency&gt;    &lt;groupId&gt;ma.glasnost.orika&lt;/groupId&gt;    &lt;artifactId&gt;orika-core&lt;/artifactId&gt;    &lt;version&gt;1.5.4&lt;/version&gt;    &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;</code></pre><h4 id="方式二所需配置类-可选"><a href="#方式二所需配置类-可选" class="headerlink" title="方式二所需配置类(可选)"></a>方式二所需配置类(可选)</h4><pre><code class="java">/** * 可自定义转换规则 * **/@Configurationpublic class MapperFactoryAware &#123;    @Autowired    private MapperFactory mapperFactory;    @PostConstruct    public void init()&#123;        mapperFactory.getConverterFactory().registerConverter(new BooleanConvert());    &#125;    /** Boolean &lt;=&gt; Integer 互转 **/    private class BooleanConvert extends BidirectionalConverter&lt;Boolean,Integer&gt;&#123;        @Override        public Integer convertTo(Boolean source, Type&lt;Integer&gt; destinationType, MappingContext mappingContext) &#123;            return source ? 1 : 0;        &#125;        @Override        public Boolean convertFrom(Integer source, Type&lt;Boolean&gt; destinationType, MappingContext mappingContext) &#123;            return source == 1;        &#125;    &#125;&#125;</code></pre><h3 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h3><h4 id="基础测试类"><a href="#基础测试类" class="headerlink" title="基础测试类"></a>基础测试类</h4><pre><code class="java">// dto对象@Getter@Setter@AllArgsConstructor@NoArgsConstructor@Builderpublic class UserInfoDTO &#123;    private String userId;    private String userName;    private String createTime;    private List&lt;String&gt; ids;    private String dtoName;    private Integer sex;&#125;// po对象@Getter@Setter@AllArgsConstructor@NoArgsConstructor@Builderpublic class UserInfo &#123;    private Integer userId;    private String userName;    private Date createTime;    private List&lt;Integer&gt; ids;    private String poName;    private Boolean sex;&#125;</code></pre><h4 id="简易demo-更多用法参考官方文档"><a href="#简易demo-更多用法参考官方文档" class="headerlink" title="简易demo(更多用法参考官方文档)"></a>简易demo(更多用法参考官方文档)</h4><pre><code class="java">@Slf4j@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT,        classes = DemoApplication.class)public class ConvertTest&#123;    @Autowired    private MapperFacade mapperFacade;    @Autowired    private MapperFactory mapperFactory;    //简易案例，属性名相同，类型不同    @Test    public void testSimple()&#123;        UserInfo userInfo = UserInfo.builder()                .userId(10001)                .ids(Arrays.asList(1002,1003,1004,1005))                .userName(&quot;aaaa&quot;)                .createTime(new Date())                .build();        //po 2 dto        UserInfoDTO result = mapperFacade.map(userInfo, UserInfoDTO.class);        log.info(&quot;po 2 dto =====&gt; &#123;&#125;&quot;, JSON.toJSONString(result));        //dto 2 po        UserInfo info = mapperFacade.map(result, UserInfo.class);        log.info(&quot;dto 2 po =====&gt; &#123;&#125;&quot;, JSON.toJSONString(info));        // pos 2 dtos        List&lt;UserInfo&gt; pos = new ArrayList&lt;&gt;();        pos.add(userInfo);        List&lt;UserInfoDTO&gt; dtos = mapperFacade.mapAsList(pos,UserInfoDTO.class);        log.info(&quot;pos 2 dtos =====&gt; &#123;&#125;&quot;, JSON.toJSONString(dtos));        // pos 2 dtos        pos = mapperFacade.mapAsList(dtos, UserInfo.class);        log.info(&quot;pos 2 dtos =====&gt; &#123;&#125;&quot;, JSON.toJSONString(pos));    &#125;    //属性名不同，需要先在mapperFactory中设置，然后获取到mapperFacade再使用    @Test    public void testDiff()&#123;        UserInfo userInfo = UserInfo.builder()                .userId(10001)                .ids(Arrays.asList(1002,1003,1004,1005))                .userName(&quot;aaaa&quot;)                .createTime(new Date())                .poName(&quot;this is po&quot;)                .build();        //不同字段互转        mapperFactory.classMap(UserInfo.class, UserInfoDTO.class)                .field(&quot;poName&quot;, &quot;dtoName&quot;)                .byDefault()                .register();        MapperFacade mapperFacade = mapperFactory.getMapperFacade();        //po 2 dto        UserInfoDTO result = mapperFacade.map(userInfo, UserInfoDTO.class);        log.info(&quot;po 2 dto =====&gt; &#123;&#125;&quot;, JSON.toJSONString(result));        //dto 2 po        UserInfo info = mapperFacade.map(result, UserInfo.class);        log.info(&quot;dto 2 po =====&gt; &#123;&#125;&quot;, JSON.toJSONString(info));        // pos 2 dtos        List&lt;UserInfo&gt; pos = new ArrayList&lt;&gt;();        pos.add(userInfo);        List&lt;UserInfoDTO&gt; dtos = mapperFacade.mapAsList(pos,UserInfoDTO.class);        log.info(&quot;pos 2 dtos =====&gt; &#123;&#125;&quot;, JSON.toJSONString(dtos));        // pos 2 dtos        pos = mapperFacade.mapAsList(dtos, UserInfo.class);        log.info(&quot;pos 2 dtos =====&gt; &#123;&#125;&quot;, JSON.toJSONString(pos));    &#125;&#125;</code></pre><h4 id="执行结果"><a href="#执行结果" class="headerlink" title="执行结果"></a>执行结果</h4><pre><code class="textmate">testSimple 执行结果:-po 2 dto =====&gt; &#123;&quot;createTime&quot;:&quot;Wed Jun 02 10:11:51 CST 2021&quot;,&quot;ids&quot;:[&quot;1002&quot;,&quot;1003&quot;,&quot;1004&quot;,&quot;1005&quot;],&quot;userId&quot;:&quot;10001&quot;,&quot;userName&quot;:&quot;aaaa&quot;&#125;-dto 2 po =====&gt; &#123;&quot;createTime&quot;:1622650311000,&quot;ids&quot;:[1002,1003,1004,1005],&quot;userId&quot;:10001,&quot;userName&quot;:&quot;aaaa&quot;&#125;-pos 2 dtos =====&gt; [&#123;&quot;createTime&quot;:&quot;Wed Jun 02 10:11:51 CST 2021&quot;,&quot;ids&quot;:[&quot;1002&quot;,&quot;1003&quot;,&quot;1004&quot;,&quot;1005&quot;],&quot;userId&quot;:&quot;10001&quot;,&quot;userName&quot;:&quot;aaaa&quot;&#125;]-pos 2 dtos =====&gt; [&#123;&quot;createTime&quot;:1622650311000,&quot;ids&quot;:[1002,1003,1004,1005],&quot;userId&quot;:10001,&quot;userName&quot;:&quot;aaaa&quot;&#125;]testDiff 执行结果:po 2 dto =====&gt; &#123;&quot;createTime&quot;:&quot;Sat Mar 20 14:30:46 CST 2021&quot;,&quot;dtoName&quot;:&quot;this is po&quot;,&quot;ids&quot;:[&quot;1002&quot;,&quot;1003&quot;,&quot;1004&quot;,&quot;1005&quot;],&quot;userId&quot;:&quot;10001&quot;,&quot;userName&quot;:&quot;aaaa&quot;&#125;dto 2 po =====&gt; &#123;&quot;createTime&quot;:1616272246000,&quot;ids&quot;:[1002,1003,1004,1005],&quot;poName&quot;:&quot;this is po&quot;,&quot;userId&quot;:10001,&quot;userName&quot;:&quot;aaaa&quot;&#125;pos 2 dtos =====&gt; [&#123;&quot;createTime&quot;:&quot;Sat Mar 20 14:30:46 CST 2021&quot;,&quot;dtoName&quot;:&quot;this is po&quot;,&quot;ids&quot;:[&quot;1002&quot;,&quot;1003&quot;,&quot;1004&quot;,&quot;1005&quot;],&quot;userId&quot;:&quot;10001&quot;,&quot;userName&quot;:&quot;aaaa&quot;&#125;]pos 2 dtos =====&gt; [&#123;&quot;createTime&quot;:1616272246000,&quot;ids&quot;:[1002,1003,1004,1005],&quot;poName&quot;:&quot;this is po&quot;,&quot;userId&quot;:10001,&quot;userName&quot;:&quot;aaaa&quot;&#125;]</code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> utils </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LDAP学习笔记</title>
      <link href="2021/02/18/devops/ldap/"/>
      <url>2021/02/18/devops/ldap/</url>
      
        <content type="html"><![CDATA[<h3 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h3><ul><li><a href="https://www.openldap.org/">OpenLDAP</a></li><li><a href="https://www.cnblogs.com/xiaomifeng0510/p/9564688.html">LDAP-admin操作指南</a></li><li><a href="https://blog.csdn.net/weixin_30338461/article/details/98920690">CSDN-Demo</a></li><li><a href="http://docs.spring.io/spring-ldap/docs/2.1.0.RELEASE/reference/">官方文档及例子(重要)</a></li><li><a href="http://docs.spring.io/spring-ldap/docs/2.1.0.RELEASE/apidocs/">JAVA文档（重要）</a></li><li><a href="https://github.com/spring-projects/spring-ldap">GitHub（大量例子）</a></li></ul><h3 id="常用名词"><a href="#常用名词" class="headerlink" title="常用名词"></a>常用名词</h3><pre><code class="textmate">o– organization（组织-公司）ou – organization unit（组织单元-部门）c - countryName（国家）dc - domainComponent（域名）sn – suer name（真实名称）cn - common name（常用名称)</code></pre><h3 id="Docker部署LDAP"><a href="#Docker部署LDAP" class="headerlink" title="Docker部署LDAP"></a>Docker部署LDAP</h3><ul><li><p>ldap<br>```shell<br>#用户名 cn=admin,dc=company,dc=com<br>#密码 123456<br>#注意，\后面不能有空格<br>docker run \</p></li><li><p>p 389:389 \</p></li><li><p>p 636:636 \</p></li><li><p>-name my-ldap \</p></li><li><p>-network bridge \</p></li><li><p>-hostname openldap-host \</p></li><li><p>-env LDAP_ORGANISATION=”company” \</p></li><li><p>-env LDAP_DOMAIN=”company.com” \</p></li><li><p>-env LDAP_ADMIN_PASSWORD=”123456” \</p></li><li><p>-detach osixia/openldap</p><pre><code></code></pre></li><li><p>ldap-admin</p></li></ul><pre><code class="shell">#启动后浏览器访问http://localhost:8080docker run \-d \--privileged \-p 8080:80 \--name ldap-admin \--env PHPLDAPADMIN_HTTPS=false \--env PHPLDAPADMIN_LDAP_HOSTS=LDAP服务IP \--detach osixia/phpldapadmin</code></pre><h3 id="查询用户信息"><a href="#查询用户信息" class="headerlink" title="查询用户信息"></a>查询用户信息</h3><h4 id="方式一"><a href="#方式一" class="headerlink" title="方式一"></a>方式一</h4><pre><code class="java">@Slf4jpublic class ldapService&#123;    public static void main(String[] args) &#123;        try &#123;            String bindUserDN = &quot;cn=admin,dc=company,dc=com&quot;;            //用户密码            String bindPassword = &quot;123456&quot;;            //ldap服务器IP            String url = &quot;ldap://127.0.0.1:389/dc=company,dc=com&quot;;            Hashtable&lt;String, String&gt; env = new Hashtable&lt;&gt;();            env.put(javax.naming.Context.INITIAL_CONTEXT_FACTORY, &quot;com.sun.jndi.ldap.LdapCtxFactory&quot;);            env.put(javax.naming.Context.PROVIDER_URL, url);            env.put(javax.naming.Context.SECURITY_AUTHENTICATION, &quot;simple&quot;);            env.put(javax.naming.Context.SECURITY_PRINCIPAL, bindUserDN);            env.put(javax.naming.Context.SECURITY_CREDENTIALS, bindPassword);            env.put(&quot;java.naming.referral&quot;, &quot;follow&quot;);            DirContext ctx = new InitialDirContext(env);            log.info(&quot;ctx=&#123;&#125;&quot;, JSON.toJSONString(ctx));        &#125; catch (Exception e) &#123;            log.info(&quot;LDAP登录失败 userName=&#123;&#125;,passWord=&#123;&#125;,error=&#123;&#125;&quot;,username,password,e);        &#125;    &#125;&#125;</code></pre><h5 id="方式二-ldapTemplate"><a href="#方式二-ldapTemplate" class="headerlink" title="方式二(ldapTemplate)"></a>方式二(ldapTemplate)</h5><ul><li><p>配置</p><pre><code class="xml">&lt;!-- ldap --&gt;&lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-starter-data-ldap&lt;/artifactId&gt;  &lt;version&gt;2.3.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;</code></pre><pre><code class="yaml"># LDAP连接配置,配置的base是不应该再加到节点的dn里面去的(dc=company,dc=com)spring:ldap:  urls: ldap://127.0.0.1:389  base: dc=company,dc=com  username: cn=admin,dc=company,dc=com  password: 123456</code></pre></li><li><p>代码(model)</p><pre><code class="java">@Getter@Setter@ToString@Entry(objectClasses = &#123;&quot;simpleSecurityObject&quot;, &quot;organizationalRole&quot;,&quot;top&quot;&#125;, base = &quot;ou=cmdb,ou=People&quot;)public class LdapPerson &#123;  @Id  @JsonIgnore  private Name dn;  /** 用户名 **/  @Attribute(name=&quot;cn&quot;)  private String personName;  @Attribute(name=&quot;sn&quot;)  private String sn;  @Attribute(name=&quot;email&quot;)  private String email;  /** 昵称 **/  @Attribute(name=&quot;displayName&quot;)  private String displayName;  @Attribute(name=&quot;password&quot;)  private String password;&#125;</code></pre></li><li><p>代码(dao)</p><pre><code class="java">@Slf4jpublic class PersonAttributesMapper implements AttributesMapper&lt;LdapPerson&gt; &#123;  @Override  public LdapPerson mapFromAttributes(Attributes attrs) throws NamingException &#123;      LdapPerson person = new LdapPerson();      person.setPersonName((String)attrs.get(&quot;cn&quot;).get());      //获取密码      byte[] bts = (byte[]) attrs.get(&quot;userpassword&quot;).get();      String password = &quot;&quot;;      for(byte bt : bts)&#123;          password = password + (char)bt;      &#125;      person.setPassword(password);      return person;  &#125;&#125;</code></pre></li><li><p>代码(service)</p><pre><code class="java">public class LoginService&#123;  //lookup查询(精确定位查询)  public AjaxResult&lt;LdapPerson&gt; ldapCheck(String username, String password) &#123;      String dn = String.format(userDN,username);      LdapPerson person = ldapTemplate.lookup(dn, new PersonAttributesMapper());      log.info(&quot;LDAP登录 username:&#123;&#125;,person=&#123;&#125;&quot;,username,JSON.toJSONString(person));      if(person == null)&#123;          return AjaxResult.error(&quot;账号不存在&quot;);      &#125;      if(!password.equals(person.getPassword()))&#123;          log.error(&quot;LDAP账号对应密码错误,username=&#123;&#125;,password=&#123;&#125;,realPwd=&#123;&#125;&quot;,username,password,person.getPassword());          return AjaxResult.error(&quot;密码错误&quot;);      &#125;      return AjaxResult.success(person);  &#125;  //search(遍历所有节点匹配)  public LdapPerson getLdapAccountByName(String name) &#123;      LdapQuery query = query()              .where(&quot;objectclass&quot;).is(objectclass)              .and(&quot;cn&quot;).is(name);      List&lt;LdapPerson&gt; persons = ldapTemplate.search(query,new PersonAttributesMapper());      if(CollectionUtils.isEmpty(persons))&#123;          return null;      &#125;      return persons.get(0);  &#125;&#125;</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ldap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>服务常见问题排查</title>
      <link href="2021/02/09/devops/check/"/>
      <url>2021/02/09/devops/check/</url>
      
        <content type="html"><![CDATA[<h3 id="死锁问题排查"><a href="#死锁问题排查" class="headerlink" title="死锁问题排查"></a>死锁问题排查</h3><ul><li>模拟死锁</li></ul><pre><code class="java">@Slf4jpublic class ThreadTest &#123;    public static String a1 = &quot;a1&quot;;    public static String a2 = &quot;a2&quot;;    public static void main(String[] args) &#123;        new Thread(new PrintA()).start();        new Thread(new PrintB()).start();    &#125;&#125;</code></pre><pre><code class="java">@Slf4jclass PrintA implements Runnable&#123;    @SneakyThrows    @Override    public void run() &#123;        synchronized (ThreadTest.a1)&#123;            log.info(&quot;PrintA =====&gt; a1&quot;);            Thread.sleep(3000);            synchronized (ThreadTest.a2)&#123;                log.info(&quot;PrintA =====&gt; a2&quot;);            &#125;        &#125;    &#125;&#125;</code></pre><pre><code class="java">@Slf4jclass PrintB implements Runnable&#123;    @SneakyThrows    @Override    public void run() &#123;        synchronized (ThreadTest.a2)&#123;            log.info(&quot;PrintB =====&gt; a2&quot;);            Thread.sleep(3000);            synchronized (ThreadTest.a1)&#123;                log.info(&quot;PrintB =====&gt; a1&quot;);            &#125;        &#125;    &#125;&#125;</code></pre><ul><li>排查命令</li></ul><pre><code class="shell"># 查找到运行中java进程jps -l# 查看进程堆栈信息jstack pid# 查看服务gc情况jstat -gcutil pid 1000</code></pre><ul><li>工具</li></ul><pre><code class="textmate">1.gceasy网站 https://www.gceasy.io2.jconsole 或者 jvisualvm</code></pre><h3 id="频繁FullGC问题排查"><a href="#频繁FullGC问题排查" class="headerlink" title="频繁FullGC问题排查"></a>频繁FullGC问题排查</h3><ul><li>模拟频繁GC</li></ul><pre><code class="java">@Slf4jpublic class OOMTest extends TestCore &#123;    @Autowired    private ThreadPoolConfig poolConfig;    @Test    public void newInstance()&#123;        for(;;)&#123;            ConcurrentHashMap map = new ConcurrentHashMap&lt;&gt;(3000);            map.put(&quot;a&quot;,&quot;b&quot;);            log.info(&quot;&#123;&#125; size=&#123;&#125;&quot;,map.toString(),map.size());        &#125;    &#125;&#125;</code></pre><ul><li>排查</li></ul><pre><code class="textmate">1.配置项目启动参数    #出现 OOM 时生成堆 dump:     -XX:+HeapDumpOnOutOfMemoryError    #生成堆文件地址：    -XX:HeapDumpPath=/home/project/jvmlogs/2.查看哪些对象较大    jmap -histo pid | head -203.通过指令排查(堆栈较大的话可能会将系统卡死)    jmap -dump:file=文件名.dump [pid]    # format=b 指定为二进制文件    jmap -dump:format=b,file=文件名 [pid]</code></pre><ul><li>分析</li></ul><pre><code class="textmate">工具     1.jhat - jdk自带分析工具        jhat &lt;heap-dump-file&gt;  heap-dump-file 是文件的路径和文件名        执行后访问浏览器访问 http://localhost:7000/ 查看     2.Eclipse Memory Analyzer(MAT)        https://www.eclipse.org/mat/downloads.php    3.IBM Heap Analyzer</code></pre>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> devops </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ThreadPool详解</title>
      <link href="2021/02/09/backend/java/thread/threadPool/"/>
      <url>2021/02/09/backend/java/thread/threadPool/</url>
      
        <content type="html"><![CDATA[<h4 id="构造方法签名"><a href="#构造方法签名" class="headerlink" title="构造方法签名"></a>构造方法签名</h4><pre><code class="textmate">ThreadPoolExecutor(int corePoolSize,        int maximumPoolSize,        long keepAliveTime,        TimeUnit unit,        BlockingQueue&lt;Runnable&gt; workQueue,        ThreadFactory threadFactory,        RejectedExecutionHandler handler)corePoolSize - 池中所保存的线程数，包括空闲线程。maximumPoolSize - 池中允许的最大线程数。keepAliveTime - 当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间。unit - keepAliveTime参数的时间单位。workQueue - 执行前用于保持任务的队列。此队列仅保持由 execute方法提交的 Runnable任务。threadFactory - 执行程序创建新线程时使用的工厂。handler - 由于超出线程范围和队列容量而使执行被阻塞时所使用的处理程序。</code></pre><h4 id="官方封装好的线程池"><a href="#官方封装好的线程池" class="headerlink" title="官方封装好的线程池"></a>官方封装好的线程池</h4><pre><code class="textmate">ThreadPoolExecutor是Executors类的底层实现。1. newSingleThreadExecutor（单个后台线程）    创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。    此线程池保证所有任务的执行顺序按照任务的提交顺序执行。2.newFixedThreadPool（固定大小线程池）    创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，    如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。3. newCachedThreadPool（无界线程池，可以进行自动线程回收）    创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，    那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。    此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。4.newScheduledThreadPool    创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。</code></pre><h4 id="排队策略"><a href="#排队策略" class="headerlink" title="排队策略"></a>排队策略</h4><pre><code class="textmate">排队有三种通用策略：1.直接提交    工作队列的默认选项是 SynchronousQueue，它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，    则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。    直接提交通常要求无界 maximumPoolSizes 以避免拒绝新提交的任务。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。2.无界队列。    使用无界队列（例如，不具有预定义容量的 LinkedBlockingQueue）将导致在所有 corePoolSize 线程都忙时新任务在队列中等待。    这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，    适合于使用无界队列；例如，在 Web页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。3.有界队列。    当使用有限的 maximumPoolSizes时，有界队列（如 ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。    队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。    如果任务频繁阻塞（例如，如果它们是 I/O边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU使用率较高，    但是可能遇到不可接受的调度开销，这样也会降低吞吐量。</code></pre><h4 id="BlockingQueue的选择"><a href="#BlockingQueue的选择" class="headerlink" title="BlockingQueue的选择"></a>BlockingQueue的选择</h4><pre><code class="textmate">例子一：使用直接提交策略，也即SynchronousQueue。    首先SynchronousQueue是无界的，也就是说他存数任务的能力是没有限制的，但是由于该Queue本身的特性，在某次添加元素后必须等待其他线程取走后才能继续添加。例子二：使用无界队列策略，即LinkedBlockingQueue    corePoolSize大小的线程数会一直运行，忙完当前的，就从队列中拿任务开始运行。要防止任务疯长，比如任务运行的实行比较长例子三：有界队列，使用ArrayBlockingQueue。    这个是最为复杂的使用，所以JDK不推荐使用。与上面的相比，最大的特点便是可以防止资源耗尽的情况发生。假设，所有的任务都永远无法执行完。    对于首先来的A,B来说直接运行，接下来，如果来了C,D，他们会被放到queue中，如果接下来再来E,F，则增加线程运行E，F。但是如果再来任务，队列无法再接受了，    线程数也到达最大的限制了，所以就会使用拒绝策略来处理。</code></pre><h4 id="拒绝策略"><a href="#拒绝策略" class="headerlink" title="拒绝策略"></a>拒绝策略</h4><pre><code class="textmate">在ThreadPoolExecutor中已经默认包含了4中拒绝策略1.CallerRunsPolicy    线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;        if (!e.isShutdown()) &#123;             r.run();         &#125;    &#125;这个策略显然不想放弃执行任务。但是由于池中已经没有任何资源了，那么就直接使用调用该execute的线程本身来执行。2.AbortPolicy    处理程序遭到拒绝将抛出运行时RejectedExecutionException    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;       throw new RejectedExecutionException();    &#125;    这种策略直接抛出异常，丢弃任务。3.DiscardPolicy    不能执行的任务将被删除    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;&#125;    这种策略和AbortPolicy几乎一样，也是丢弃任务，只不过他不抛出异常。4.DiscardOldestPolicy    如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程）    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;        if (!e.isShutdown()) &#123;            e.getQueue().poll();            e.execute(r);        &#125;    &#125;    该策略就稍微复杂一些，在pool没有关闭的前提下首先丢掉缓存在队列中的最早的任务，然后重新尝试运行该任务。这个策略需要适当小心。    设想:如果其他线程都还在运行，那么新来任务踢掉旧任务，缓存在queue中，再来一个任务又会踢掉queue中最老任务。</code></pre><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><pre><code class="textmate">总结：keepAliveTime和maximumPoolSize及BlockingQueue的类型均有关系。如果BlockingQueue是无界的，那么永远不会触发maximumPoolSize，自然keepAliveTime也就没有了意义。反之，如果核心数较小，有界BlockingQueue数值又较小，同时keepAliveTime又设的很小，如果任务频繁，那么系统就会频繁的申请回收线程</code></pre><h4 id="配置计算公式"><a href="#配置计算公式" class="headerlink" title="配置计算公式"></a>配置计算公式</h4><pre><code class="textmate">为了使CPU达到期望使用率，线程池的最优大小为线程个数 = cpu个数 * cpu利用率 * （1+ IO处理时间 / CPU处理时间)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 线程池 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线程池 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot集成Kafka</title>
      <link href="2021/02/03/backend/mq/kafka/"/>
      <url>2021/02/03/backend/mq/kafka/</url>
      
        <content type="html"><![CDATA[<h3 id="简单案例"><a href="#简单案例" class="headerlink" title="简单案例"></a>简单案例</h3><h4 id="引用包"><a href="#引用包" class="headerlink" title="引用包"></a>引用包</h4><pre><code class="xml">&lt;!-- 设置了版本号，有可能会报错ClassNotFound --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;    &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><pre><code class="yaml">spring:  kafka:  topic: testTopic  bootstrap-servers: 127.0.0.1:9092  producer:    retries: 0    batch-size: 50    buffer-memory: 6554432    key-serializer: org.apache.kafka.common.serialization.StringSerializer    value-serializer: org.apache.kafka.common.serialization.StringSerializer    properties:      max:        request:          size: 5242880      linger.ms: 1</code></pre><h4 id="发送消息"><a href="#发送消息" class="headerlink" title="发送消息"></a>发送消息</h4><pre><code class="java">@Slf4j@Componentpublic class MessageService&#123;    @Autowired    private KafkaTemplate kafkaTemplate;    @Value(&quot;$&#123;spring.kafka.topic&#125;&quot;)    private String topics;    public void sendSyncMessage(String resourceName)&#123;        try&#123;            kafkaTemplate.send(topics,resourceName);        &#125; catch (Exception e) &#123;            log.error(&quot;message send failed, error=&#123;&#125;&quot;, e);        &#125;    &#125;&#125;</code></pre><h4 id="监听消息"><a href="#监听消息" class="headerlink" title="监听消息"></a>监听消息</h4><pre><code class="java">@Slf4j@Componentpublic class MessageListener &#123;    @KafkaListener(topics = &#123;&quot;testTopic&quot;&#125;, groupId = &quot;testGroupId&quot;)    public void annul1(ConsumerRecord&lt;String, String&gt; record) &#123;        log.info(&quot;groupId = myContainer2, message = &quot; + record.toString());    &#125;&#125;</code></pre><h3 id="双kafka案例"><a href="#双kafka案例" class="headerlink" title="双kafka案例"></a>双kafka案例</h3><ul><li><a href="https://www.byteblogs.com/article/434">SpringBoot多kafka配置</a><h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><pre><code class="yaml">spring:kafka:  kafka1:    bootstrap-servers: 127.0.0.1:9092    producer:      retries: 0      batch-size: 50      buffer-memory: 6554432      key-serializer: org.apache.kafka.common.serialization.StringSerializer      value-serializer: org.apache.kafka.common.serialization.StringSerializer      properties:        max:          request:            size: 5242880        linger.ms: 1  kafka2:    bootstrap-servers: 127.0.0.1:9092    producer:      retries: 0      batch-size: 50      buffer-memory: 6554432      key-serializer: org.apache.kafka.common.serialization.StringSerializer      value-serializer: org.apache.kafka.common.serialization.StringSerializer      properties:        max:          request:            size: 5242880        linger.ms: 1</code></pre></li></ul><h4 id="代码配置"><a href="#代码配置" class="headerlink" title="代码配置"></a>代码配置</h4><ul><li><p>实例1配置</p><pre><code class="java">@Configuration@EnableKafkapublic class Kafka1Config &#123;  @Bean(&quot;kafka1ExtListenerKafkaProperties&quot;)  @Primary  @ConfigurationProperties(prefix = &quot;spring.kafka.kafka1&quot;)  public KafkaProperties kafka1ExtListenerKafkaProperties() &#123;      return new KafkaProperties();  &#125;  @Bean(&quot;kafka1ListenerContainerFactory&quot;)  @Primary  KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;Integer, String&gt;&gt; kafkaListenerContainerFactory() &#123;      ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;();      factory.setConsumerFactory(consumerFactory());      factory.setConcurrency(3);      factory.getContainerProperties().setPollTimeout(3000);      return factory;  &#125;  private ConsumerFactory&lt;Integer, String&gt; consumerFactory() &#123;      return new DefaultKafkaConsumerFactory&lt;&gt;(consumerConfigs());  &#125;  private Map&lt;String, Object&gt; consumerConfigs() &#123;      return kafka1ExtListenerKafkaProperties().buildConsumerProperties();  &#125;  @Bean(&quot;kafkaTemplate&quot;)  @Primary  public KafkaTemplate&lt;String, String&gt; kafkaTemplate() &#123;      return new KafkaTemplate&lt;&gt;(producerFactory());  &#125;  private ProducerFactory&lt;String, String&gt; producerFactory() &#123;      DefaultKafkaProducerFactory&lt;String, String&gt; producerFactory = new DefaultKafkaProducerFactory&lt;&gt;(producerConfigs());      return producerFactory;  &#125;  private Map&lt;String, Object&gt; producerConfigs() &#123;      return kafka1ExtListenerKafkaProperties().buildProducerProperties();  &#125;&#125;</code></pre></li><li><p>实例2配置</p><pre><code class="java">@Configuration@EnableKafkapublic class Kafka2Config &#123;  @Bean(&quot;kafka2ListenerKafkaProperties&quot;)  @ConfigurationProperties(prefix = &quot;spring.kafka.kafka2&quot;)  public KafkaProperties kafka2ListenerKafkaProperties() &#123;      return new KafkaProperties();  &#125;  @Bean(&quot;kafka2ListenerContainerFactory&quot;)  public KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;Integer, String&gt;&gt; kafka2ListenerContainerFactory() &#123;      ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;();      factory.setConsumerFactory(consumerFactory());      factory.setConcurrency(3);      factory.getContainerProperties().setPollTimeout(3000);      return factory;  &#125;  /**   * 消费者工厂的bean   *   * @return   */  private ConsumerFactory&lt;Integer, String&gt; consumerFactory() &#123;      return new DefaultKafkaConsumerFactory&lt;&gt;(consumerConfigs());  &#125;  private Map&lt;String, Object&gt; consumerConfigs() &#123;      return kafka2ListenerKafkaProperties().buildConsumerProperties();  &#125;  @Bean(&quot;kafka2Template&quot;)  public KafkaTemplate&lt;String, String&gt; kafka2Template() &#123;      return new KafkaTemplate&lt;&gt;(producerFactory());  &#125;  private ProducerFactory&lt;String, String&gt; producerFactory() &#123;      DefaultKafkaProducerFactory&lt;String, String&gt; producerFactory = new DefaultKafkaProducerFactory&lt;&gt;(producerConfigs());      return producerFactory;  &#125;  private Map&lt;String, Object&gt; producerConfigs() &#123;      return kafka2ListenerKafkaProperties().buildProducerProperties();  &#125;&#125;</code></pre></li></ul><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><pre><code class="java">@Slf4j@Servicepublic class MessageSendService&#123;    @Resource(name = &quot;kafkaTemplate&quot;)    private KafkaTemplate&lt;String, Object&gt; kafkaTemplate;    @Resource(name = &quot;kafkaTemplateForMonitor&quot;)    private KafkaTemplate&lt;String, Object&gt; kafkaTemplateForMonitor;    public boolean kafka1Send(String topic, String message) &#123;        try &#123;            if (kafkaMq) &#123;                kafkaTemplate.send(topic, message);            &#125;        &#125; catch (Exception e) &#123;            log.warn(&quot;kafka1 发送kafka消息失败 topic=&#123;&#125;,error=&#123;&#125;&quot;,topic,e);        &#125;        return true;    &#125;    public boolean kafka2Send(String topic, String message)&#123;        try &#123;            kafkaTemplateForMonitor.send(topic, message);        &#125; catch (Exception e) &#123;            log.warn(&quot;kafka2 发送kafka消息失败 topic=&#123;&#125;,error=&#123;&#125;&quot;,topic,e);        &#125;        return true;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> message </tag>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis学习笔记</title>
      <link href="2021/02/02/backend/storage/redis/"/>
      <url>2021/02/02/backend/storage/redis/</url>
      
        <content type="html"><![CDATA[<h3 id="Redis相关"><a href="#Redis相关" class="headerlink" title="Redis相关"></a>Redis相关</h3><h4 id="RedisTemplate配置"><a href="#RedisTemplate配置" class="headerlink" title="RedisTemplate配置"></a>RedisTemplate配置</h4><pre><code class="java">@Configuration@EnableCachingpublic class RedisConfig extends CachingConfigurerSupport &#123;    @Bean    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory connectionFactory)&#123;        RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;();        template.setConnectionFactory(connectionFactory);        //key的序列化方式        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();        // string的key序列化方式        template.setKeySerializer(stringRedisSerializer);        // hash的key也采用String的序列化方式        template.setHashKeySerializer(stringRedisSerializer);        //value的序列化方式        FastJson2JsonRedisSerializer serializer = new FastJson2JsonRedisSerializer(Object.class);        ObjectMapper om = new ObjectMapper();        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);        om.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);        om.registerModule(new JavaTimeModule());        serializer.setObjectMapper(om);        //string的value序列化方式        template.setValueSerializer(serializer);        // hash的value序列化方式        template.setHashValueSerializer(stringRedisSerializer);        template.afterPropertiesSet();        return template;    &#125;&#125;</code></pre><h3 id="RedisTemplate-k-v序列化差异"><a href="#RedisTemplate-k-v序列化差异" class="headerlink" title="RedisTemplate k-v序列化差异"></a>RedisTemplate k-v序列化差异</h3><img src="https://im-fan.gitee.io/img/cache/redisTemplate-serialize.png"/><h3 id="RedisTemplate-操作hash"><a href="#RedisTemplate-操作hash" class="headerlink" title="RedisTemplate 操作hash"></a>RedisTemplate 操作hash</h3><pre><code class="java">//redis中的hash相当于java中的HashMapString key = &quot;key&quot;;Map&lt;String,String&gt; hashMap = new HashMap&lt;&gt;();hashMap.put(&quot;a&quot;,JSON.toJSONString(new Object()));hashMap.put(&quot;b&quot;,JSON.toJSONString(new Object()));//所有值redisTemplate.opsForHash().putAll(key,hashMap);//获取单个值List&lt;String&gt; hashKey = new ArrayList&lt;&gt;();hashKey.add(&quot;a&quot;); // 获取hash中的某个key下的值redisTemplate.opsForHash().multiGet(key,hashKey);//设置单个值String hk = &quot;hash 的key&quot;;String hv = &quot;hash 的value&quot;;redisTemplate.opsForHash().put(key,hk,hv);//删除keyString[] hkeys = &#123;hk&#125;;redisTemplate.opsForHash().delete(key, hkeys);</code></pre><h3 id="Redis原子操作的两种方式"><a href="#Redis原子操作的两种方式" class="headerlink" title="Redis原子操作的两种方式"></a>Redis原子操作的两种方式</h3><h4 id="Lua脚本"><a href="#Lua脚本" class="headerlink" title="Lua脚本"></a>Lua脚本</h4><pre><code class="shell">-- lua语法 https://www.runoob.com/lua/lua-tutorial.html-- 实现一个原子锁,存在key则返回失败,否则返回存储并返回成功-- 关键字必须大写 参数1:value 参数2:有效时长-- call 与 pcall区别  call执行错误就直接返回,pcall错误则返回一个带 err 域的 Lua 表(table),用于表示错误-- 存在则直接返回失败local val = redis.call(&quot;get&quot;,KEYS[1])-- 不存在,则获取锁if val then    return 0else    redis.call(&quot;set&quot;,KEYS[1],ARGV[1])    redis.call(&#39;expire&#39;,KEYS[1],ARGV[2])    return 1end</code></pre><pre><code class="java">@Servicepublic class LuaService &#123;    @Autowired    private RedisTemplate redisTemplate;    /**     * lua文件所在路径     * @parm key 键     * @param ttl 过期时间，秒     **/    public boolean getAtomLock(String key,long ttl)&#123;        String lockKey = &quot;my:lock:&quot; + key;        // lua脚本所在resource目录下的相对路径        String luaName = &quot;lua/atom_lock.lua&quot;;        // 执行 lua 脚本        DefaultRedisScript&lt;Long&gt; redisScript = new DefaultRedisScript&lt;&gt;();        // 指定 lua 脚本        redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(luaName)));        // 指定返回类型        redisScript.setResultType(Long.class);        // 参数一：redisScript，参数二：key列表，参数三：arg（可多个）        Long result = (Long) redisTemplate.execute(redisScript, Collections.singletonList(lockKey),1,ttl);        return result != null &amp;&amp; result == 1L;    &#125;&#125;</code></pre><h4 id="事务操作"><a href="#事务操作" class="headerlink" title="事务操作"></a>事务操作</h4><ul><li><p>execute方式</p><pre><code class="java">@Servicepublic class RedisService &#123;  @Autowired  private RedisTemplate redisTemplate;  /**   * 不存则在获取锁   * @param key   * @param value 值   * @param expire 过期时间，秒   * **/  public boolean setAndExpireIfAbsent(final String key, final String value, final long expire) &#123;      boolean isSuccess = (boolean) redisTemplate.execute((RedisCallback) connection -&gt; &#123;          Object object = connection.execute(&quot;set&quot;,                  key.getBytes(),                  value.getBytes(),                  SafeEncoder.encode(&quot;NX&quot;),                  SafeEncoder.encode(&quot;EX&quot;),                  Protocol.toByteArray(expire));          return null != object;      &#125;);      return isSuccess;  &#125;&#125;</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 存储 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gradle学习笔记</title>
      <link href="2021/01/21/backend/java/build/gradle/"/>
      <url>2021/01/21/backend/java/build/gradle/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://blog.csdn.net/gdeer/article/details/104815986">Gradle理解：configuration、dependency</a></li></ul><h3 id="关键字解释"><a href="#关键字解释" class="headerlink" title="关键字解释"></a>关键字解释</h3><table><thead><tr><th>关键字</th><th align="center">关键字解释</th><th>值</th><th align="center">值解释</th></tr></thead><tbody><tr><td>plugins</td><td align="center"></td><td>id</td><td align="center"></td></tr><tr><td>group</td><td align="center">定义模块</td><td></td><td align="center"></td></tr><tr><td>version</td><td align="center">模块版本号</td><td></td><td align="center"></td></tr><tr><td>sourceCompatibility</td><td align="center"></td><td></td><td align="center"></td></tr><tr><td>configurations</td><td align="center">不同的 configuration 用来引用不同领域</br>（或不同用途）的 dependencies</td><td></td><td align="center"></td></tr><tr><td>buildscript</td><td align="center">用于声明gradle自身依赖的插件，优先执行</td><td>ext</td><td align="center"></td></tr><tr><td></td><td align="center"></td><td>repositories</td><td align="center"></td></tr><tr><td></td><td align="center"></td><td>dependencies</td><td align="center"></td></tr><tr><td>allprojects</td><td align="center">对所有project的配置,包括root project</td><td>repositories</td><td align="center"></td></tr><tr><td>subprojects</td><td align="center">对所有Child Project的配置</td><td></td><td align="center"></td></tr><tr><td>repositories</td><td align="center">查找jar包顺序</td><td></td><td align="center"></td></tr><tr><td>dependencies</td><td align="center">定义依赖</td><td></td><td align="center"></td></tr><tr><td>test</td><td align="center">定义测试依赖信息</td><td></td><td align="center"></td></tr></tbody></table><h3 id="dependencies依赖关键字"><a href="#dependencies依赖关键字" class="headerlink" title="dependencies依赖关键字"></a>dependencies依赖关键字</h3><table><thead><tr><th>3+</th><th>2.+</th><th align="center">描述</th></tr></thead><tbody><tr><td>implementation</td><td></td><td align="center">所依赖的库仅可在当前module使用，编译速度快</td></tr><tr><td>api</td><td>compile</td><td align="center">所依赖的库可在整工程使用，编译速度较implementation慢</td></tr><tr><td>provided</td><td>compileOnly</td><td align="center">仅在编译时有效，不参与打包，一般在发布no jar的库时候会用到，很少用</td></tr><tr><td>apk</td><td>runtimeOnly</td><td align="center">仅在生成apk的时候参与打包，编译时不参与</td></tr><tr><td>testImplementation</td><td>testCompile</td><td align="center">仅在单元测试代码的编译以及最终打包测试apk时有效</td></tr><tr><td>debugImplementation</td><td>debugCompile</td><td align="center">仅在debug模式的编译和最终的debug apk打包时有效</td></tr><tr><td>releaseImplementation</td><td>releaseCompile</td><td align="center">仅在Release模式的编译和最终的Release apk打包时有效</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 项目编译 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 项目编译 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>技术文档</title>
      <link href="2020/12/25/framework/design/uml/"/>
      <url>2020/12/25/framework/design/uml/</url>
      
        <content type="html"><![CDATA[<h2 id="技术文档设计"><a href="#技术文档设计" class="headerlink" title="技术文档设计"></a>技术文档设计</h2><h3 id="文档格式"><a href="#文档格式" class="headerlink" title="文档格式"></a>文档格式</h3><ul><li>文档版本</li><li>参考资源<ul><li>相关文档地址</li><li>关键名词解释</li></ul></li><li>背景及目标</li><li>系统设计<ul><li>系统架构图(可选)</li><li>组件关系图(可选)</li><li>用例图</li><li>流程图</li><li>时序图</li><li>状态图(可选)</li><li>领域建模</li><li>ER图</li></ul></li></ul><h2 id="UML图相关"><a href="#UML图相关" class="headerlink" title="UML图相关"></a>UML图相关</h2><h3 id="常用元素"><a href="#常用元素" class="headerlink" title="常用元素"></a>常用元素</h3><pre><code class="textmate">1.类  用三层矩形框表示，第一层类名及解释(斜体表示抽象类)、第二层字段和属性、第三层方法  前面的符号，‘+’表示public，‘-’表示private，‘#’表示protected。2.接口  用两层矩形框表示，第一层接口名及解释、第二层方法</code></pre><h3 id="常见的几种关系"><a href="#常见的几种关系" class="headerlink" title="常见的几种关系"></a>常见的几种关系</h3><pre><code class="textmate">1.泛化(Generalization)    表示继承。是is-a的关系。 用 空心三角箭头+实线 表示，箭头指向继承的类2.依赖(Dependency)    是一种类与接口的关系，表示类是接口所有特征和行为的实现. 空心三角箭头+虚线 箭头指向接口3.关联(Association)    描述类与类之间的连接，是has­-a的关系。它使一个类知道另一个类的属性和方法; 实心三角箭头+实线，两边关联则有两个箭头4.聚合(Aggregation)    是整体与部分的关系，且部分可以离开整体而单独存在。空心菱形+实线，菱形指向整体5.组合(Composition)    是整体与部分的关系，但部分不能离开整体而单独存在。实心菱形+实线，菱形指向整体6. 实现(Realization)    是一种类与接口的关系，表示类是接口所有特征和行为的实现。空心三角箭头+虚线，箭头指向接口基数: 线两端的数字表明这一端的类可以有几个实例，比如：一个鸟应该有两只翅膀。如果一个类可能有无数个实例，则就用‘n’来表示。关联、聚合、组合是有基数的。</code></pre><img src="https://im-fan.gitee.io/img/uml/uml-line.png" width="500" height="300"/><h3 id="示例-标识了所有关系"><a href="#示例-标识了所有关系" class="headerlink" title="示例-标识了所有关系"></a>示例-标识了所有关系</h3><img src="https://im-fan.gitee.io/img/uml/uml.png"/><h2 id="设计工具"><a href="#设计工具" class="headerlink" title="设计工具"></a>设计工具</h2><h3 id="在线版"><a href="#在线版" class="headerlink" title="在线版"></a>在线版</h3><ul><li><a href="https://www.processon.com/">Processon-推荐</a></li><li><a href="https://app.diagrams.net/">Draw.io</a></li><li><a href="https://online.visual-paradigm.com/cn/drive/#diagramlist:proj=0&new">Visual-Paradigm</a></li></ul><h3 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h3><ul><li>VisualParadigm(功能强大，相比其他软件样式可能有点丑)</li><li>draw.io(简单易用，样式美观)</li></ul>]]></content>
      
      
      <categories>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 技术文档 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>COLA</title>
      <link href="2020/12/15/framework/cola/"/>
      <url>2020/12/15/framework/cola/</url>
      
        <content type="html"><![CDATA[<h3 id="相关网址"><a href="#相关网址" class="headerlink" title="相关网址"></a>相关网址</h3><ul><li><a href="https://github.com/alibaba/COLA">COLA 4.0</a></li><li><a href="https://blog.csdn.net/significantfrank/article/details/110934799?utm_source=app">COLA 4.0：应用架构的最佳实践</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> COLA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MybatisPlus使用笔记</title>
      <link href="2020/12/10/backend/java/utils/mybatis-plus/"/>
      <url>2020/12/10/backend/java/utils/mybatis-plus/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://mp.baomidou.com/">官网</a></li></ul><h3 id="常用配置"><a href="#常用配置" class="headerlink" title="常用配置"></a>常用配置</h3><pre><code class="yaml">#mybatis# 配置是否打印日志 true-打印  false-不打印# paginationInterceptor-true 改为false则分页功能无效sql:  performanceInterceptor: truemybatis-plus:  mapper-locations: classpath*:/mapper/**/*.xml  #实体扫描，多个package用逗号或者分号分隔  typeAliasesPackage: com.ruoyi.**.domain  global-config:    #数据库相关配置    db-config:      #主键类型  AUTO:&quot;数据库ID自增&quot;, INPUT:&quot;用户输入ID&quot;, ID_WORKER:&quot;全局唯一ID (数字类型唯一ID)&quot;, UUID:&quot;全局唯一ID UUID&quot;;      id-type: AUTO      #字段策略 IGNORED:&quot;忽略判断&quot;,NOT_NULL:&quot;非 NULL 判断&quot;),NOT_EMPTY:&quot;非空判断&quot;      field-strategy: NOT_NULL      #驼峰下划线转换      column-underline: true      logic-delete-value: -1      logic-not-delete-value: 0    banner: false  #原生配置  configuration:    #不加无法打印执行脚本及内容    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl    map-underscore-to-camel-case: true    cache-enabled: false    call-setters-on-nulls: true    jdbc-type-for-null: &#39;null&#39;</code></pre><h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><ul><li><p>1.selectOne() 查询出多条数据会报错</p><pre><code class="textmate">selectOne不是存在多条数据时只返回一条！！！报错信息： org.mybatis.spring.MyBatisSystemException: nested exception is org.apache.ibatis.exceptions.TooManyResultsException: Expected one result (or null) to be returned by selectOne(), but found: 2解决方法:  1.手动添加  wrapper最后加上(最好带上排序，每次返回固定的值) .last(&quot;limit 1&quot;)  2.切面统一处理,如下</code></pre><pre><code class="java">@Aspect@Componentpublic class MybatisPlusAspect &#123;  // 配置织入点  @Pointcut(&quot;execution(public * com.baomidou.mybatisplus.core.mapper.BaseMapper.selectOne(..))&quot;)  public void selectOneAspect() &#123;  &#125;  @Before(&quot;selectOneAspect()&quot;)  public void beforeSelect(JoinPoint point) &#123;      Object arg = point.getArgs()[0];      if (arg instanceof AbstractWrapper) &#123;          arg = (AbstractWrapper) arg;          ((AbstractWrapper) arg).last(&quot;limit 1&quot;);      &#125;  &#125;&#125;</code></pre></li></ul><h3 id="Idea生成代码插件推荐"><a href="#Idea生成代码插件推荐" class="headerlink" title="Idea生成代码插件推荐"></a>Idea生成代码插件推荐</h3><ul><li><a href="https://plugins.jetbrains.com/plugin/13847-easycode-mybatiscodehelper">EasyCode-MybatisCodeHelper</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> utils </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OAuth2学习笔记</title>
      <link href="2020/11/17/framework/oauth2/"/>
      <url>2020/11/17/framework/oauth2/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://github.com/lexburner/oauth2-demo">参考demo</a></li><li><a href="https://colobu.com/2017/04/28/oauth2-rfc6749/">OAuth2 RFC6749中文翻译</a></li><li><a href="http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html">理解OAuth 2.0-阮一峰</a></li><li><a href="https://github.com/im-fan/my-project/tree/release/1.0/my-oauth2">文档对应demo</a></li></ul><h4 id="框架相关"><a href="#框架相关" class="headerlink" title="框架相关"></a>框架相关</h4><ul><li>OAuth2<pre><code>解释：  OAuth 2.0是一个关于授权的开放网络协议，它允许用户让第三方网站访问该用户在某一网站上存储的信息和资源，  如账户信息，照片，联系人等，而不需要给第三方网站提供某一网站上的账户和密码。流程：  1、用户打开客户端，客户端要求授权。  2、用户同意客户端授权。  3、客户端使用上一步提供的授权，向服务器授权层申请令牌。  4、授权服务器对客户端进行认证后，同意发放令牌。  5、客户端使用令牌，向资源服务器申请资源。  6、资源服务器确认令牌，向客户端开放资源。</code></pre></li><li>LDAP<pre><code>解释：  LDAP是一种基于轻量目录访问协议，全称是Lightweight Directory Access Protocol，是由一个为查询、  浏览和搜索而优化的数据库构成，它成树状结构组织数据，类似文件目录一样。  LDAP单点登录认证主要是改变原有的认证策略，使得需要的软件都通过LDAP服务器进行认证，在统一身份认证后，  用户的所有信息都存储在AD Server中，终端用户在需要使用公司内部服务的时候，都需要通过AD服务器进行认证。登录流程：  1、连接到LDAP服务器。  2、绑定到LDAP服务器。  3、在LDAP服务器上执行所需要的操作。  4、释放LDAP服务器的连接。</code></pre></li><li><a href="https://www.cnblogs.com/lihuidu/p/6495247.html">CAS(Central Authentication Service-中央式认证服务)</a><pre><code>SSO 仅仅是一种架构，一种设计，而 CAS 则是实现 SSO 的一种手段。两者是抽象与具体的关系。CAS即Central Authentication Service模型（中央式认证服务），该协议是为应用提供可信身份认证的单点登录系统，最初是由耶鲁大学开发的。CAS 包含两个部分： CAS Server 和 CAS Client。CAS Server 需要独立部署，主要负责对用户的认证工作；CAS Client 负责处理对客户端受保护资源的访问请求，需要登录时，重定向到 CAS Server。</code></pre></li><li>适用场景<pre><code>OAuth协议能广泛应用于互联网中，基于大企业的巨大用户量，能减少小网站的注册推广成本，并且能做到更加便捷的资源共享。LDAP协议适用于企业用户使用，通过LDAP协议，能较好地管理员工在公司各系统之间的授权与访问。CAS模型，作为权威机构开发的系统，具有很好的兼容性与安全性，广泛应用于各大高校等大型组织，能很好地完成大量系统的对接与大量人员的使用。</code></pre></li></ul><h4 id="授权模式"><a href="#授权模式" class="headerlink" title="授权模式"></a>授权模式</h4><ul><li><p>授权码模式（authorization code）</p><pre><code>功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与&quot;服务提供商&quot;的认证服务器进行互动。</code></pre></li><li><p>简化模式（implicit）</p></li><li><p>密码模式（resource owner password credentials）</p></li><li><p>客户端模式（client credentials）</p></li><li><p>主要配置</p><pre><code>Oauth2ServerConfigWebSecurityConfigurer</code></pre></li></ul><h4 id="不同授权模式请求"><a href="#不同授权模式请求" class="headerlink" title="不同授权模式请求"></a>不同授权模式请求</h4><ul><li><p>授权码模式(在浏览器中访问接口)</p><pre><code>配置项：需要将返回地址添加到client中  clients.redirectUris(&quot;http://www.baidu.com&quot;)  GET http://localhost:8200/oauth/authorize?response_type=code&amp;client_id=client_1&amp;redirect_uri=http://www.baidu.com&amp;state=123所需参数解释  response_type：表示授权类型，必选项，此处的值固定为&quot;code&quot;  client_id：表示客户端的ID，必选项  redirect_uri：表示重定向URI，可选项  scope：表示申请的权限范围，可选项  state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。</code></pre></li><li><p>简化模式(在浏览器中访问接口)</p><pre><code>请求地址  GET http://localhost:8200/oauth/authorize?response_type=token&amp;client_id=client_1&amp;redirect_uri=http://www.baidu.com&amp;state=123&amp;scope=select参数解释：  response_type：表示授权类型，此处的值固定为&quot;token&quot;，必选项。  client_id：表示客户端的ID，必选项。  redirect_uri：表示重定向的URI，可选项。  scope：表示权限范围，可选项。  state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值。</code></pre></li><li><p>password方式获取toke</p><pre><code>请求地址  POST http://localhost:8200/oauth/token?grant_type=password&amp;scope=select&amp;client_id=client_1&amp;client_secret=123456&amp;username=user_1&amp;password=123456返回信息  &#123;      &quot;access_token&quot;: &quot;39be5ea6-fdcd-4b15-a4dd-1f3dbaf8fc63&quot;,      &quot;token_type&quot;: &quot;bearer&quot;,      &quot;refresh_token&quot;: &quot;396e6c5e-9d79-420a-8b25-945098b10c82&quot;,      &quot;expires_in&quot;: 43021,      &quot;scope&quot;: &quot;select&quot;  &#125;参数解释  grant_type：表示授权类型，此处的值固定为&quot;password&quot;，必选项。  username：表示用户名，必选项。  password：表示用户的密码，必选项。  scope：表示权限范围，可选项。</code></pre></li><li><p>client方式获取access_token</p><pre><code>请求地址  POST http://localhost:8200/oauth/token?grant_type=client_credentials&amp;scope=select&amp;client_id=client_2&amp;client_secret=123456返回信息  &#123;      &quot;access_token&quot;: &quot;17fc17a9-83b2-41c3-8621-c727d8329bbd&quot;,      &quot;token_type&quot;: &quot;bearer&quot;,      &quot;expires_in&quot;: 42400,      &quot;scope&quot;: &quot;select&quot;  &#125;参数解释  granttype：表示授权类型，此处的值固定为&quot;clientcredentials&quot;，必选项。  scope：表示权限范围，可选项。</code></pre></li></ul><ul><li>刷新token<pre><code>请求地址  POST http://localhost:8200/oauth/token?grant_type=refresh_token&amp;refresh_token=396e6c5e-9d79-420a-8b25-945098b10c82&amp;client_id=client_2&amp;client_secret=123456返回信息  &#123;      &quot;access_token&quot;: &quot;e0e64627-f157-4718-81f0-069ca21549ad&quot;,      &quot;token_type&quot;: &quot;bearer&quot;,      &quot;refresh_token&quot;: &quot;396e6c5e-9d79-420a-8b25-945098b10c82&quot;,      &quot;expires_in&quot;: 43199,      &quot;scope&quot;: &quot;select&quot;  &#125;</code></pre></li></ul><h4 id="请求业务接口"><a href="#请求业务接口" class="headerlink" title="请求业务接口"></a>请求业务接口</h4><ul><li>请求接口<pre><code>配置拦截：  HttpSecurity中配置 http.antMatchers(&quot;/user/**&quot;).authenticated()使用client方式获取的access_token  GET http://localhost:8200/user/info?access_token=d8f47460-c0a6-4247-9f87-1712bae5325e接口可正常返回</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> oauth2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java解析Swagger文档接口及参数</title>
      <link href="2020/11/11/backend/java/utils/swagger/"/>
      <url>2020/11/11/backend/java/utils/swagger/</url>
      
        <content type="html"><![CDATA[<h3 id="相关依赖包"><a href="#相关依赖包" class="headerlink" title="相关依赖包"></a>相关依赖包</h3><pre><code class="xml">&lt;dependencies&gt;    &lt;!--swagger依赖--&gt;    &lt;dependency&gt;        &lt;groupId&gt;io.springfox&lt;/groupId&gt;        &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;        &lt;version&gt;2.9.2&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;io.springfox&lt;/groupId&gt;        &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt;        &lt;version&gt;2.9.2&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;        &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;        &lt;version&gt;1.9.6&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;        &lt;artifactId&gt;fastjson&lt;/artifactId&gt;        &lt;version&gt;1.2.73&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><h3 id="Swagger文档相关接口"><a href="#Swagger文档相关接口" class="headerlink" title="Swagger文档相关接口"></a>Swagger文档相关接口</h3><pre><code class="textmate">1.接口文档地址    https://localhost:8080/swagger-ui.html    https://localhost:8080/doc.html2.JSON格式接口数据(group参数由项目中swagger配置决定)    http://localhost:8080/v2/api-docs?group=V1版本</code></pre><h3 id="主要代码"><a href="#主要代码" class="headerlink" title="主要代码"></a>主要代码</h3><pre><code class="java">    class Test&#123;    /**     * 加载swagger文档中的接口信息     * @Date 2020/11/6 11:31     * @Author fan    **/    public boolean loadSwaggerAPI(Integer lesseeId,String url)&#123;        try &#123;            log.info(&quot;开始加载Swagger文档,url=&#123;&#125;&quot;,url);            String result = OkhttpClientUtil.get(url);            JSONObject jsonObject = JSON.parseObject(result);            if(jsonObject == null)&#123;                return false;            &#125;            //移除对象描述信息            String platform = (String) JSON.parseObject(JSON.toJSONString(jsonObject.get(&quot;info&quot;))).get(&quot;title&quot;);            JSONObject paths = (JSONObject) jsonObject.get(&quot;paths&quot;);            JSONObject definitions = (JSONObject) jsonObject.get(&quot;definitions&quot;);            Map&lt;String,JSONObject&gt; paramMap = JSONObject.toJavaObject(definitions,Map.class);            List&lt;PublicResourceInfo&gt; resourceInfos = new ArrayList&lt;&gt;();            for(Map.Entry&lt;String,Object&gt; entry :  paths.entrySet())&#123;                String apiUrl = entry.getKey();                String perms = resourceInfoService.buildPermByApiPath(null,apiUrl);                JSONObject methodInfo = (JSONObject) entry.getValue();                for(Map.Entry&lt;String,Object&gt; methodEntry : methodInfo.entrySet())&#123;                    String requestType = methodEntry.getKey().toUpperCase();                    JSONObject requestTypeInfo = (JSONObject) methodEntry.getValue();                    String apiName = String.valueOf(requestTypeInfo.get(&quot;summary&quot;));                    String moduleName = StringUtils.join((List&lt;String&gt;)requestTypeInfo.get(&quot;tags&quot;),&quot;,&quot;);                    PublicResourceInfo resourceInfo = new PublicResourceInfo();                    resourceInfo.setPlatformNameCn(platform);                    resourceInfo.setApiPath(apiUrl);                    resourceInfo.setPerms(perms);                    resourceInfo.setApiName(apiName);                    resourceInfo.setRequestType(requestType);                    resourceInfo.setModuleNameCn(moduleName);                    //解析swagger-ui中的出参入参                    JSONArray parameterJson = (JSONArray) requestTypeInfo.get(&quot;parameters&quot;);                    Object requestParam = null;                    Map&lt;String,Object&gt; requestParamMap = new HashMap&lt;&gt;();                    if(parameterJson != null)&#123;                        for(Object object : parameterJson)&#123;                            JSONObject schema = (JSONObject) ((JSONObject) object).get(&quot;schema&quot;);                            if (schema != null)&#123;                                String ref = (String) schema.get(&quot;$ref&quot;);                                requestParam = parseRequestToJson(null,paramMap,ref);                            &#125; else &#123;                                String mapKey = (String) ((JSONObject) object).get(&quot;name&quot;);                                String type = ((JSONObject) object).getString(&quot;type&quot;);                                Object value = setValueByType(type,null);                                requestParamMap.put(mapKey,value);                            &#125;                        &#125;                    &#125;                    if(requestParam != null)&#123;                        resourceInfo.setRequestParam(JSONObject.toJSONString(requestParam));                    &#125; else &#123;                        resourceInfo.setRequestParam(JSONObject.toJSONString(requestParamMap));                    &#125;                    //返回值类型都用标准类型，不解析其他格式                    JSONObject response = (JSONObject) requestTypeInfo.get(&quot;responses&quot;);                    Object responseResult = null;                    if(response != null)&#123;                        JSONObject schema = (JSONObject) ((JSONObject)response.get(&quot;200&quot;)).get(&quot;schema&quot;);                        if(schema != null)&#123;                            String ref = (String) schema.get(&quot;$ref&quot;);                            responseResult = parseRequestToJson(null,paramMap,ref);                        &#125;                    &#125;                    if(responseResult != null)&#123;                        resourceInfo.setResponseParam(JSONObject.toJSONString(responseResult));                    &#125;                    resourceInfos.add(resourceInfo);                &#125;            &#125;            log.info(&quot;解析完成=====&gt;&#123;&#125;&quot;,JSONObject.toJSONString(resourceInfos));        &#125; catch (IOException e) &#123;            log.error(&quot;加载Swagger文档中接口失败，url=&#123;&#125;&quot;,url);            return false;        &#125;        return true;    &#125;    /**     * 解析swagger-ui中出参和入参为json     * @param paramMap 入参和出参对象map,key-对象标识，value-对象属性及类型json     * @param paramRef 入参和出参对应的对象信息， 格式: #/definitions/R«PageResultDTO«PublicResourceInfoDTO»»     * @Date 2020/11/11 16:01     * @Author fan    **/    private Object parseRequestToJson(Map&lt;String,Integer&gt; forEachCache,Map&lt;String,JSONObject&gt; paramMap, String paramRef)&#123;        if(StringUtils.isBlank(paramRef))&#123;            return &quot;&quot;;        &#125;        //对象标识        String paramKey = paramRef.substring(paramRef.lastIndexOf(&quot;/&quot;)+1);        //控制递归次数，同一个对象循环超过1次就返回空        if(forEachCache == null)&#123;            forEachCache = new HashMap&lt;&gt;();        &#125;        Integer forEachCount = forEachCache.get(paramKey);        if(forEachCount != null &amp;&amp; forEachCount &gt;= 1)&#123;            return null;        &#125; else &#123;            forEachCache.put(paramKey,1);        &#125;        //对象值        JSONObject paramJson = paramMap.get(paramKey);        JSONObject propertiesJson = JSONObject.parseObject(String.valueOf(paramJson.get(&quot;properties&quot;)));        Map&lt;String,Object&gt; columnMap = new HashMap&lt;&gt;();        for(Map.Entry&lt;String,Object&gt; entry : propertiesJson.entrySet())&#123;            String key = entry.getKey();            Object value = new JSONObject();            JSONObject valueJson = JSONObject.parseObject(String.valueOf(entry.getValue()));            String type = valueJson.getString(&quot;type&quot;);            Object obj = valueJson.get(&quot;items&quot;);            if(obj != null)&#123;                JSONObject property = JSONObject.parseObject(String.valueOf(obj));                String ref = (String) property.get(&quot;$ref&quot;);                //有下一级，则递归                if(StringUtils.isNotBlank(ref))&#123;                    value = parseRequestToJson(forEachCache,paramMap,ref);                &#125;            &#125;            value = setValueByType(type,value);            columnMap.put(key,value);        &#125;        return columnMap;    &#125;    /**  根据参数类型设置value **/    private Object setValueByType(String type,Object value)&#123;        if(&quot;array&quot;.equals(type))&#123;            JSONArray jsonArray = new JSONArray();            if(value == null)&#123;                value = new JSONObject();            &#125;            jsonArray.add(value);            return JSONArray.toJSONString(jsonArray);        &#125;        if(&quot;integer&quot;.equals(type))&#123;            return 0;        &#125;        if(&quot;boolean&quot;.equals(type))&#123;            return true;        &#125;        if(&quot;object&quot;.equals(type))&#123;            return value;        &#125;        return &quot;&quot;;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> utils </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>互联网常用语记录</title>
      <link href="2020/11/04/thinking/ali-words/"/>
      <url>2020/11/04/thinking/ali-words/</url>
      
        <content type="html"><![CDATA[<h3 id="二字动词"><a href="#二字动词" class="headerlink" title="二字动词"></a>二字动词</h3><pre><code class="textmate">复盘、赋能、沉淀、倒逼、落地、串联、协同、反哺、兼容、包装、重组、履约、响应、量化、发力、布局、联动、开拓、细分、梳理、输出、加速、共建、支撑、融合、聚合、解耦、集成、对齐、对标、对焦、抓手、拆解、拉通、抽象、摸索、提炼、打通、打透、吃透、迁移、分发、分层、分装、穿梭、辐射、围绕、复用、渗透、扩展、</code></pre><h3 id="二字名词"><a href="#二字名词" class="headerlink" title="二字名词"></a>二字名词</h3><pre><code class="textmate">漏斗、中台、闭环、打法、拉通、纽带、矩阵、刺激、规模、场景、聚焦、维度、格局、形态、生态、话术、体系、认知、玩法、体感、感知、调性、心智、战役、合力、心力、赛道、因子、模型、载体、横向、通道、补位、链路、试点</code></pre><h3 id="三字名词"><a href="#三字名词" class="headerlink" title="三字名词"></a>三字名词</h3><pre><code class="textmate">颗粒度、感知度、方法论、组合拳、引爆点、点线面、精细化、差异化、平台化、结构化、影响力、耦合性、易用性、一致性、端到端、短平快</code></pre><h3 id="四字名词"><a href="#四字名词" class="headerlink" title="四字名词"></a>四字名词</h3><pre><code class="textmate">生命周期、价值转化、强化认知、资源倾斜、完善逻辑、抽离透传、复用打法、商业价值、商业模式、快速响应、定性定量、关键链路、去中心化、结果导向、垂直领域、如何收口、归因分析、体验度量、信息屏障</code></pre>]]></content>
      
      
      <categories>
          
          <category> 思考 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 常用语 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper搭建</title>
      <link href="2020/10/29/backend/service/zookeeper/"/>
      <url>2020/10/29/backend/service/zookeeper/</url>
      
        <content type="html"><![CDATA[<h2 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h2><blockquote><p><a href="https://zookeeper.apache.org/releases.html">官网</a></p></blockquote><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><pre><code class="textmate">1.下载 xxx-bin.tar.gz包(这种是编译好的)，否则启动时会提示找不到Class2.启动时注意端口号是否已经被占用</code></pre><h3 id="单机部署步骤"><a href="#单机部署步骤" class="headerlink" title="单机部署步骤"></a>单机部署步骤</h3><pre><code class="textmate">1.解压文件    tar -zxvf xxx-bin.tar.gz zookeeper2.修改配置    cd zookeeper/conf    cp zoo_sample.cfg zoo.cfg    vim zoo.cfg    修改以下配置项        dataDir= xxx/dataDir        dataLogDir= xxx/logs/zookeeper3.新增配置    cd xxx/dataDir    echo 1001&gt;myid4.启动    cd zookeeper/bin    ./zkServer.sh start / restart / stop / status</code></pre><h3 id="zookeeper数据查看工具"><a href="#zookeeper数据查看工具" class="headerlink" title="zookeeper数据查看工具"></a>zookeeper数据查看工具</h3><blockquote><p><a href="https://issues.apache.org/jira/secure/attachment/12436620/ZooInspector.zip">下载地址</a></p></blockquote><ul><li>使用</li></ul><pre><code class="textmate">1.解压后进入build文件夹2.运行jar    nohup java -jar zookeeper-dev-ZooInspector.jar &amp;3.左上角连接按钮，输入zk地址并连接</code></pre><h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><ul><li><p>启动报ClassNotFound</p><pre><code class="textmate">重新下载zookeeper包，注意是xxxx-bin.tar.gz这种的</code></pre></li><li><p>启动失败</p></li></ul><pre><code class="textmate">1.检查配置的文件夹路径和权限是否正常2.检查zookeeper是否已经被启动    ps -ef | grep zookeeper    kill进程3.删除 dataDir 和 dataLogDir 路径下 version-2 文件夹后重启</code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 服务治理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper </tag>
            
            <tag> 注册中心 </tag>
            
            <tag> 分布式锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EasyExcel使用遇到的问题</title>
      <link href="2020/10/20/backend/java/utils/excel/"/>
      <url>2020/10/20/backend/java/utils/excel/</url>
      
        <content type="html"><![CDATA[<h3 id="导出设置标题格式"><a href="#导出设置标题格式" class="headerlink" title="导出设置标题格式"></a>导出设置标题格式</h3><ul><li><p>TitleHandler</p><pre><code class="java">public class TitleHandler implements CellWriteHandler&#123;  //操作列  private List&lt;Integer&gt; columnIndexs;  //颜色  private Short colorIndex;  public TitleHandler(List&lt;Integer&gt; columnIndexs, Short colorIndex) &#123;      this.columnIndexs = columnIndexs;      this.colorIndex = colorIndex;  &#125;  @Override  public void beforeCellCreate(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, Row row, Head head, Integer columnIndex, Integer relativeRowIndex, Boolean isHead) &#123;  &#125;  @Override  public void afterCellCreate(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, Cell cell, Head head, Integer relativeRowIndex, Boolean isHead) &#123;  &#125;  @Override  public void afterCellDataConverted(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, CellData cellData, Cell cell, Head head, Integer relativeRowIndex, Boolean isHead) &#123;  &#125;  @Override  public void afterCellDispose(WriteSheetHolder writeSheetHolder, WriteTableHolder writeTableHolder, List&lt;CellData&gt; cellDataList, Cell cell, Head head, Integer relativeRowIndex, Boolean isHead) &#123;      if(isHead)&#123;          // 设置列宽          Sheet sheet = writeSheetHolder.getSheet();          sheet.setColumnWidth(cell.getColumnIndex(), 20 * 256);          writeSheetHolder.getSheet().getRow(0).setHeight((short)(3*256));          Workbook workbook = writeSheetHolder.getSheet().getWorkbook();          // 设置标题字体样式          WriteCellStyle headWriteCellStyle = new WriteCellStyle();          WriteFont headWriteFont = new WriteFont();          headWriteFont.setFontName(&quot;宋体&quot;);          headWriteFont.setFontHeightInPoints((short)14);          headWriteFont.setBold(true);          if (CollectionUtils.isNotEmpty(columnIndexs) &amp;&amp;                  colorIndex != null &amp;&amp;                  columnIndexs.contains(cell.getColumnIndex())) &#123;              // 设置字体颜色              headWriteFont.setColor(colorIndex);          &#125;          headWriteCellStyle.setWriteFont(headWriteFont);          headWriteCellStyle.setFillForegroundColor(IndexedColors.GREY_25_PERCENT.getIndex());          CellStyle cellStyle = StyleUtil.buildHeadCellStyle(workbook, headWriteCellStyle);          cell.setCellStyle(cellStyle);      &#125;  &#125;&#125;</code></pre></li><li><p>ExcelUtils</p><pre><code class="java">public class ExcelUtils &#123;  /** 导出Excel **/  public static void exportExcel(String fileName, String sheetName,Class clazz,                                 List data, HttpServletResponse response,                                 CellWriteHandler... cellWriteHandlers) throws IOException &#123;      response.setContentType(&quot;application/vnd.ms-excel&quot;);      response.setCharacterEncoding(&quot;utf-8&quot;);      fileName = URLEncoder.encode(fileName, &quot;UTF-8&quot;).replaceAll(&quot;\\+&quot;, &quot;%20&quot;);      response.setHeader(&quot;Content-disposition&quot;, &quot;attachment;filename*=utf-8&#39;&#39;&quot; + fileName + &quot;.xlsx&quot;);      // 列标题的策略      WriteCellStyle headWriteCellStyle = new WriteCellStyle();      // 单元格策略      WriteCellStyle contentWriteCellStyle = new WriteCellStyle();      // 初始化表格样式      HorizontalCellStyleStrategy horizontalCellStyleStrategy = new HorizontalCellStyleStrategy(headWriteCellStyle, contentWriteCellStyle);      ExcelWriterSheetBuilder excelWriterSheetBuilder = EasyExcel.write(response.getOutputStream(), clazz)              .sheet(sheetName)              .registerWriteHandler(horizontalCellStyleStrategy);      if (null != cellWriteHandlers &amp;&amp; cellWriteHandlers.length &gt; 0) &#123;          for (int i = 0; i &lt; cellWriteHandlers.length; i++) &#123;              excelWriterSheetBuilder.registerWriteHandler(cellWriteHandlers[i]);          &#125;      &#125;      // 开始导出      excelWriterSheetBuilder.doWrite(data);  &#125;&#125;</code></pre></li><li><p>使用</p><pre><code class="java">/** 导出excel模板**/public void exportTemplate(List&lt;Integer&gt; ids,HttpServletResponse response)&#123;  try &#123;      List&lt;XXX&gt; result = getByIds(ids);      // 指定标红色的列      List&lt;Integer&gt; columns = Arrays.asList(0,1,2,3);      TitleHandler titleHandler = new TitleHandler(columns, IndexedColors.RED.index);      ExcelUtils.exportExcel(&quot;文件名&quot;,&quot;sheet名称&quot;,              XXX.class,result,response,titleHandler);  &#125; catch (IOException e) &#123;      log.warn(&quot;导出失败,error=&#123;&#125;&quot;,e);  &#125;&#125;</code></pre></li></ul><h3 id="设置中文文件名"><a href="#设置中文文件名" class="headerlink" title="设置中文文件名"></a>设置中文文件名</h3><pre><code class="java">// 代码中添加response.setContentType(&quot;application/vnd.ms-excel;charset=UTF-8&quot;);response.setCharacterEncoding(&quot;utf-8&quot;);response.setHeader(&quot;Content-disposition&quot;, &quot;attachment;filename*=utf-8&#39;&#39;&quot; + fileName + &quot;.xlsx&quot;);</code></pre><h3 id="导出失败返回错误信息"><a href="#导出失败返回错误信息" class="headerlink" title="导出失败返回错误信息"></a>导出失败返回错误信息</h3><pre><code class="java">// 重写响应信息数据类型response.reset();response.setContentType(&quot;application/json&quot;);response.setCharacterEncoding(&quot;utf-8&quot;);try &#123;    response.getWriter().println(result);&#125; catch (IOException ioException) &#123;    log.warn(&quot;业务异常  msg=&#123;&#125;&quot;,ioException);&#125;</code></pre><h3 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h3><h4 id="导出成功但是后台日志报类型转换异常"><a href="#导出成功但是后台日志报类型转换异常" class="headerlink" title="导出成功但是后台日志报类型转换异常"></a>导出成功但是后台日志报类型转换异常</h4><pre><code class="textmate">错误日志    No converter for [class com.hzrys.dashboard.common.result.R] with preset Content-Type &#39;application/vnd.ms-excel;charset=utf-8&#39;    org.springframework.http.converter.HttpMessageNotWritableException: No converter for [class com.hzrys.dashboard.common.result.R] with preset Content-Type &#39;application/vnd.ms-excel;charset=utf-8&#39;原因    导出方法不能有返回值，导出文件时会设置相应头为文件格式；如果有返回值，则就会出现数据转换异常的错误解决方法    修改Controller中方法，改为 void 即可</code></pre><h4 id="poi流转对象问题-用easy-poi时遇到的问题"><a href="#poi流转对象问题-用easy-poi时遇到的问题" class="headerlink" title="poi流转对象问题(用easy-poi时遇到的问题)"></a>poi流转对象问题(用easy-poi时遇到的问题)</h4><pre><code class="textmate">错误日志    Your stream was neither an OLE2 stream, nor an OOXML stream.原因    多次操作流导致文件类型异常解决方法    读取远程流后，直接用当前流转换成对象例:    //读取远程文件工具类    public static InputStream readUrlExcelFile(String urlPath) &#123;        try&#123;            URL url = new URL(urlPath);            URLConnection conn = url.openConnection();            int size = conn.getContentLength();            if(size &lt; 0)&#123;                return null;            &#125;            return conn.getInputStream();        &#125; catch (IOException e)&#123;            e.printStackTrace();        &#125;        return null;    &#125;    //具体业务逻辑 流转对象用的是easy-poi    public static XXService&#123;        public void saveExcel(String url)&#123;            InputStream inputStream;            try&#123;                inputStream = FileUtils.readUrlExcelFile(request.getFilePath());                if(inputStream == null)&#123;                    System.out.println(&quot;文件读取失败&quot;);                    return;                &#125;                ImportParams importParams = new ImportParams();                //标识开始行                importParams.setStartRows(0);                List&lt;XXX&gt; list = ExcelImportUtil.importExcel(inputStream,                        XXX.class,                        importParams);            &#125; catch(Exception e)&#123;                e.printStackTrace();            &#125; finally&#123;                if(inputStream != null)&#123;                    inputStream.close();                &#125;            &#125;        &#125;    &#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> utils </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DDD-领域驱动设计</title>
      <link href="2020/10/09/framework/ddd/"/>
      <url>2020/10/09/framework/ddd/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://mp.weixin.qq.com/s/9eGZZ2wsZoaCVRy0oKt0iw">有赞DDD实践</a></li><li><a href="https://www.processon.com/view/5e55d17ee4b069f82a120d06#map">DDD设计</a></li><li><a href="https://segmentfault.com/a/1190000020270851?utm_source=tag-newest">阿里技术专家详解 DDD 系列- Domain Primitive</a></li></ul><h3 id="Domain-Primitive"><a href="#Domain-Primitive" class="headerlink" title="Domain Primitive"></a>Domain Primitive</h3><pre><code class="textmate">Domain Primitive :Domain Primitive 是一个在特定领域里，拥 有精准定义的、可自我验证的、拥有行为的 Value Object 。1.DP 是一个传统意义上的 Value Object，拥有 Immutable 的特性2.DP 是一个完整的概念整体，拥有精准定义3.DP 使用业务域中的原生语言4.DP 可以是业务域的最小组成部分、也可以构建复杂组合</code></pre><h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h3><pre><code class="textmate">六边形架构、洋葱架构、整洁架构、四色原型SIDE-EFFECT-FREE模式被称为无副作用模式，熟悉函数时编程的朋友都知道，严格的函数就是一个无副作用的函数，对于一个给定的输入，总是返回固定的结果，通常查询功能就是一个函数，命令功能就不是一个函数，它通常会执行某些修改。在DDD架构中，通常会将查询和命令操作分开，我们称之为CQRS(命令查询的责任分离Command Query Responsibility Segregation)，具体落地时，是否将Command和Query分开成两个项目可以看情况决定，大多数情况下放在一个项目可以提高业务内聚性，</code></pre><h4 id="六边形架构"><a href="#六边形架构" class="headerlink" title="六边形架构"></a>六边形架构</h4><ul><li><a href="http://alistair.cockburn.us/Hexagonal+architecture">起源文章</a></li><li><a href="https://www.jianshu.com/p/c6bb08d9c613">相关文章&amp;demo</a></li><li>摘要<pre><code class="textmate">六角架构的初衷是：允许应用程序同样由用户，程序，自动化测试或批处理脚本驱动，并与最终的运行时设备和数据库隔离开发和测试。</code></pre></li></ul><h4 id="洋葱架构"><a href="#洋葱架构" class="headerlink" title="洋葱架构"></a>洋葱架构</h4><ul><li><a href="https://www.infoq.cn/article/2014/11/ddd-onion-architecture">在洋葱(Onion)架构中实现领域驱动设计</a></li><li>摘要<pre><code class="textmate">层级关系  Core ) Domain ) API ) Infrastructure )洋葱架构中的一个重要概念是依赖，外部的层能够访问内部的层，而内部的层则对外部的层一无所知。  核心（Core）层是与领域或技术无关的基础构件块，它包含了一些通用的构件块,包含任何技术层面的概念  领域（Domain）层是定义业务逻辑的地方，每个类的方法都是按照领域通用语言中的概念进行命名的  API 层是领域层的入口，它使用领域中的术语和对象。  基础架构（Infrastructure）层是最外部的一层，它包含了对接各种技术的适配器，例如数据库、用户界面以及外部服务。</code></pre></li></ul><h4 id="整洁架构"><a href="#整洁架构" class="headerlink" title="整洁架构"></a>整洁架构</h4><ul><li><a href="https://www.jianshu.com/p/b296ceea673b">阿里云-架构整洁之道</a></li></ul><h4 id="开源框架"><a href="#开源框架" class="headerlink" title="开源框架"></a>开源框架</h4><ul><li>cola4 </li><li>DDDLib  </li><li>Koala</li></ul><h4 id="四色原型-需求分析利器"><a href="#四色原型-需求分析利器" class="headerlink" title="四色原型-需求分析利器"></a>四色原型-需求分析利器</h4><img src="https://im-fan.gitee.io/img/ddd/four-color.png"/><pre><code class="textmate">概念    “四色原型”是在使用UML建模的时候，把实体分为四类，并标注不同的颜色的一种建模方法。    用一句话来概括四色原型就是：一个什么样的人或物品以某种角色在某个时刻或某段时间内参与某个活动。其中“什么样的”就是DESC，“人或物品”就是PPT,”角色”就是ROLE,而“某个时刻或某个时间段内的某个活动”就是MI。    四色原型”有一个规则：就是MI（事件）不能与PPT（事物）直接打交道，必须通过ROLE（角色）来打交道。例如：只有买家才能下订单，订单只能通过买家与用户关联四色建模法包括    时标型（Moment-Interval）对象：具有可追溯性的记录运营或管理数据的时刻或时段对象，用粉红色表示    PPT（Party/Place/Thing）对象：代表参与到流程中的参与方/地点/物，用绿色表示    角色（Role）对象：在时标型对象与 PPT 对象（通常是参与方）之间参与的角色，用黄色表示    描述（Description）对象：对 PPT 对象的一种补充描述，用蓝色表示四色原型法设计领域模型的步骤：    1.根据需求，采用四色原型分析法建立一个初步的领域模型；    2.进一步分析领域模型，识别出哪些是实体，哪些是值对象，哪些是领域服务；    3.对实体、值对象进行关联和聚合，提炼出聚合边界和聚合根；    4.为聚合根设计仓储（一般情况下，一个聚合分配一个仓储），同时，思考实体、值对象的创建方式，是通过工厂创建，还是直接通过构造函数；    5.走查需求场景，验证设计的领域模型的合理性。</code></pre><h4 id="标准项目模块解释"><a href="#标准项目模块解释" class="headerlink" title="标准项目模块解释"></a>标准项目模块解释</h4><pre><code class="textmate">1.Interface     对外提供服务，包括Controller、防腐层-facade、对象转换-assembler、出参入参对象-dto2.Application     应用层,包括服务层-service(主要作用是操作 聚合根+仓储)3.Domain    领域层,包括领域对象-entity(主要业务逻辑，可以理解为对象封装操作)、领域服务-EntityService(不属于任何一个领域对象的其他业务或复杂业务逻辑)、值对象-ValueObjects 领域事件-DomainEvent、仓储接口定义-repository4.Infrastructure    基础设施层,包括持久化设置-PersistenceFacilities(仓储实现)、工具类等；支持以上模块</code></pre><h3 id="DDD核心概念"><a href="#DDD核心概念" class="headerlink" title="DDD核心概念"></a>DDD核心概念</h3><ul><li><p>实体</p></li><li><p>值对象</p></li><li><p>聚合</p></li><li><p>仓储</p></li><li><p>工厂</p></li><li><p>仓储</p><pre><code class="textmate">实体(Entities):具有唯一标识的对象值对象(Value Objects): 无需唯一标识的对象领域服务(Domain Services): 一些行为无法归类到实体对象或值对象上,本质是一些操作,而非事物聚合/聚合根(Aggregates,Aggregate Roots): 聚合是指一组具有内聚关系的相关对象的集合,每个聚合都有一个root和boundary工厂(Factories): 创建复杂对象,隐藏创建细节仓储(Repository): 提供查找和持久化对象的方法</code></pre></li><li><p>DDD架构图</p><img src="https://im-fan.gitee.io/img/ddd/ddd-framework.png"/></li></ul><h4 id="识别领域服务"><a href="#识别领域服务" class="headerlink" title="识别领域服务"></a>识别领域服务</h4><pre><code class="textmate">主要看它是否满足以下三个特征：    1. 服务执行的操作代表了一个领域概念，这个领域概念无法自然地隶属于一个实体或者值对象。    2. 被执行的操作涉及到领域中的其他的对象。    3. 操作是无状态的。</code></pre><h4 id="仓储相关"><a href="#仓储相关" class="headerlink" title="仓储相关"></a>仓储相关</h4><ul><li>CQRS<pre><code class="textmate">将查询单独划分为应用系统的一个分支，将修改（命令）单独划分为另外一个分支来操作领域对象。这是DDD的另外一种模式，英文简写：CQRS</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14种常用设计模式</title>
      <link href="2020/10/02/framework/design-model/"/>
      <url>2020/10/02/framework/design-model/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="http://www.runoob.com/design-pattern">菜鸟教程</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI4ODQ3NjE2OA==&mid=2247485687&idx=2&sn=d1a405491311488c576197b556d357ec&chksm=ec3c9590db4b1c86a13ff39894dbeead2bbcee738a58da96bcb1bc404b6a948bd1f38312176a&mpshare=1&scene=1&srcid=&sharer_sharetime=1570684867528&sharer_shareid=4c8872b4436b495590f58ccf1453ba58&rd2werd=1#wechat_redirect">设计模式在Spring框架中的良好实践</a><br><a href="https://github.com/im-fan/my-design-mode.git">实现的demo</a></p></blockquote><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h3 id="设计模式的类型"><a href="#设计模式的类型" class="headerlink" title="设计模式的类型"></a>设计模式的类型</h3><img class="magplus" title="设计模式类型" src="https://im-fan.gitee.io/img/design-model/design-model-type.jpg" alt="设计模式类型" width="700" height="840"><h3 id="设计模式实践的关系"><a href="#设计模式实践的关系" class="headerlink" title="设计模式实践的关系"></a>设计模式实践的关系</h3><img class="magplus" title="设计模式之间的关系" src="http://www.runoob.com/wp-content/uploads/2014/08/the-relationship-between-design-patterns.jpg" alt="设计模式之间的关系" width="700" height="840"><h3 id="设计模式的六大原则"><a href="#设计模式的六大原则" class="headerlink" title="设计模式的六大原则"></a>设计模式的六大原则</h3><pre><code>1、开闭原则（Open Close Principle）    开闭原则的意思是：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类。2、里氏代换原则（Liskov Substitution Principle）    里氏代换原则是面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。3、依赖倒转原则（Dependence Inversion Principle）    这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。4、接口隔离原则（Interface Segregation Principle）    这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。5、迪米特法则，又称最少知道原则（Demeter Principle）    最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。6、合成复用原则（Composite Reuse Principle）    合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承。</code></pre><h2 id="模式详解"><a href="#模式详解" class="headerlink" title="模式详解"></a>模式详解</h2><h3 id="1-策略模式-Strategy"><a href="#1-策略模式-Strategy" class="headerlink" title="1.策略模式(Strategy)"></a>1.策略模式(Strategy)</h3><pre><code>定义个策略接口，不同的实现类提供不同的具体策略算法，通过context方法确定方法执行时具体执行那个子类的方法，属于行为型模式混合使用(https://blog.csdn.net/pengpegV5yaya/article/details/25189253)优点： 1、算法可以自由切换。 2、避免使用多重条件判断。 3、扩展性良好。缺点： 1、策略类会增多。 2、所有策略类都需要对外暴露。注意事项：如果一个系统的策略多于四个，就需要考虑使用混合模式，解决策略类膨胀的问题</code></pre><ul><li>示例图片<br/><img src="http://www.runoob.com/wp-content/uploads/2014/08/strategy_pattern_uml_diagram.jpg" /></li></ul><h3 id="2-简单工厂模式-Simple-Factory"><a href="#2-简单工厂模式-Simple-Factory" class="headerlink" title="2.简单工厂模式( Simple Factory )"></a>2.简单工厂模式( Simple Factory )</h3><pre><code>定义一个用以创建对象的工厂, 根据不同的条件[传参/反射]生成不同的对象，属于创建型模式- 优点：工厂类是整个模式的关键.包含了必要的逻辑判断,根据外界给定的信息,决定究竟应该创建哪个具体类的对象.通过使用工厂类,外界仅仅需要负责“消费”对象就可以了。而不必管这些对象究竟如何创建及如何组织的。- 缺点：由于工厂类集中了所有实例的创建逻辑，违反了高内聚责任分配原则，将全部创建逻辑集中到了一个工厂类中；它所能创建的类只能是事先考虑到的，如果需要添加新的类，则就需要改变工厂类了。当系统中的具体产品类不断增多时候，可能会出现要求工厂类根据不同条件创建不同实例的需求．这种对条件的判断和对具体产品类型的判断交错在一起，很难避免模块功能的蔓延，对系统的维护和扩展非常不利；</code></pre><h3 id="3-工厂模式-Factory"><a href="#3-工厂模式-Factory" class="headerlink" title="3.工厂模式( Factory )"></a>3.工厂模式( Factory )</h3><pre><code>针对每一种产品提供一个工厂类，通过不同的工厂实例来创建不同的产品实例。简单工厂是一种产品，工厂是多种产品</code></pre><h3 id="4-抽象工厂模式-Abstract-Factory"><a href="#4-抽象工厂模式-Abstract-Factory" class="headerlink" title="4.抽象工厂模式( Abstract Factory )"></a>4.抽象工厂模式( Abstract Factory )</h3><pre><code>https://blog.csdn.net/hguisu/article/details/7505909应对产品族概念而生，属于创建型模式区别简单工厂 ：用来生产同一等级结构中的任意产品。（对于增加新的产品，无能为力）     例：造了一个工厂，只能生产 宝马和比亚迪汽车；如果需要制造其他车系，工厂要改造升级工厂方法 ：用来生产同一等级结构中的固定产品。（支持增加任意产品）     例：根据工厂图纸造了两个工厂，分别生产宝马和比亚迪汽车；如果需要制造其他车系，按照图纸再造一个工厂； 但无法生产除了车以外的其他产品抽象工厂 ：用来生产不同产品族的全部产品。（对于增加新的产品，无能为力；支持增加产品族）    例：收购了个汽车空调厂，将工厂图纸和空调厂图纸合并成一个图纸；建新厂时按照新的图纸，先建造出有空调+汽车生产线的厂，在利用不同生产线生产汽车和对应的汽车空调；如果需要一个五菱车厂，不支持单独建五菱车厂，但是可以新建带空调的五菱车厂1）还没有工厂时代：假如还没有工业革命，如果一个客户要一款宝马车,一般的做法是客户去创建一款宝马车，然后拿来用。2）简单工厂模式：后来出现工业革命。用户不用去创建车。因为客户有一个工厂来帮他创建.想要什么车，这个工厂就可以建。比如想要宝马车。工厂就创建这个系列的车。即工厂可以创建产品。3）工厂方法模式时代：为了满足客户，车品牌越来越多，如宝马、比亚迪等，一个工厂无法创建所有的车型。于是由单独分出来多个具体的工厂。每个具体工厂创建一种系列。即具体工厂类只能创建一个具体产品。但是轿车工厂还是个抽象。你需要指定某个具体的工厂才能生产车出来。4）抽象工厂模式时代：随着客户的要求越来越高，轿车必须配置空调。于是这个工厂开始生产轿车和需要的空调。最终是客户只要对轿车的销售员说：我要宝马空调车，销售员就直接给他宝马空调车了。而不用自己去创建车.</code></pre><img src="https://www.runoob.com/wp-content/uploads/2014/08/3E13CDD1-2CD2-4C66-BD33-DECBF172AE03.jpg" alt="抽象工厂模式的 UML 图"><h3 id="5-装饰器模式-Decorator"><a href="#5-装饰器模式-Decorator" class="headerlink" title="5.装饰器模式( Decorator )"></a>5.装饰器模式( Decorator )</h3><pre><code>动态的给一个对象添加一些额外的功能，属于结构型模式优点：装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。缺点：多层装饰比较复杂。使用场景： 1、扩展一个类的功能。 2、动态增加功能，动态撤销。注意事项：可代替继承。其他：下图，RedShapeDecorator extends ShapeDecorator</code></pre><img src="http://www.runoob.com/wp-content/uploads/2014/08/decorator_pattern_uml_diagram.jpg" alt="装饰器模式的UML图"/><h3 id="6-代理模式-Proxy"><a href="#6-代理模式-Proxy" class="headerlink" title="6.代理模式( Proxy )"></a>6.代理模式( Proxy )</h3><pre><code>封装被代理对象并限制外界对被代理对象的访问，属于结构型模式关键代码：实现与被代理类组合。优点： 1、职责清晰。 2、高扩展性。 3、智能化。缺点： 1、由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 2、实现代理模式需要额外的工作，有些代理模式的实现非常复杂。注意事项：1、和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口。2、和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制。</code></pre><img src="https://www.runoob.com/wp-content/uploads/2014/08/20201015-proxy.svg" alt="代理模式的UML图"><h3 id="7-模板方法模式-Template"><a href="#7-模板方法模式-Template" class="headerlink" title="7.模板方法模式( Template )"></a>7.模板方法模式( Template )</h3><pre><code>1.定义一个操作的算法骨架, 并将一些步骤延迟到子类中2.一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。属于行为型模式。优点： 1、封装不变部分，扩展可变部分。 2、提取公共代码，便于维护。 3、行为由父类控制，子类实现。缺点：每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。使用场景： 1、有多个子类共有的方法，且逻辑相同。 2、重要的、复杂的方法，可以考虑作为模板方法。注意事项：为防止恶意操作，一般模板方法都加上 final 关键词，否则扩展类就可以自己实现模板方法。</code></pre><img src="http://www.runoob.com/wp-content/uploads/2014/08/template_pattern_uml_diagram.jpg" alt="模板模式的 UML 图"><h3 id="8-外观模式-Facade"><a href="#8-外观模式-Facade" class="headerlink" title="8.外观模式( Facade )"></a>8.外观模式( Facade )</h3><pre><code>为系统向外界提供一个统一的接口、隐藏系统的复杂性（对使用者来说，只关系需要的结果，不关心怎么实现的）；属于结构型模式简单理解：电脑开机关机启动电脑（按一下电源键）：启动CPU、启动内存、启动硬盘关闭电脑（按一下电源键）：关闭硬盘、关闭内存、关闭CPU优点： 1、减少系统相互依赖。 2、提高灵活性。 3、提高了安全性。缺点：不符合开闭原则，如果要改东西很麻烦，继承重写都不合适。使用场景： 1、为复杂的模块或子系统提供外界访问的模块。 2、子系统相对独立。 3、预防低水平人员带来的风险。注意事项：在层次化结构中，可以使用外观模式定义系统中每一层的入口。</code></pre><h3 id="9-适配器模式-Adapter"><a href="#9-适配器模式-Adapter" class="headerlink" title="9.适配器模式( Adapter )"></a>9.适配器模式( Adapter )</h3><pre><code>将一个类的接口转换成客户希望的另一个接口。属于结构型模式简单理解：用于现有业务维护，整合业务逻辑，根据传入的参数来执行具体某个业务优点： 1、可以让任何两个没有关联的类一起运行。 2、提高了类的复用。 3、增加了类的透明度。 4、灵活性好。缺点：1、过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。2.由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类。使用场景：有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。注意事项：适配器不是在详细设计时添加的，而是解决正在服役的项目的问题。</code></pre><img src="https://www.runoob.com/wp-content/uploads/2014/08/20201204-adapter.png" alt="适配器模式的UML图"><h3 id="10-桥接模式-Bridge"><a href="#10-桥接模式-Bridge" class="headerlink" title="10.桥接模式( Bridge )"></a>10.桥接模式( Bridge )</h3><pre><code>将抽象部分与实现部分分离，使它们都可以独立的变化。属于结构型模式优点： 1、抽象和实现的分离。 2、优秀的扩展能力。 3、实现细节对客户透明。缺点：桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程。使用场景： 1、如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系。 2、对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用。 3、一个类存在两个独立变化的维度，且这两个维度都需要进行扩展。注意事项：对于两个独立变化的维度，使用桥接模式再适合不过了。</code></pre><img src="https://www.runoob.com/wp-content/uploads/2014/08/20201015-bridge.svg" alt="桥接模式的UML图"><h3 id="11-建造者模式-Builder"><a href="#11-建造者模式-Builder" class="headerlink" title="11.建造者模式( Builder )"></a>11.建造者模式( Builder )</h3><pre><code>使用多个简单的对象一步一步构建成一个复杂的对象。属于创建型模式优点： 1、建造者独立，易扩展。 2、便于控制细节风险。缺点： 1、产品必须有共同点，范围有限制。 2、如内部变化复杂，会有很多的建造类。注意事项：与工厂模式的区别是：建造者模式更加关注与零件装配的顺序。</code></pre><img src="https://www.runoob.com/wp-content/uploads/2014/08/20201015-builder-pattern.svg" alt="建造者模式的UML图"><h3 id="12-观察者模式-Observer"><a href="#12-观察者模式-Observer" class="headerlink" title="12.观察者模式( Observer )"></a>12.观察者模式( Observer )</h3><pre><code>定义了一种一对多的依赖关系,让多个观察者对象同时监听某一主题对象,在它的状态发生变化时,会通知所有的观察者。观察者模式属于行为型模式。优点： 1、观察者和被观察者是抽象耦合的。 2、建立一套触发机制。缺点：    1、观察者太多时，通知观察者会耗时比较久    2、如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。    3、观察者模式仅仅只是知道观察目标发生了变化。注意事项：    1、JAVA 中已经有了对观察者模式的支持类。    2、避免循环引用。    3、如果顺序执行，某一观察者错误会导致系统卡壳，一般采用异步方式。</code></pre><img src="http://www.runoob.com/wp-content/uploads/2014/08/observer_pattern_uml_diagram.jpg" alt="观察者模式的 UML 图"><h3 id="13-单例模式-Singleton"><a href="#13-单例模式-Singleton" class="headerlink" title="13.单例模式( Singleton )"></a>13.单例模式( Singleton )</h3><pre><code>保证一个类仅有一个实例,并提供一个访问它的全局控制点.优点：1、在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。2、避免对资源的多重占用（比如写文件操作）。   缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。单例模式的几种实现方式1.懒汉式，线程不安全   不加锁 synchronized，所以严格意义上它并不算单例模式。这种方式 lazy loading 很明显，不要求线程安全，在多线程不能正常工作2.懒汉式，线程安全    加锁 synchronized，方式具备很好的 lazy loading，能够在多线程中很好的工作，但是，效率很低，99% 情况下不需要同步。    优点：第一次调用才初始化，避免内存浪费。    缺点：必须加锁 synchronized 才能保证单例，但加锁会影响效率。getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。3、饿汉式    优点：没有加锁，执行效率会提高。    缺点：类加载时就初始化，浪费内存。4、双检锁/双重校验锁（DCL，即 double-checked locking）    这种方式采用双锁机制，安全且在多线程情况下能保持高性能。getInstance() 的性能对应用程序很关键。5、登记式/静态内部类    这种方式能达到双检锁方式一样的功效，但实现更简单。对静态域使用延迟初始化，应使用这种方式而不是双检锁方式。这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。6、枚举    这种实现方式还没有被广泛采用，但这是实现单例模式的最佳方法。它更简洁，自动支持序列化机制，绝对防止多次实例化。经验之谈：一般情况下，不建议使用第 1 种和第 2 种懒汉方式，建议使用第 3 种饿汉方式。只有在要明确实现 lazy loading 效果时，才会使用第 5 种登记方式。如果涉及到反序列化创建对象时，可以尝试使用第 6 种枚举方式。如果有其他特殊的需求，可以考虑使用第 4 种双检锁方式。</code></pre><h3 id="14-命令模式-Command"><a href="#14-命令模式-Command" class="headerlink" title="14.命令模式( Command )"></a>14.命令模式( Command )</h3><pre><code>将一个请求封装成为一个对象, 使可以用不同的请求对客户进行参数化优点：1、降低了系统耦合度。2、新的命令可以很容易添加到系统中去。缺点：使用命令模式可能会导致某些系统有过多的具体命令类。</code></pre><img src="https://www.runoob.com/wp-content/uploads/2014/08/20201015-command-1.svg" alt="命令模式的 UML 图">]]></content>
      
      
      <categories>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Canal服务搭建</title>
      <link href="2020/10/02/backend/storage/canal/"/>
      <url>2020/10/02/backend/storage/canal/</url>
      
        <content type="html"><![CDATA[<h2 id="相关网址"><a href="#相关网址" class="headerlink" title="相关网址"></a>相关网址</h2><ul><li><a href="https://github.com/alibaba/canal/wiki/Home">官网</a></li><li><a href="https://github.com/alibaba/canal/wiki/QuickStart">快速开始</a></li><li><a href="https://github.com/alibaba/canal/releases">Release下载</a></li><li><a href="https://hub.docker.com/r/canal/canal-server/tags/">Docker镜像地址</a></li><li><a href="https://github.com/alibaba/canal/wiki/Canal-Admin-QuickStart">Canal Admin QuickStart</a></li><li><a href="https://github.com/alibaba/canal/wiki/ClientExample">Canal Client Example</a></li></ul><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><h3 id="主要用途"><a href="#主要用途" class="headerlink" title="主要用途"></a>主要用途</h3><pre><code class="textmate">基于 MySQL 数据库增量日志解析，提供增量数据订阅和消费。</code></pre><h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><ul><li>数据库镜像</li><li>数据库实时备份</li><li>索引构建和实时维护(拆分异构索引、倒排索引等)</li><li>业务 cache 刷新</li><li>带业务逻辑的增量数据处理</li></ul><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><pre><code class="textmate">基于MySQL主备复制原理,伪装成MySQL slave,模拟MySQL slave的交互协议,向MySQL mater发送dump协议,MySQL mater收到canal发送过来的dump请求，开始推送binary log给canal，canal解析binary log，再发送到其他存储服务中，如: MySQL，RocketMQ，ES等等。</code></pre><h2 id="用途"><a href="#用途" class="headerlink" title="用途"></a>用途</h2><h2 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h2><h3 id="1-直接部署"><a href="#1-直接部署" class="headerlink" title="1.直接部署"></a>1.直接部署</h3><pre><code class="textmate">1.下载安装包(点击上面Release)    这里用1.1.4版本,下载 canal.deployer-1.1.4.tar.gz(主要程序) 和 canal.admin-1.1.4.tar.gz(管理程序)2.解压&amp;配置    mkdir canal-deployer    mkdir canal-admin    tar -zxvf canal.deployer-1.1.4.tar.gz -C canal-deployer    tar -zxvg canal.admin-1.1.4.tar.gz -C canal-admin    修改 canal-deployer/conf 中 canal.properties(参考 快速开始，或参考底部配置)3.修改Instance配置    cd cd canal-deployer/conf/example/instance.properties    参考官网或底部instance.peroperties配置4.多Instance - 可选    cd canal-deployer/conf    cp -R example example2    修改example2中配置5.配置canal-admin    初始化数据脚本，脚本所在位置 canal-admin/conf/canal_manager.sql    修改配置，配置所在位置 canal-admin/conf/application.yml    修改其中的数据库配置、端口号、用户名密码等-可选6.启动    6-1.canal-admin启动( 访问链接 localhost:80 )        sh ./canal-admin/bin/startup.sh    6-2.canal-server启动        sh ./canal-deployer/bin/startup.sh    6-3.日志所在文件夹        cd canal-deployer/logs</code></pre><h3 id="2、Docker搭建步骤"><a href="#2、Docker搭建步骤" class="headerlink" title="2、Docker搭建步骤"></a>2、Docker搭建步骤</h3><blockquote><p>docker方式部署,注意配置时mysql的IP地址</p></blockquote><h4 id="2-1、准备"><a href="#2-1、准备" class="headerlink" title="2.1、准备"></a>2.1、准备</h4><pre><code class="textmate">1.mysql  需要确认mysql已开启binlog设置2.拉取canal-server镜像  docker pull canal/canal-server:v1.1.43.下载docker启动脚本   wget https://github.com/alibaba/canal/blob/master/docker/run.sh4.修改启动脚本中数据库配置5.下载canal-admin包,修改配置(或者复制run.sh并修改启动命令，启动canal-admin)-可选   wget https://github.com/alibaba/canal/releases/download/canal-1.1.4/canal.admin-1.1.4.tar.gz   mkdir canal-admin   tar -zxvf canal.admin-1.1.4.tar.gz -C canal-admin   修改conf/application.yml中数据库配置   初始化mysql脚本，conf/canal_manager.sql6.canal-client   参考 Canal Client Example</code></pre><h4 id="2-2、启动命令"><a href="#2-2、启动命令" class="headerlink" title="2.2、启动命令"></a>2.2、启动命令</h4><pre><code class="textmate">1.canal-server   运行 sh run.sh 会出现提示，复制提示后运行2.canal-admin   sh bin/startup.sh3.启动程序(canal-client)    成功后会打印出empty count : xx</code></pre><h3 id="CanalAdmin部署"><a href="#CanalAdmin部署" class="headerlink" title="CanalAdmin部署"></a>CanalAdmin部署</h3><ul><li><p>1.集群配置</p><pre><code class="yaml">#集群名-local#zk地址-127.0.0.1:2181 (可以不搭建zk)#以下为配置项# register ipcanal.register.ip =# canal admin configcanal.admin.manager = 127.0.0.1:8089canal.admin.port = 11110canal.admin.user = admincanal.admin.passwd = 4ACFE3202A5FF5CF467898FC58AAB1D615029441</code></pre></li><li><p>2.Server管理</p><pre><code class="textmate">ServerIP-127.0.0.1 (同一集群下server ip不能重复)admin端口号-11110</code></pre></li><li><p>3.Instance管理</p><pre><code class="textmate">注意：Instance名称要与cancal-server容器中文件夹一致，默认有exampleInstance配置项参考官网或底部配置</code></pre></li></ul><h4 id="一个Canal服务读取多个MySQL实例-docker中操作"><a href="#一个Canal服务读取多个MySQL实例-docker中操作" class="headerlink" title="一个Canal服务读取多个MySQL实例(docker中操作)"></a>一个Canal服务读取多个MySQL实例(docker中操作)</h4><pre><code class="textmate">1.进入canal容器内部关闭服务(不关闭复制会导致写入db2失败)    docker exec -it canal-server bash    ./stop.sh2.复制一份Instatnce配置(注意确认example2中文件权限与example中是否一样)    cd canal-server/conf    cp -R example example23.Canal Admin中添加新配置    Instance名称-example24.集成zookeeper    修改canal-server/conf/下配置canal.properties    canal.register.ip = zk服务器IP    canal.zkServers = zk服务器IP:2181</code></pre><h3 id="参考配置-基础版，其他配置参考官网"><a href="#参考配置-基础版，其他配置参考官网" class="headerlink" title="参考配置(基础版，其他配置参考官网)"></a>参考配置(基础版，其他配置参考官网)</h3><ul><li><p>canal.properties</p><pre><code class="yaml"># 用以下配置项是需要修改的，其他默认配置项保留原来设置# canal地址canal.register.ip = zk所在地址# zk配置，如果有用到则配置，没用到则保留默认设置canal.admin.register.auto = truecanal.admin.register.cluster = 192.168.154.231:2181canal.zkServers = 192.168.154.231:2181</code></pre></li><li><p>instance.properties</p><pre><code class="yaml"># 用以下配置项是需要修改的，其他默认配置项保留原来设置(example2配置同下)# 数据库配置canal.instance.master.address= 数据库IP:端口号canal.instance.dbUsername = 用户名 canal.instance.dbPassword = 密码canal.instance.defaultDatabaseName = 要监控的库名，不设置则监听当前实例下所有库canal.instance.connectionCharset = UTF-8canal.instance.tsdb.enable=false</code></pre></li></ul><h4 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h4><ul><li><p>服务都启动成功，客户端拉不到变更日志</p><pre><code class="textmate">注意客户端中 canalConnector.subscribe() 中设置项，设置了值则服务中配置的过滤条件不生效参考配置 canalConnector.subscribe(&quot;sap_system\\..*,user_center\\..*&quot;)</code></pre></li><li><p>一个Canal-Service,多个client，运行时报错</p><pre><code class="textmate">改为一个canal一个client，原因是多个client同时提交ack时，可能会存在重复提交的问题</code></pre></li><li><p>zk中记录的点位异常</p><pre><code class="textmate">进入zookeeper安装目录 cd /bin./zkClient.sh  或  ./zkCli.shdeleteall /otter/canal/destinations/instanceName(canal-admin中配置的instance名称)</code></pre></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><pre><code class="textmate">1.对业务代码无侵入、实时性接近准实时2.支持集群，集群基于zk做集群管理3.提供多种接入方式、适配器等3.不适合做复杂的业务逻辑判断及计算；直接对表数据进行修改，出问题后影响较大</code></pre>]]></content>
      
      
      <categories>
          
          <category> 存储 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> canal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL相关-常用命令</title>
      <link href="2020/10/02/backend/storage/mysql-other/"/>
      <url>2020/10/02/backend/storage/mysql-other/</url>
      
        <content type="html"><![CDATA[<h3 id="存储引擎区别"><a href="#存储引擎区别" class="headerlink" title="存储引擎区别"></a>存储引擎区别</h3><ul><li>查看数据库支持的存储引擎<pre><code class="sql">show engines;</code></pre></li></ul><table><thead><tr><th>类型</th><th>磁盘文件</th><th>特性</th><th>适用场景</th></tr></thead><tbody><tr><td>FEDERATED</td><td></td><td>用来访问远程表存储引擎</td><td>访问远程表</td></tr><tr><td>MRG_MYISAM</td><td></td><td>把多个MyISAM表合并为一个逻辑单元；查询一个表时，相当与查询其所有成员表</td><td>可以用分区表替换merge表</td></tr><tr><td>MyISAM</td><td>.MDY数据)<br/> .MYI(索引)</td><td>主要的非实物处理存储引擎</td><td></td></tr><tr><td>BLACKHOLE</td><td></td><td>丢弃写操作，读操作返回空内容</td><td></td></tr><tr><td>CSV</td><td>.CSV(数据)<br/>.CSM(元数据)</td><td>存储数据时，会以逗号作为数据项之间的分割符号</td><td>不支持索引，数据存在为普通文本文件</td></tr><tr><td>MEMORY</td><td></td><td>置于内存的表</td><td></td></tr><tr><td>ARCHIVE</td><td></td><td>用于数据存档(行插入后不能再修改)</td><td>数据归档，大批量存储后不修改</td></tr><tr><td>InnoDB</td><td>.ibd(数据&amp;索引)</td><td>具备外键支持功能的事务处理引擎</td><td></td></tr><tr><td>PERFORMANCE_SCHEMA</td><td></td><td>用于监视MySQL服务器</td><td></td></tr><tr><td>NDB</td><td></td><td>集群存储引擎</td><td></td></tr><tr><td></td><td>TokuDB</td><td></td><td>存储速度快，查询速度略慢与InnoDB,支持事务等，未来替代InnoDB</td></tr></tbody></table><h3 id="建表语句"><a href="#建表语句" class="headerlink" title="建表语句"></a>建表语句</h3><pre><code class="sql">1.表结构完全复制create table user_bak LIKE user;2.使用某些字段建表create table user_bak select now() as time ;3.建表时字段值强制转换create table user_bak select CAST(&#39;2019-8-01&#39; as UNSIGNED) as time;4.临时表解释：只对当前会话有效，有同名表则原表隐藏不可见，会话结束自动清除create temporary table user_bak  like user;drop temporary table user_bak;</code></pre><h3 id="Cast类型强制转换"><a href="#Cast类型强制转换" class="headerlink" title="Cast类型强制转换"></a>Cast类型强制转换</h3><pre><code class="sql">语法:     Cast(字段名 as 转换的类型 )支持的类型:    CHAR[(N)] 字符型     DATE 日期型    DATETIME 日期和时间型    DECIMAL float型    SIGNED int    TIME 时间型场景:    1.解决utf8字符查询时传入表情符，导致报错；</code></pre><h3 id="新建分区表"><a href="#新建分区表" class="headerlink" title="新建分区表"></a>新建分区表</h3><ul><li><p>示例</p><pre><code class="sql">create table user_bak (id int(11) UNSIGNED AUTO_INCREMENT ,`name` varchar(200) DEFAULT null COMMENT &#39;名称&#39;,rand_num int(11) DEFAULT NULL COMMENT &#39;随机数&#39;,birthday datetime default null comment &#39;生日&#39;,PRIMARY KEY (`id`,rand_num)) ENGINE = INNODB partition by RANGE (rand_num)(  PARTITION p0 VALUES less THAN (20),  PARTITION p1 VALUES less THAN (40),  PARTITION p2 VALUES less THAN (60),  PARTITION p3 VALUES less THAN (80),  PARTITION p4 VALUES less THAN MAXVALUE);</code></pre></li><li><p>注意点</p></li></ul><pre><code class="textmate">1.PRIMARY必须包含分区的字段2.不能单独创建分区，建表时就要创建</code></pre><ul><li>常见异常</li></ul><pre><code class="textmate">1.ERROR 1064  不能单独创建分区解决：建表时就要把分区创建好2.ERROR 1503 主键必须包含分区函数中所有列解决：创建分区的字段必须放在主键索引中</code></pre><h3 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a>子查询</h3><pre><code class="sql">-- 1.ALL - 查询返回单个结果,类似in操作select * from user_bak where (id) &gt;= ALL(select id from user_bak where id = 10)-- 2.ANY &amp; SUM -效果一样,类似or操作select * from user_bak where (name,id) = SOME(select name,id from user_bak where id = 1 or name = &#39;eee&#39;)</code></pre><h3 id="FullText全文搜索"><a href="#FullText全文搜索" class="headerlink" title="FullText全文搜索"></a>FullText全文搜索</h3><ul><li>全文搜索类型</li></ul><pre><code class="textmate">1.自然语言搜索-搜索包含匹配词的信息2.布尔模式搜索-3.查询扩展搜索</code></pre><ul><li>创建索引需要满足的条件</li></ul><pre><code class="textmate">1.表类型为MyISAM,version5.6以后引入了对InnoDB支持2.字段类型只能是char/varchar/text类型3.全文搜索会自动忽略掉常用词(在记录中出现几率为50%以上)-验证可以查出来4.停用词会被过滤掉(the/after/other等)5.少于4个字符会被忽略，查不出来(默认4-84个字符范围，可更改)</code></pre><ul><li>语法</li></ul><pre><code class="sql">-- 自然语言select *,match(`name`) against(&#39;good boy&#39;) as &#39;percentage&#39; from `user` where match(`name`) against(&#39;good boy&#39;);-- 布尔模式select *,match(`name`) against(&#39;good boy&#39; in boolean MODE) as &#39;percentage&#39; from `user` where match(`name`) against(&#39;good boy&#39; in boolean MODE);-- 内容顺序完全匹配select *,match(`name`) against(&#39;&quot;good boy&quot;&#39; in boolean MODE) as &#39;percentage&#39; from `user` where match(`name`) against(&#39;&quot;good boy&quot;&#39; in boolean MODE);-- 扩展查询select *,match(`name`) against(&#39;good boy&#39; with query expansion) as &#39;percentage&#39; from `user` where match(`name`) against(&#39;good boy&#39;  with query expansion);</code></pre><ul><li>修改查询字符长度</li></ul><pre><code class="textmate">1.my.cnf文件中ft_min_word_len2.重建FullText索引或者快速修复repair table table_name quick;</code></pre><h2 id="字符集"><a href="#字符集" class="headerlink" title="字符集"></a>字符集</h2><h3 id="有字符集有关的系统设置"><a href="#有字符集有关的系统设置" class="headerlink" title="有字符集有关的系统设置"></a>有字符集有关的系统设置</h3><pre><code class="yaml">character_set_system 用于存储的字符集character_set_server 服务器默认字符集collation_server  系统排序规则character_set_database 数据库字符集collation_database  数据库排序规则character_set_client 客户端向服务器发送SQL时使用的字符集character_set_result 表示服务器返回结果时使用的字符集character_set_connection 连接时使用的字符串character_set_filesystem 文件系统字符集</code></pre><h3 id="空间值"><a href="#空间值" class="headerlink" title="空间值"></a>空间值</h3><pre><code class="textmate">OpenGIS规范point 类型值,只支持InnoDB/MyISAM/NDB/ARCHIVE引擎point(xxxx,xxxx)</code></pre><h3 id="模糊匹配查询"><a href="#模糊匹配查询" class="headerlink" title="模糊匹配查询"></a>模糊匹配查询</h3><pre><code class="textmate">1.like    % 匹配任意数量的字符序列    _ 只能匹配单个字符    \%  \_  转义2.REGEXP-正则查询</code></pre><h3 id="新建用户后授权"><a href="#新建用户后授权" class="headerlink" title="新建用户后授权"></a>新建用户后授权</h3><pre><code class="sql">-- %表示所有IP可连接CREATE USER `用户名`@`%` IDENTIFIED BY &#39;密码&#39;;grant all privileges on jwgateway.* to &#39;用户名&#39;@&#39;%&#39; identified by &#39;密码&#39;;select * from mysql.user;</code></pre><h3 id="判断时间与已有记录是否重叠"><a href="#判断时间与已有记录是否重叠" class="headerlink" title="判断时间与已有记录是否重叠"></a>判断时间与已有记录是否重叠</h3><pre><code class="sql">-- 1.方法一SELECT * FROM test_tableWHERE (start_time &gt;= startT AND start_time &lt; endT)   OR (start_time &lt;= startT AND end_time &gt; endT)   OR (end_time &gt;= startT AND end_time &lt; endT)-- 2.方法二SELECT * FROM test_table WHERE NOT ( (end_time &lt; startT OR (start_time &gt; endT) )</code></pre>]]></content>
      
      
      <categories>
          
          <category> 存储 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对象转换工具-MapStruct</title>
      <link href="2020/10/02/backend/java/utils/convert/map-struct/"/>
      <url>2020/10/02/backend/java/utils/convert/map-struct/</url>
      
        <content type="html"><![CDATA[<h2 id="MapStruct"><a href="#MapStruct" class="headerlink" title="MapStruct"></a>MapStruct</h2><p><a href="http://mapstruct.org/">MapStruct</a>是一个代码生成器，它基于约定优于配置方法极大地简化了Java bean类型之间映射的实现。<br>生成的映射代码使用普通方法调用，因此快速，类型安全且易于理解。</p><h3 id="如何接入MapStruct"><a href="#如何接入MapStruct" class="headerlink" title="如何接入MapStruct"></a>如何接入MapStruct</h3><ul><li><a href="http://mapstruct.org/documentation/installation/">官网文档</a></li></ul><p>IDEA Support: <a href="https://plugins.jetbrains.com/plugin/10036-mapstruct-support/versions">https://plugins.jetbrains.com/plugin/10036-mapstruct-support/versions</a></p><h3 id="Java-Bean属性拷贝性能对比"><a href="#Java-Bean属性拷贝性能对比" class="headerlink" title="Java Bean属性拷贝性能对比"></a>Java Bean属性拷贝性能对比</h3><p>get/set &gt;= <a href="http://mapstruct.org/">MapStruct</a> &gt; <a href="https://jmapper-framework.github.io/jmapper-core/">JMapper</a>  &gt;  <a href="https://github.com/cglib/cglib/blob/master/cglib/src/main/java/net/sf/cglib/beans/BeanCopier.java">“beanCopier(cglib)”</a> &gt; Orika &gt; ModelMapper &gt; Spring BeanUtils &gt; Dozer &gt; Apache BeanUtils</p><p>性能对比数据来源：</p><ul><li><a href="https://www.baeldung.com/java-performance-mapping-frameworks">https://www.baeldung.com/java-performance-mapping-frameworks</a></li><li><a href="https://java.libhunt.com/categories/337-bean-mapping">https://java.libhunt.com/categories/337-bean-mapping</a></li></ul><p>说明：</p><ul><li>get/set 需要手动编写大量转换代码，代码简洁性差、重复性高和工作量大。</li><li>beanCopier 性能较高，属性名和类型有较高的匹配要求。</li><li>MapStruct 性能较高，在编译阶段，生成Get/Set代码,支持不同属性之间自定义转换。</li><li>Orika 性能较高,支持自定义属性拷贝，性能略差与前两种，当比后面几种高很多。</li><li>Spring BeanUtils 性能一般，只能支持相关名称的拷贝。</li><li>Dozer 性能差，使用简单，编写xml不方便。</li><li>Apache BeanUtils 性能差。</li></ul><h3 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h3><p>实例代码:</p><pre><code class="java">/*** 定义对象之间转换Mapper * @Mapper 只有在接口加上这个注解， MapStruct 才会去实现该接口 *     @Mapper *     componentModel ：主要是指定实现类的类型， *         - default：默认，可以通过 Mappers.getMapper(Class) 方式获取实例对象 *         -  spring：在接口的实现类上自动添加注解 @Component，可通过 @Autowired 方式注入 *     uses 使用用户自定义转换器 * *     http://mapstruct.org/documentation/stable/reference/html/ *///@Mapper(componentModel = &quot;spring&quot;,uses = &#123;DateHandWritten.class&#125;)@Mapper(        uses = &#123;DateHandWritten.class, UserNameHandWritten.class&#125;,        imports = &#123;LocalDateUtil.class&#125;        )public interface PersonMapper &#123;    PersonMapper  INSTANCE  = Mappers.getMapper(PersonMapper.class);    @Mappings(&#123;            //@Mapping(source = &quot;name&quot;,target = &quot;name&quot;,ignore = true),            @Mapping(target = &quot;birthExpressionFormat&quot;, expression = &quot;java(LocalDateUtil.getDateNow().toString())&quot;),            @Mapping(source = &quot;name&quot;,target = &quot;address.name&quot;),            @Mapping(source = &quot;price&quot;,target = &quot;price&quot;,numberFormat = &quot;#.00&quot;),            @Mapping(source = &quot;birthDate&quot;,target = &quot;birthDateFormat&quot;,dateFormat = &quot;yyyy-MM-dd HH:mm:ss&quot;)    &#125;)    /***     * @Mapping：属性映射，若源对象属性与目标对象名字一致，会自动映射对应属性     *     source：源属性     *     target：目标属性     *     dateFormat：String 到 Date 日期之间相互转换，通过 SimpleDateFormat，该值为 SimpleDateFormat              的日期格式     *     ignore: 忽略这个字段     * @Mappings：配置多个@Mapping     */    PersonDto toDto(Person person);    @InheritConfiguration(name = &quot;toDto&quot;)    List&lt;PersonDto&gt; toDtos(List&lt;Person&gt; person);    /*@InheritInverseConfiguration()    PersonDto fromDto(Person person);*/    /**     * @InheritConfiguration 用于继承配置     * */  /*  @InheritConfiguration(name = &quot;toDto&quot;)    void update(Person person, @MappingTarget PersonDto personDto);*/&#125;/**定义自定义转换规则*/public class DateHandWritten &#123;    public String asString(Date date) &#123;        return date != null ? new SimpleDateFormat( &quot;yyyy-MM-dd&quot; )            .format( date ) : null;    &#125;    public Date asDate(String date) &#123;        try &#123;            return date != null ? new SimpleDateFormat( &quot;yyyy-MM-dd&quot; )                .parse( date ) : null;        &#125;        catch ( ParseException e ) &#123;            throw new RuntimeException( e );        &#125;    &#125;&#125;/**定义自定义转换规则*/public class UserNameHandWritten &#123;    public String asUsername(String username) &#123;        return  &quot;被修改后的name&quot;;    &#125; &#125;/***使用实例*/public class MapStructTest &#123;    @Test    public void personTest()&#123;        Person person = buildPerson();        PersonDto personDto = PersonMapper.INSTANCE.toDto(person);        System.out.println(JSON.toJSONString(personDto));        /**        * &#123;&quot;address&quot;:&#123;&quot;name&quot;:&quot;被修改后的name&quot;&#125;,&quot;addresses&quot;:[&#123;&quot;name&quot;:&quot;被修改后的name&quot;&#125;],&quot;age&quot;:0,&quot;birthDate&quot;:1555573411245,&quot;birthDateFormat&quot;:&quot;2019-04-18&quot;,&quot;birthExpressionFormat&quot;:&quot;Thu Apr 18 15:43:31 CST 2019&quot;,&quot;name&quot;:&quot;被修改后的name&quot;,&quot;price&quot;:&quot;2.35&quot;&#125;        * */    &#125;    @Test    public void personListTest()&#123;        Person person = buildPerson();        List&lt;PersonDto&gt; personDtos = PersonMapper.INSTANCE.toDtos(Lists.newArrayList(person));        System.out.println(JSON.toJSONString(personDtos));        /**        * [&#123;&quot;address&quot;:&#123;&quot;name&quot;:&quot;被修改后的name&quot;&#125;,&quot;addresses&quot;:[&#123;&quot;name&quot;:&quot;被修改后的name&quot;&#125;],&quot;age&quot;:0,&quot;birthDate&quot;:1555573439123,&quot;birthDateFormat&quot;:&quot;2019-04-18&quot;,&quot;birthExpressionFormat&quot;:&quot;Thu Apr 18 15:43:59 CST 2019&quot;,&quot;name&quot;:&quot;被修改后的name&quot;,&quot;price&quot;:&quot;2.35&quot;&#125;]        * */    &#125;    private Person buildPerson()&#123;        Address a = new Address();        a.setName(&quot;demo&quot;);        return Person.builder().birthDate(new Date()).price(BigDecimal.valueOf(2.347)).name(&quot;中国人&quot;).addresses(Lists.newArrayList(a)).build();    &#125;&#125;</code></pre><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p>在Maven 编译阶段将自动实现PersonMapper的对象属性转换接口,生成PersonMapperImpl文件。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> utils </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阅读</title>
      <link href="2020/10/02/thinking/book/"/>
      <url>2020/10/02/thinking/book/</url>
      
        <content type="html"><![CDATA[<h3 id="技术书"><a href="#技术书" class="headerlink" title="技术书"></a>技术书</h3><ul><li>计算机基础</li></ul><table><thead><tr><th>分类</th><th>书名</th><th>作者</th></tr></thead><tbody><tr><td>操作系统</td><td>《现代操作系统》</td><td></td></tr><tr><td></td><td>《程序员的自我修养：链接、装载与库》</td><td></td></tr><tr><td></td><td>《操作系统真象还原》</td><td></td></tr><tr><td></td><td>《Linux 内核设计与实现》</td><td></td></tr><tr><td></td><td>《Windows 程序设计》第五版</td><td></td></tr><tr><td>计算机网络</td><td>《计算机网络：自顶向下方法》</td><td></td></tr><tr><td></td><td>《TCP/IP 网络编程》</td><td></td></tr><tr><td></td><td>《网络是怎样连接的》</td><td></td></tr><tr><td></td><td>《图解HTTP》</td><td>上野宣</td></tr><tr><td></td><td>《HTTP权威指南》</td><td></td></tr><tr><td>编译原理</td><td>《编译系统透视：图解编译原理》</td><td></td></tr><tr><td>计算机组成</td><td>《计算机组成与设计：硬件软件接口》</td><td></td></tr></tbody></table><ul><li><p>综合<br>《Netty、Zookeeper、Redis高并发实战》</p></li><li><p>语言</p></li></ul><table><thead><tr><th>分类</th><th>书名</th></tr></thead><tbody><tr><td>Java</td><td>《Java 核心技术》</td></tr><tr><td></td><td>《Effective Java》</td></tr><tr><td></td><td>《Java 编程思想》</td></tr><tr><td></td><td>《深入理解 Java 虚拟机》</td></tr><tr><td></td><td>《Java 并发编程实战》</td></tr></tbody></table><h3 id="思考方式"><a href="#思考方式" class="headerlink" title="思考方式"></a>思考方式</h3><ul><li><a href="https://www.toutiao.com/i6619057728725729800/">结构化思维</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 思考 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 思维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>软件推荐</title>
      <link href="2020/10/02/other/software/"/>
      <url>2020/10/02/other/software/</url>
      
        <content type="html"><![CDATA[<h3 id="Mac软件-amp-工具网站"><a href="#Mac软件-amp-工具网站" class="headerlink" title="Mac软件&amp;工具网站"></a>Mac软件&amp;工具网站</h3><table><thead><tr><th>主要功能</th><th>软件名</th><th>相关网址</th></tr></thead><tbody><tr><td>图片编辑器</td><td>PixelStyle</td><td></td></tr><tr><td>视频播放</td><td>IINA</td><td></td></tr><tr><td>录屏软件</td><td>LICEcap</td><td></td></tr><tr><td>文件比较</td><td>Beyond Compare</td><td></td></tr><tr><td>Markdown编辑工具</td><td>Haroopad</td><td></td></tr><tr><td>Mac包管理工具</td><td>Homebrew</td><td></td></tr><tr><td>Mac破解软件</td><td></td><td><a href="https://xclient.info/">https://xclient.info</a></td></tr><tr><td>相似网站查询</td><td></td><td><a href="https://www.similarsites.com/">https://www.similarsites.com</a></td></tr></tbody></table><h3 id="常用软件激活方法"><a href="#常用软件激活方法" class="headerlink" title="常用软件激活方法"></a>常用软件激活方法</h3><h4 id="JRebl激活"><a href="#JRebl激活" class="headerlink" title="JRebl激活"></a>JRebl激活</h4><ul><li><a href="http://www.yq1012.com/things/5019.html">Idea JRebl插件激活方法</a></li></ul><pre><code class="textmate">1.生成guid    http://jrebel.cicoding.cn/guid2.配置    设置 JRebel &amp; XRebel 点击Chanage license3.填入    http://jrebel.cicoding.cn/新生成的guid    邮箱</code></pre><ul><li>方式二<br>```textmate</li></ul><p>1.Team Url<br>    <a href="http://jrebel.cicoding.cn/016AAD2C-DD8E-6D92-58EB-B6C79E874355">http://jrebel.cicoding.cn/016AAD2C-DD8E-6D92-58EB-B6C79E874355</a><br>    <a href="mailto:&#x78;&#x78;&#120;&#64;&#120;&#120;&#x78;&#46;&#x63;&#111;&#109;">&#x78;&#x78;&#120;&#64;&#120;&#120;&#x78;&#46;&#x63;&#111;&#109;</a><br>2.然后设置为离线使用</p><pre><code>#### MacOS sourceTree跳过登录```textmate1.显示包内容2.搜索Atlassian3.删除搜出来的文件(没有说明安装包可能有问题)</code></pre><h4 id="MacOS软件已损坏修复"><a href="#MacOS软件已损坏修复" class="headerlink" title="MacOS软件已损坏修复"></a>MacOS软件已损坏修复</h4><pre><code class="textmate">## 软件已损坏sudo xattr -d com.apple.quarantine /Applications/xxxxxx.app</code></pre><h4 id="ssh密钥生成"><a href="#ssh密钥生成" class="headerlink" title="ssh密钥生成"></a>ssh密钥生成</h4><pre><code class="shell">## 配置git config --global user.name &quot;名称&quot;git config --global user.email &quot;邮箱地址&quot;## -t重新生成ssh-keygen [-t] rsa -C &quot;your_email@example.com&quot; -f gitee_id_rsa## 如果生成的密钥不生效，则将密钥重新加下！！！ssh-add ~/.ssh/qts_id_rsa##测试是否成生效ssh -T gitee@gitee.com</code></pre>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo搭建博客</title>
      <link href="2020/09/30/other/hexo/"/>
      <url>2020/09/30/other/hexo/</url>
      
        <content type="html"><![CDATA[<blockquote><p>记录本博客搭建步骤，适用于Mac/Linux系统，详细介绍及其他系统请参照Hexo官网</p></blockquote><h3 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h3><ul><li><a href="https://hexo.io/zh-cn/">Hexo官网</a></li><li><a href="https://hexo.io/themes/">官网主题</a></li><li><a href="https://github.com/yelog/hexo-theme-3-hexo">3-hexo主题</a></li><li><a href="https://yelog.org/2017/03/13/3-hexo-logs/">3-hexo主题相关文档</a></li></ul><h3 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h3><blockquote><p>mac用户推荐先安装Homebrew，通过Homebrew安装一下软件</p></blockquote><ul><li><a href="https://brew.sh/">Homebrew</a></li><li>安装Git</li><li>安装Node.js</li></ul><h3 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h3><pre><code class="textmate">npm install -g hexo-cli</code></pre><h3 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h3><pre><code class="shell">注: my-hexo - 项目名/项目文件夹名hexo init my-hexocd my-hexonpm install</code></pre><h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3><ul><li><p>目录</p><pre><code class="textmate">.├── _config.yml├── package.json├── scaffolds├── source|   ├── _drafts|   └── _posts└── themes</code></pre></li><li><p>目录介绍</p></li></ul><pre><code class="textmate">1._config.yml网站的 配置 信息，您可以在此配置大部分的参数2.package.json应用程序的信息。3.scaffolds模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。4.source资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。5.themes主题 文件夹。Hexo 会根据主题来生成静态页面。</code></pre><h3 id="配置主题"><a href="#配置主题" class="headerlink" title="配置主题"></a>配置主题</h3><ul><li><a href="https://hexo.io/themes/">官网主题</a></li><li>本博客使用的主题 <a href="https://github.com/yelog/hexo-theme-3-hexo">3-hexo</a></li></ul><pre><code class="textmate">1.项目根目录下执行(下载其他主题，修改为themes/xxx即可)git clone https://github.com/yelog/hexo-theme-3-hexo.git themes/3-hexo2.修改配置修改hexo根目录的_config.yml，theme: 3-hexo3.主题更新cd themes/3-hexogit pull在此感谢提供主题的作者</code></pre><h3 id="写作"><a href="#写作" class="headerlink" title="写作"></a>写作</h3><ul><li>常用文档命令</li></ul><pre><code class="textmate">1.新建文档hexo new [layout] &lt;title&gt;2.新建草稿文档hexo new [layout] &lt;title&gt;3.草稿&lt;-&gt;发布hexo publish [layout] &lt;title&gt;</code></pre><ul><li><p>参数介绍</p><table><thead><tr><th>参数</th><th>值</th><th>作用</th><th>生成文件的路径</th></tr></thead><tbody><tr><td>layout</td><td>post</td><td>正式发表的文章</td><td>source/_posts</td></tr><tr><td>layout</td><td>page</td><td>静态页面</td><td>source</td></tr><tr><td>layout</td><td>draft</td><td>草稿</td><td>source/_drafts</td></tr><tr><td>title</td><td>-</td><td>文章标题&amp;文件名</td><td>-</td></tr></tbody></table></li><li><p>文档头部信息格式</p></li></ul><pre><code class="textmate">---title: Javadate: 2020-09-30 14:51:20tags: - Javacategories: - Java- 笔记---</code></pre><ul><li>文档头部信息解释</li></ul><table><thead><tr><th>参数</th><th>作用</th></tr></thead><tbody><tr><td>title</td><td>网站标题</td></tr><tr><td>subtitle</td><td>网站副标题</td></tr><tr><td>description</td><td>网站描述</td></tr><tr><td>tags</td><td>标签，可多个</td></tr><tr><td>categories</td><td>分类菜单，可定义多级</td></tr><tr><td>keywords</td><td>网站的关键词。支援多个关键词。</td></tr><tr><td>author</td><td>您的名字</td></tr><tr><td>language</td><td>网站使用的语言。对于简体中文用户来说，使用不同的主题可能需要设置成不同的值，请参考你的主题的文档自行设置，常见的有 zh-Hans和 zh-CN。</td></tr><tr><td>timezone</td><td>网站时区。Hexo 默认使用您电脑的时区。请参考 时区列表 进行设置，如 America/New_York, Japan, 和 UTC 。一般的，对于中国大陆地区可以使用 Asia/Shanghai。</td></tr></tbody></table><h3 id="运行-amp-发布"><a href="#运行-amp-发布" class="headerlink" title="运行&amp;发布"></a>运行&amp;发布</h3><ul><li>本地运行<pre><code class="textmate">npm run server</code></pre></li><li>编译&amp;部署<pre><code class="textmate">hexo clean hexo generate编译后会生成public文件夹，部署gitpage可以直接指定public为资源文件夹即可</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tool </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
